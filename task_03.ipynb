{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMUod1cIOTiACs4FYnzdPSs"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize"
      ],
      "metadata": {
        "id": "3lzYptk8YhQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the repo\n",
        "!git clone https://fas38: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@github.com/fas38/nnti-project-25.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6Vz1ixnTucc",
        "outputId": "9d61a94a-8e8b-4e03-a23f-d3e2e50885c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nnti-project-25'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 50 (delta 20), reused 17 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (50/50), 1.67 MiB | 3.93 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "# for mouting drive in google colab\n",
        "drive.mount('/content/drive')\n",
        "# set path\n",
        "%cd /content/nnti-project-25/\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "wmaTcnvQEA8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2058b8b3-b60a-44a4-bf30-cd32fe04fdf3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/nnti-project-25\n",
            "/content/nnti-project-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install required packages\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZcvcu2FELD0",
        "outputId": "e581726d-c765-49ac-9971-c2f2efc8c635",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (7.7.1)\n",
            "Collecting jupyter (from -r requirements.txt (line 2))\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.5.1+cu124)\n",
            "Collecting datasets (from -r requirements.txt (line 7))\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.48.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.6.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.19.7)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r requirements.txt (line 1)) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r requirements.txt (line 1)) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r requirements.txt (line 1)) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r requirements.txt (line 1)) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r requirements.txt (line 1)) (3.0.13)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter->-r requirements.txt (line 2)) (6.5.5)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter->-r requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter->-r requirements.txt (line 2)) (7.16.6)\n",
            "Collecting jupyterlab (from jupyter->-r requirements.txt (line 2))\n",
            "  Downloading jupyterlab-4.3.5-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 4)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 4)) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 7)) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 7))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 7)) (4.67.1)\n",
            "Collecting xxhash (from datasets->-r requirements.txt (line 7))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->-r requirements.txt (line 7))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 7)) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 7)) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 7)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 8)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 8)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 8)) (0.5.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (3.5.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (2.10.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 10)) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 10)) (4.0.12)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 1)) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 1)) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 1)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 1)) (1.6.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 1)) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 1)) (6.4.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (4.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 10)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 7)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 7)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 7)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 7)) (2025.1.31)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (5.10.4)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 2)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (1.5.1)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->-r requirements.txt (line 2)) (0.28.1)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->-r requirements.txt (line 2)) (0.2.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 2)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 10)) (5.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 2)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 2)) (0.14.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (0.8.4)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 1))\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter->-r requirements.txt (line 2)) (21.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 1)) (0.4)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 2)) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 2)) (4.23.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook->jupyter->-r requirements.txt (line 2)) (2.21.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (0.2.13)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 2)) (2.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 2)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 2)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 2)) (0.23.1)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading python_json_logger-3.2.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 2)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 2)) (2.22)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2)) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2)) (24.11.1)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.3.5-py3-none-any.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
            "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_json_logger-3.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: xxhash, uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, json5, jedi, fqdn, dill, async-lru, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jupyter-server-terminals, jupyter-client, arrow, nvidia-cusolver-cu12, isoduration, datasets, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "Successfully installed arrow-1.3.0 async-lru-2.0.4 datasets-3.3.2 dill-0.3.8 fqdn-1.5.1 isoduration-20.11.0 jedi-0.19.2 json5-0.10.0 jupyter-1.1.1 jupyter-client-7.4.9 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.3.5 jupyterlab-server-2.27.3 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 overrides-7.7.0 python-json-logger-3.2.1 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from datasets import Dataset as HF_Dataset\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from itertools import islice\n",
        "import random"
      ],
      "metadata": {
        "id": "ts0KumnWFv68"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "vIPexXD5A1we"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class and Methods"
      ],
      "metadata": {
        "id": "5kzNKy2482eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model class with regression head\n",
        "class MoLFormerWithRegressionHead(nn.Module):\n",
        "    # TODO: your code goes here\n",
        "  def __init__(self,model):\n",
        "    super(MoLFormerWithRegressionHead, self).__init__()\n",
        "    self.pretrained = model\n",
        "    hidden_size = self.pretrained.config.hidden_size\n",
        "\n",
        "    self.regression = nn.Linear(hidden_size, 1)\n",
        "\n",
        "\n",
        "  def forward(self, ids, mask):\n",
        "    # pass input to the pre-trained model\n",
        "    output = self.pretrained(ids, attention_mask=mask)\n",
        "    # extracts the last hidden state\n",
        "    hidden_states = output.last_hidden_state\n",
        "    # selects the cls token, represents the summary of the entire sequence\n",
        "    cls_representation = hidden_states[:, 0, :]\n",
        "\n",
        "    output = self.regression(cls_representation)\n",
        "    return output.squeeze(-1) # to remove the last dimension\n",
        "\n",
        "# dataset class\n",
        "class SMILESDataset(Dataset):\n",
        "\n",
        "  def __init__(self, data, tokenizer, max_length):\n",
        "      self.data = data\n",
        "      self.tokenizer = tokenizer\n",
        "      self.max_len = max_length\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      row = self.data[idx]\n",
        "      SMILES = row['SMILES']\n",
        "      label = row['label']\n",
        "\n",
        "      inputs = self.tokenizer.encode_plus(\n",
        "      SMILES,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      padding='max_length',\n",
        "      return_token_type_ids=False,\n",
        "      truncation=True\n",
        "  )\n",
        "\n",
        "      return {\n",
        "    'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
        "    'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
        "    'target': torch.tensor(label, dtype=torch.float)  # Directly convert the target to float\n",
        "}"
      ],
      "metadata": {
        "id": "zi9ZNUTB9A43"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Methods for Computing Influence"
      ],
      "metadata": {
        "id": "QGBZz_rA9rjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_hvp(model, loss, v, max_norm=1.0):\n",
        "    \"\"\"\n",
        "    Computes the Hessian-vector product (HVP) using Fast Exact Multiplication by the Hessian\n",
        "\n",
        "    Parameters:\n",
        "    - model: Pre-trained model\n",
        "    - loss: MSE Output\n",
        "    - v: Gradient vector\n",
        "    - max_norm: Maximum allowed norm for HVP.\n",
        "\n",
        "    Returns:\n",
        "    - The Hessian-vector product (HVP)\n",
        "    \"\"\"\n",
        "    grads = torch.autograd.grad(loss, model.parameters(), create_graph=True, retain_graph=True)\n",
        "    flat_grads = torch.cat([g.view(-1) for g in grads])\n",
        "\n",
        "    hvp = torch.autograd.grad(v @ flat_grads, model.parameters(), retain_graph=True)\n",
        "    hvp_flat = torch.cat([h.view(-1) for h in hvp])\n",
        "\n",
        "    # clipping\n",
        "    hvp_norm = torch.norm(hvp_flat, p=2) # L2 norm\n",
        "    if hvp_norm > max_norm:\n",
        "        hvp_flat = hvp_flat * (max_norm / hvp_norm)\n",
        "\n",
        "    # Debugging: check for explosion\n",
        "    if torch.norm(hvp_flat) > 1e6:\n",
        "        print(f\"\\nExploding values detected in HVP after clipping! Norm: {torch.norm(hvp_flat)}\")\n",
        "\n",
        "    return hvp_flat\n",
        "\n",
        "\n",
        "def lissa_approximation(model, train_dataloader, v, num_samples=5, num_repeats=5, criterion=None):\n",
        "    \"\"\"\n",
        "    Approximates Hessian-inverse-vector product (iHVP) using the stochastic estimation method\n",
        "    explained in https://arxiv.org/pdf/1703.04730 and https://arxiv.org/pdf/1602.03943\n",
        "\n",
        "    Parameters:\n",
        "    - model: Pre-trained model\n",
        "    - train_dataloader: Dataloader for training data\n",
        "    - v: Gradient vector\n",
        "    - damping: Damping factor for stabilization\n",
        "    - num_samples: Number of training points (t) to sample per iteration\n",
        "    - num_iter: Number of Taylor approximation iterations\n",
        "    - num_repeats: Number of times to repeat estimation to reduce variance (r)\n",
        "\n",
        "    Returns:\n",
        "    - Approximate inverse Hessian-vector product (iHVP)\n",
        "    \"\"\"\n",
        "    ihvp_estimates = []\n",
        "\n",
        "    for i in range(num_repeats):\n",
        "        # H^{-1}_0 v = v\n",
        "        print(f\"Repeat {i+1}/{num_repeats}\")\n",
        "        z = v.clone()\n",
        "\n",
        "        # sampling training points for unbiased estimator\n",
        "        indices = torch.randint(len(train_dataloader.dataset), (num_samples,)).tolist()\n",
        "        sampled_train_data = [train_dataloader.dataset[i] for i in indices]\n",
        "\n",
        "        # taylor approximation\n",
        "        for j in range(num_samples):\n",
        "            print(f\"Iteration {j+1}/{num_samples}\")\n",
        "            train_batch = sampled_train_data[j] # Filtering the sampled train instance\n",
        "            train_input_ids = train_batch['input_ids'].unsqueeze(0).to(device)\n",
        "            train_attention_mask = train_batch['attention_mask'].unsqueeze(0).to(device)\n",
        "            train_label = train_batch['target'].unsqueeze(0).to(device)\n",
        "\n",
        "            # Compute Hessian-gradient product using the sampled loss\n",
        "            train_loss = criterion(\n",
        "                model(train_input_ids, train_attention_mask).view(-1), train_label\n",
        "            )\n",
        "            hvp = compute_hvp(model, train_loss, z)\n",
        "\n",
        "            # update: H_j^{-1} v = v + (I - H) H_{j-1}^{-1} v\n",
        "            z = (v + (z - hvp)).detach()\n",
        "\n",
        "        ihvp_estimates.append(z)\n",
        "\n",
        "    return torch.stack(ihvp_estimates).mean(dim=0)\n",
        "\n",
        "\n",
        "def compute_test_ihvp(model, test_point, test_label, train_dataloader, num_samples=5, num_repeats=5, criterion=None):\n",
        "    \"\"\"\n",
        "    Precomputes the Hessian-inverse-vector product (iHVP) for a test point\n",
        "\n",
        "    Parameters:\n",
        "    - model: Pre-trained model\n",
        "    - test_point: Dictionary containing {'input_ids': tensor, 'attention_mask': tensor}\n",
        "    - test_label: Target label for the test point\n",
        "    - train_dataloader: Dataloader for training data\n",
        "    - num_samples: Number of steps for Taylor approximation (t)\n",
        "    - num_repeats: Number of times to repeat estimation to reduce variance (r)\n",
        "    - criterion: Loss function\n",
        "\n",
        "    Returns:\n",
        "    - Precomputed iHVP for the test point.\n",
        "    \"\"\"\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Compute gradient of test loss w.r.t. model parameters\n",
        "    test_loss = criterion(model(test_point['input_ids'], test_point['attention_mask']).view(-1), test_label)\n",
        "    grad_test = torch.autograd.grad(test_loss, model.parameters(), retain_graph=True)\n",
        "    grad_test_vector = torch.cat([g.view(-1) for g in grad_test])\n",
        "\n",
        "    # Compute Hessian-inverse-vector product using LiSSA\n",
        "    print(\"Computing iHVP...\")\n",
        "    ihvp = lissa_approximation(model, train_dataloader, grad_test_vector, num_samples=num_samples, num_repeats=num_repeats, criterion=criterion)\n",
        "\n",
        "    return ihvp\n",
        "\n",
        "def compute_test_ihvp_all(model, test_dataloader, train_dataloader, num_samples=5, num_repeats=5, criterion=None):\n",
        "    \"\"\"\n",
        "    Precomputes the Hessian-inverse-vector product (iHVP) for a test set\n",
        "\n",
        "    Parameters:\n",
        "    - model: Pre-trained model\n",
        "    - test_loader: Dataloader for test data\n",
        "    - train_dataloader: Dataloader for training data\n",
        "    - num_samples: Number of steps for Taylor approximation (t)\n",
        "    - num_repeats: Number of times to repeat estimation to reduce variance (r)\n",
        "    - criterion: Loss function\n",
        "\n",
        "    Returns:\n",
        "    - Precomputed iHVP for the test point.\n",
        "    \"\"\"\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    # compute gradient of test loss w.r.t. model parameters\n",
        "    grad_test_accum = None\n",
        "    num_test_samples = 0\n",
        "    for test_batch in test_dataloader:\n",
        "        test_input_ids = test_batch['input_ids'].to(device)\n",
        "        test_attention_mask = test_batch['attention_mask'].to(device)\n",
        "        test_label = test_batch['target'].to(device)\n",
        "\n",
        "        test_loss = criterion(model(test_input_ids, test_attention_mask).view(-1), test_label)\n",
        "        grad_test = torch.autograd.grad(test_loss, model.parameters(), retain_graph=True)\n",
        "        grad_test_vector = torch.cat([g.view(-1) for g in grad_test])\n",
        "\n",
        "        if grad_test_accum is None:\n",
        "            grad_test_accum = grad_test_vector.clone()\n",
        "        else:\n",
        "            grad_test_accum += grad_test_vector\n",
        "\n",
        "        num_test_samples += test_label.shape[0]\n",
        "    grad_test_vector = grad_test_accum / num_test_samples\n",
        "\n",
        "    # Compute Hessian-inverse-vector product using LiSSA\n",
        "    print(\"Computing iHVP...\")\n",
        "    ihvp = lissa_approximation(model, train_dataloader, grad_test_vector, num_samples=num_samples, num_repeats=num_repeats, criterion=criterion)\n",
        "\n",
        "    return ihvp\n",
        "\n",
        "def influence_by_train_point(train_point, train_label, ihvp, model, criterion):\n",
        "    \"\"\"\n",
        "    Computes the influence of a training point using the precomputed iHVP for test\n",
        "\n",
        "    Parameters:\n",
        "    - train_point: Dictionary containing {'input_ids': tensor, 'attention_mask': tensor}\n",
        "    - train_label: Target label for the training point\n",
        "    - ihvp: Precomputed Hessian-inverse-vector product (iHVP) for test\n",
        "    - model: Pre-trained model\n",
        "    - criterion: Loss function (MSELoss)\n",
        "\n",
        "    Returns:\n",
        "    - Influence of the training point\n",
        "    \"\"\"\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Compute gradient of training loss w.r.t. model parameters\n",
        "    train_loss = criterion(model(train_point['input_ids'], train_point['attention_mask']).view(-1), train_label)\n",
        "    grad_train = torch.autograd.grad(train_loss, model.parameters(), retain_graph=True)\n",
        "    grad_train_vector = torch.cat([g.view(-1) for g in grad_train])\n",
        "\n",
        "    # Compute influence using dot product\n",
        "    influence = - (torch.dot(ihvp, grad_train_vector))\n",
        "\n",
        "    return influence"
      ],
      "metadata": {
        "id": "KhuXtwjV90jJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up Model and Data"
      ],
      "metadata": {
        "id": "LIyuEsZ4-JoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"ibm/MoLFormer-XL-both-10pct\"  #MoLFormer model\n",
        "DATASET_PATH = \"scikit-fingerprints/MoleculeNet_Lipophilicity\"\n",
        "\n",
        "# load pre-trained model from HuggingFace\n",
        "model = AutoModel.from_pretrained(MODEL_NAME, deterministic_eval=True, trust_remote_code=True)\n",
        "\n",
        "# load the fine-tuned masked model from task-1\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "mlm_finetuned_model = AutoModel.from_pretrained(\"./mlm_finetuned_model\", local_files_only=True, trust_remote_code=True).to(device) # fine tuned model\n",
        "mlm_regression_model = MoLFormerWithRegressionHead(mlm_finetuned_model).to(device) # initialize with regression head\n",
        "# reset the path to git repo\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())\n",
        "\n",
        "# load dataset\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "dataset = load_dataset(DATASET_PATH)\n",
        "\n",
        "# loading external dataset\n",
        "ext_data = pd.read_csv(\"./tasks/External-Dataset_for_Task2.csv\")\n",
        "ext_data = ext_data.rename(columns={\"Label\": \"label\"}) # making column names consistent\n",
        "ext_dataset = HF_Dataset.from_pandas(ext_data)\n",
        "ext_dataset = ext_dataset.remove_columns([\"__index__\"]) if \"__index__\" in ext_dataset.column_names else ext_dataset\n",
        "\n",
        "# train-test-val split\n",
        "split_dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42) # 80:20\n",
        "train_valid_dataset = split_dataset[\"train\"]\n",
        "test_dataset = split_dataset[\"test\"]\n",
        "split_train_valid = train_valid_dataset.train_test_split(test_size=0.1, seed=42) # 90:10\n",
        "train_dataset = split_train_valid[\"train\"]\n",
        "valid_dataset = split_train_valid[\"test\"]\n",
        "combined_train = concatenate_datasets([train_dataset, ext_dataset])\n",
        "\n",
        "# create dataset and dataloader\n",
        "train_dataset = SMILESDataset(train_dataset, tokenizer, max_length=128)\n",
        "valid_dataset = SMILESDataset(valid_dataset, tokenizer, max_length=128)\n",
        "test_dataset  = SMILESDataset(test_dataset, tokenizer, max_length=128)\n",
        "ext_dataset = SMILESDataset(ext_dataset, tokenizer, max_length=128)\n",
        "combined_train = SMILESDataset(combined_train, tokenizer, max_length=128)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
        "test_dataloader  = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "test_single_dataloader  = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "combined_train_dataloader = DataLoader(combined_train, batch_size=16, shuffle=True)\n",
        "# ext_train_dataloader = DataLoader(ext_dataset, batch_size=16, shuffle=False) # for training the model - batch size 16\n",
        "ext_influence_dataloader = DataLoader(ext_dataset, batch_size=1, shuffle=False) # for determing influence of each train points - batch size 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4op_LO4_-Isx",
        "outputId": "90ab2d9a-e00e-4a39-bede-51673dd90507"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nnti-project-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Xy4ghiO3BOyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS_reg = 200\n",
        "LEARNING_RATE_reg = 1e-7\n",
        "patience = 5\n",
        "epochs_no_improve = 0\n",
        "best_valid_loss = float(\"inf\")\n",
        "optimizer_reg = torch.optim.Adam(mlm_regression_model.parameters(), lr=LEARNING_RATE_reg)\n",
        "loss_fn = nn.MSELoss()\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "\n",
        "for epoch in range(EPOCHS_reg):\n",
        "    mlm_regression_model.train()\n",
        "    total_train_loss = 0.0\n",
        "\n",
        "    # training with combined set\n",
        "    for batch in combined_train_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        mask = batch['attention_mask'].to(device)\n",
        "        targets = batch['target'].to(device)\n",
        "\n",
        "        optimizer_reg.zero_grad()\n",
        "        outputs = mlm_regression_model(input_ids, mask)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer_reg.step()\n",
        "\n",
        "        total_train_loss += loss.item() * input_ids.size(0)\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataset)\n",
        "    print(f\"Epoch {epoch+1} - Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # validation\n",
        "    mlm_regression_model.eval()\n",
        "    total_valid_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in valid_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            mask = batch['attention_mask'].to(device)\n",
        "            targets = batch['target'].to(device)\n",
        "            outputs = mlm_regression_model(input_ids, mask)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            total_valid_loss += loss.item() * input_ids.size(0)\n",
        "\n",
        "    avg_valid_loss = total_valid_loss / len(valid_dataset)\n",
        "    print(f\"Epoch {epoch+1} - Validation Loss: {avg_valid_loss:.4f}\")\n",
        "\n",
        "    # early stop check\n",
        "    if avg_valid_loss < best_valid_loss:\n",
        "        best_valid_loss = avg_valid_loss\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(mlm_regression_model.state_dict(), \"best_mlm_regression_model.pth\")\n",
        "        print(\"Validation loss improved, model saved.\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"No improvement for {epochs_no_improve} consecutive epochs.\")\n",
        "    if epochs_no_improve >= patience:\n",
        "        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "        break\n",
        "\n",
        "    # saving model after each 5 epoch\n",
        "    if (epoch+1) % 10 == 0:\n",
        "      save_path = f\"mlm_regression_model_ckp_{epoch+1}.pth\"\n",
        "      torch.save(mlm_regression_model.state_dict(), save_path)\n",
        "      print(f\"Model saved at {save_path}\")\n",
        "\n",
        "# reset the path to git repo\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP7NStZ1BUEc",
        "outputId": "722f20de-f71a-49b1-b46e-aed9f02809e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Train Loss: 7.3085\n",
            "Epoch 1 - Validation Loss: 6.3140\n",
            "Validation loss improved, model saved.\n",
            "Epoch 2 - Train Loss: 6.0983\n",
            "Epoch 2 - Validation Loss: 5.3792\n",
            "Validation loss improved, model saved.\n",
            "Epoch 3 - Train Loss: 5.0745\n",
            "Epoch 3 - Validation Loss: 4.3145\n",
            "Validation loss improved, model saved.\n",
            "Epoch 4 - Train Loss: 4.1745\n",
            "Epoch 4 - Validation Loss: 3.4567\n",
            "Validation loss improved, model saved.\n",
            "Epoch 5 - Train Loss: 3.4033\n",
            "Epoch 5 - Validation Loss: 2.8227\n",
            "Validation loss improved, model saved.\n",
            "Epoch 6 - Train Loss: 2.8089\n",
            "Epoch 6 - Validation Loss: 2.2587\n",
            "Validation loss improved, model saved.\n",
            "Epoch 7 - Train Loss: 2.3321\n",
            "Epoch 7 - Validation Loss: 1.8646\n",
            "Validation loss improved, model saved.\n",
            "Epoch 8 - Train Loss: 2.0165\n",
            "Epoch 8 - Validation Loss: 1.6263\n",
            "Validation loss improved, model saved.\n",
            "Epoch 9 - Train Loss: 1.8016\n",
            "Epoch 9 - Validation Loss: 1.4502\n",
            "Validation loss improved, model saved.\n",
            "Epoch 10 - Train Loss: 1.6947\n",
            "Epoch 10 - Validation Loss: 1.4168\n",
            "Validation loss improved, model saved.\n",
            "Model saved at mlm_regression_model_ckp_10.pth\n",
            "Epoch 11 - Train Loss: 1.6282\n",
            "Epoch 11 - Validation Loss: 1.3837\n",
            "Validation loss improved, model saved.\n",
            "Epoch 12 - Train Loss: 1.5847\n",
            "Epoch 12 - Validation Loss: 1.3914\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 13 - Train Loss: 1.5467\n",
            "Epoch 13 - Validation Loss: 1.3254\n",
            "Validation loss improved, model saved.\n",
            "Epoch 14 - Train Loss: 1.5191\n",
            "Epoch 14 - Validation Loss: 1.3149\n",
            "Validation loss improved, model saved.\n",
            "Epoch 15 - Train Loss: 1.5082\n",
            "Epoch 15 - Validation Loss: 1.2815\n",
            "Validation loss improved, model saved.\n",
            "Epoch 16 - Train Loss: 1.4699\n",
            "Epoch 16 - Validation Loss: 1.2914\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 17 - Train Loss: 1.4707\n",
            "Epoch 17 - Validation Loss: 1.2595\n",
            "Validation loss improved, model saved.\n",
            "Epoch 18 - Train Loss: 1.4247\n",
            "Epoch 18 - Validation Loss: 1.2483\n",
            "Validation loss improved, model saved.\n",
            "Epoch 19 - Train Loss: 1.4304\n",
            "Epoch 19 - Validation Loss: 1.2033\n",
            "Validation loss improved, model saved.\n",
            "Epoch 20 - Train Loss: 1.4078\n",
            "Epoch 20 - Validation Loss: 1.2016\n",
            "Validation loss improved, model saved.\n",
            "Model saved at mlm_regression_model_ckp_20.pth\n",
            "Epoch 21 - Train Loss: 1.4023\n",
            "Epoch 21 - Validation Loss: 1.1977\n",
            "Validation loss improved, model saved.\n",
            "Epoch 22 - Train Loss: 1.3767\n",
            "Epoch 22 - Validation Loss: 1.1879\n",
            "Validation loss improved, model saved.\n",
            "Epoch 23 - Train Loss: 1.3636\n",
            "Epoch 23 - Validation Loss: 1.1766\n",
            "Validation loss improved, model saved.\n",
            "Epoch 24 - Train Loss: 1.3702\n",
            "Epoch 24 - Validation Loss: 1.1571\n",
            "Validation loss improved, model saved.\n",
            "Epoch 25 - Train Loss: 1.3526\n",
            "Epoch 25 - Validation Loss: 1.1491\n",
            "Validation loss improved, model saved.\n",
            "Epoch 26 - Train Loss: 1.3308\n",
            "Epoch 26 - Validation Loss: 1.1464\n",
            "Validation loss improved, model saved.\n",
            "Epoch 27 - Train Loss: 1.3326\n",
            "Epoch 27 - Validation Loss: 1.1342\n",
            "Validation loss improved, model saved.\n",
            "Epoch 28 - Train Loss: 1.3343\n",
            "Epoch 28 - Validation Loss: 1.1332\n",
            "Validation loss improved, model saved.\n",
            "Epoch 29 - Train Loss: 1.2963\n",
            "Epoch 29 - Validation Loss: 1.1185\n",
            "Validation loss improved, model saved.\n",
            "Epoch 30 - Train Loss: 1.3085\n",
            "Epoch 30 - Validation Loss: 1.1061\n",
            "Validation loss improved, model saved.\n",
            "Model saved at mlm_regression_model_ckp_30.pth\n",
            "Epoch 31 - Train Loss: 1.2774\n",
            "Epoch 31 - Validation Loss: 1.1025\n",
            "Validation loss improved, model saved.\n",
            "Epoch 32 - Train Loss: 1.2663\n",
            "Epoch 32 - Validation Loss: 1.0784\n",
            "Validation loss improved, model saved.\n",
            "Epoch 33 - Train Loss: 1.2522\n",
            "Epoch 33 - Validation Loss: 1.0769\n",
            "Validation loss improved, model saved.\n",
            "Epoch 34 - Train Loss: 1.2677\n",
            "Epoch 34 - Validation Loss: 1.0542\n",
            "Validation loss improved, model saved.\n",
            "Epoch 35 - Train Loss: 1.2396\n",
            "Epoch 35 - Validation Loss: 1.0540\n",
            "Validation loss improved, model saved.\n",
            "Epoch 36 - Train Loss: 1.2181\n",
            "Epoch 36 - Validation Loss: 1.0470\n",
            "Validation loss improved, model saved.\n",
            "Epoch 37 - Train Loss: 1.2197\n",
            "Epoch 37 - Validation Loss: 1.0493\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 38 - Train Loss: 1.2219\n",
            "Epoch 38 - Validation Loss: 1.0424\n",
            "Validation loss improved, model saved.\n",
            "Epoch 39 - Train Loss: 1.1965\n",
            "Epoch 39 - Validation Loss: 1.0405\n",
            "Validation loss improved, model saved.\n",
            "Epoch 40 - Train Loss: 1.2231\n",
            "Epoch 40 - Validation Loss: 1.0299\n",
            "Validation loss improved, model saved.\n",
            "Model saved at mlm_regression_model_ckp_40.pth\n",
            "Epoch 41 - Train Loss: 1.1997\n",
            "Epoch 41 - Validation Loss: 1.0018\n",
            "Validation loss improved, model saved.\n",
            "Epoch 42 - Train Loss: 1.1866\n",
            "Epoch 42 - Validation Loss: 0.9980\n",
            "Validation loss improved, model saved.\n",
            "Epoch 43 - Train Loss: 1.1783\n",
            "Epoch 43 - Validation Loss: 1.0108\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 44 - Train Loss: 1.1917\n",
            "Epoch 44 - Validation Loss: 0.9937\n",
            "Validation loss improved, model saved.\n",
            "Epoch 45 - Train Loss: 1.1676\n",
            "Epoch 45 - Validation Loss: 1.0084\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 46 - Train Loss: 1.1659\n",
            "Epoch 46 - Validation Loss: 1.0057\n",
            "No improvement for 2 consecutive epochs.\n",
            "Epoch 47 - Train Loss: 1.1619\n",
            "Epoch 47 - Validation Loss: 0.9849\n",
            "Validation loss improved, model saved.\n",
            "Epoch 48 - Train Loss: 1.1540\n",
            "Epoch 48 - Validation Loss: 0.9884\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 49 - Train Loss: 1.1464\n",
            "Epoch 49 - Validation Loss: 0.9529\n",
            "Validation loss improved, model saved.\n",
            "Epoch 50 - Train Loss: 1.1470\n",
            "Epoch 50 - Validation Loss: 0.9704\n",
            "No improvement for 1 consecutive epochs.\n",
            "Model saved at mlm_regression_model_ckp_50.pth\n",
            "Epoch 51 - Train Loss: 1.1181\n",
            "Epoch 51 - Validation Loss: 0.9585\n",
            "No improvement for 2 consecutive epochs.\n",
            "Epoch 52 - Train Loss: 1.1120\n",
            "Epoch 52 - Validation Loss: 0.9675\n",
            "No improvement for 3 consecutive epochs.\n",
            "Epoch 53 - Train Loss: 1.1102\n",
            "Epoch 53 - Validation Loss: 0.9694\n",
            "No improvement for 4 consecutive epochs.\n",
            "Epoch 54 - Train Loss: 1.1029\n",
            "Epoch 54 - Validation Loss: 0.9636\n",
            "No improvement for 5 consecutive epochs.\n",
            "Early stopping triggered after 54 epochs.\n",
            "/content/nnti-project-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Regression Model"
      ],
      "metadata": {
        "id": "tq7Lr1-BBOvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "influences = []\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# loading pre-trained mlm regression model\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "mlm_regression_model = MoLFormerWithRegressionHead(mlm_finetuned_model).to(device)\n",
        "mlm_regression_model.load_state_dict(torch.load(\"best_mlm_regression_model.pth\"))\n",
        "# reset the path to git repo\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())\n",
        "regression_model = mlm_regression_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5svjW8eJBQ07",
        "outputId": "0abd3317-8d51-4660-ecfd-9c1f2e712010"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-dec9dcce555b>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  mlm_regression_model.load_state_dict(torch.load(\"best_mlm_regression_model.pth\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nnti-project-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computing IHVP for Test"
      ],
      "metadata": {
        "id": "X6A5CJQ6CuYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing iHVP for each test point\n",
        "test_ihvps = []\n",
        "start_idx = 10\n",
        "end_idx = 12\n",
        "sliced_dataloader = islice(test_single_dataloader, start_idx, end_idx)\n",
        "# flag_count = 0\n",
        "for _, test_batch in enumerate(sliced_dataloader, start=start_idx):\n",
        "    print(f\"Processing test sample {len(test_ihvps) + 1}/{(end_idx - start_idx)}\")\n",
        "    test_input_ids = test_batch['input_ids'].to(device)\n",
        "    test_attention_mask = test_batch['attention_mask'].to(device)\n",
        "    test_label = test_batch['target'].to(device)\n",
        "    test_point = {'input_ids': test_input_ids, 'attention_mask': test_attention_mask}\n",
        "\n",
        "    ihvp = compute_test_ihvp(regression_model, test_point, test_label, combined_train_dataloader,\n",
        "                             num_samples=300, num_repeats=5, criterion=criterion)\n",
        "    test_ihvps.append(ihvp)\n",
        "    # flag_count += 1\n",
        "    # if flag_count == 2:\n",
        "    #   break\n",
        "\n",
        "# Save the iHVP\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "torch.save(test_ihvps, f\"test_ihvps_{start_idx}_{end_idx}.pt\")\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cChDtCabCQIo",
        "outputId": "beb14949-437f-4742-9270-dca82d620151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing test sample 1/2\n",
            "Computing iHVP...\n",
            "Repeat 1/5\n",
            "Iteration 1/300\n",
            "Iteration 2/300\n",
            "Iteration 3/300\n",
            "Iteration 4/300\n",
            "Iteration 5/300\n",
            "Iteration 6/300\n",
            "Iteration 7/300\n",
            "Iteration 8/300\n",
            "Iteration 9/300\n",
            "Iteration 10/300\n",
            "Iteration 11/300\n",
            "Iteration 12/300\n",
            "Iteration 13/300\n",
            "Iteration 14/300\n",
            "Iteration 15/300\n",
            "Iteration 16/300\n",
            "Iteration 17/300\n",
            "Iteration 18/300\n",
            "Iteration 19/300\n",
            "Iteration 20/300\n",
            "Iteration 21/300\n",
            "Iteration 22/300\n",
            "Iteration 23/300\n",
            "Iteration 24/300\n",
            "Iteration 25/300\n",
            "Iteration 26/300\n",
            "Iteration 27/300\n",
            "Iteration 28/300\n",
            "Iteration 29/300\n",
            "Iteration 30/300\n",
            "Iteration 31/300\n",
            "Iteration 32/300\n",
            "Iteration 33/300\n",
            "Iteration 34/300\n",
            "Iteration 35/300\n",
            "Iteration 36/300\n",
            "Iteration 37/300\n",
            "Iteration 38/300\n",
            "Iteration 39/300\n",
            "Iteration 40/300\n",
            "Iteration 41/300\n",
            "Iteration 42/300\n",
            "Iteration 43/300\n",
            "Iteration 44/300\n",
            "Iteration 45/300\n",
            "Iteration 46/300\n",
            "Iteration 47/300\n",
            "Iteration 48/300\n",
            "Iteration 49/300\n",
            "Iteration 50/300\n",
            "Iteration 51/300\n",
            "Iteration 52/300\n",
            "Iteration 53/300\n",
            "Iteration 54/300\n",
            "Iteration 55/300\n",
            "Iteration 56/300\n",
            "Iteration 57/300\n",
            "Iteration 58/300\n",
            "Iteration 59/300\n",
            "Iteration 60/300\n",
            "Iteration 61/300\n",
            "Iteration 62/300\n",
            "Iteration 63/300\n",
            "Iteration 64/300\n",
            "Iteration 65/300\n",
            "Iteration 66/300\n",
            "Iteration 67/300\n",
            "Iteration 68/300\n",
            "Iteration 69/300\n",
            "Iteration 70/300\n",
            "Iteration 71/300\n",
            "Iteration 72/300\n",
            "Iteration 73/300\n",
            "Iteration 74/300\n",
            "Iteration 75/300\n",
            "Iteration 76/300\n",
            "Iteration 77/300\n",
            "Iteration 78/300\n",
            "Iteration 79/300\n",
            "Iteration 80/300\n",
            "Iteration 81/300\n",
            "Iteration 82/300\n",
            "Iteration 83/300\n",
            "Iteration 84/300\n",
            "Iteration 85/300\n",
            "Iteration 86/300\n",
            "Iteration 87/300\n",
            "Iteration 88/300\n",
            "Iteration 89/300\n",
            "Iteration 90/300\n",
            "Iteration 91/300\n",
            "Iteration 92/300\n",
            "Iteration 93/300\n",
            "Iteration 94/300\n",
            "Iteration 95/300\n",
            "Iteration 96/300\n",
            "Iteration 97/300\n",
            "Iteration 98/300\n",
            "Iteration 99/300\n",
            "Iteration 100/300\n",
            "Iteration 101/300\n",
            "Iteration 102/300\n",
            "Iteration 103/300\n",
            "Iteration 104/300\n",
            "Iteration 105/300\n",
            "Iteration 106/300\n",
            "Iteration 107/300\n",
            "Iteration 108/300\n",
            "Iteration 109/300\n",
            "Iteration 110/300\n",
            "Iteration 111/300\n",
            "Iteration 112/300\n",
            "Iteration 113/300\n",
            "Iteration 114/300\n",
            "Iteration 115/300\n",
            "Iteration 116/300\n",
            "Iteration 117/300\n",
            "Iteration 118/300\n",
            "Iteration 119/300\n",
            "Iteration 120/300\n",
            "Iteration 121/300\n",
            "Iteration 122/300\n",
            "Iteration 123/300\n",
            "Iteration 124/300\n",
            "Iteration 125/300\n",
            "Iteration 126/300\n",
            "Iteration 127/300\n",
            "Iteration 128/300\n",
            "Iteration 129/300\n",
            "Iteration 130/300\n",
            "Iteration 131/300\n",
            "Iteration 132/300\n",
            "Iteration 133/300\n",
            "Iteration 134/300\n",
            "Iteration 135/300\n",
            "Iteration 136/300\n",
            "Iteration 137/300\n",
            "Iteration 138/300\n",
            "Iteration 139/300\n",
            "Iteration 140/300\n",
            "Iteration 141/300\n",
            "Iteration 142/300\n",
            "Iteration 143/300\n",
            "Iteration 144/300\n",
            "Iteration 145/300\n",
            "Iteration 146/300\n",
            "Iteration 147/300\n",
            "Iteration 148/300\n",
            "Iteration 149/300\n",
            "Iteration 150/300\n",
            "Iteration 151/300\n",
            "Iteration 152/300\n",
            "Iteration 153/300\n",
            "Iteration 154/300\n",
            "Iteration 155/300\n",
            "Iteration 156/300\n",
            "Iteration 157/300\n",
            "Iteration 158/300\n",
            "Iteration 159/300\n",
            "Iteration 160/300\n",
            "Iteration 161/300\n",
            "Iteration 162/300\n",
            "Iteration 163/300\n",
            "Iteration 164/300\n",
            "Iteration 165/300\n",
            "Iteration 166/300\n",
            "Iteration 167/300\n",
            "Iteration 168/300\n",
            "Iteration 169/300\n",
            "Iteration 170/300\n",
            "Iteration 171/300\n",
            "Iteration 172/300\n",
            "Iteration 173/300\n",
            "Iteration 174/300\n",
            "Iteration 175/300\n",
            "Iteration 176/300\n",
            "Iteration 177/300\n",
            "Iteration 178/300\n",
            "Iteration 179/300\n",
            "Iteration 180/300\n",
            "Iteration 181/300\n",
            "Iteration 182/300\n",
            "Iteration 183/300\n",
            "Iteration 184/300\n",
            "Iteration 185/300\n",
            "Iteration 186/300\n",
            "Iteration 187/300\n",
            "Iteration 188/300\n",
            "Iteration 189/300\n",
            "Iteration 190/300\n",
            "Iteration 191/300\n",
            "Iteration 192/300\n",
            "Iteration 193/300\n",
            "Iteration 194/300\n",
            "Iteration 195/300\n",
            "Iteration 196/300\n",
            "Iteration 197/300\n",
            "Iteration 198/300\n",
            "Iteration 199/300\n",
            "Iteration 200/300\n",
            "Iteration 201/300\n",
            "Iteration 202/300\n",
            "Iteration 203/300\n",
            "Iteration 204/300\n",
            "Iteration 205/300\n",
            "Iteration 206/300\n",
            "Iteration 207/300\n",
            "Iteration 208/300\n",
            "Iteration 209/300\n",
            "Iteration 210/300\n",
            "Iteration 211/300\n",
            "Iteration 212/300\n",
            "Iteration 213/300\n",
            "Iteration 214/300\n",
            "Iteration 215/300\n",
            "Iteration 216/300\n",
            "Iteration 217/300\n",
            "Iteration 218/300\n",
            "Iteration 219/300\n",
            "Iteration 220/300\n",
            "Iteration 221/300\n",
            "Iteration 222/300\n",
            "Iteration 223/300\n",
            "Iteration 224/300\n",
            "Iteration 225/300\n",
            "Iteration 226/300\n",
            "Iteration 227/300\n",
            "Iteration 228/300\n",
            "Iteration 229/300\n",
            "Iteration 230/300\n",
            "Iteration 231/300\n",
            "Iteration 232/300\n",
            "Iteration 233/300\n",
            "Iteration 234/300\n",
            "Iteration 235/300\n",
            "Iteration 236/300\n",
            "Iteration 237/300\n",
            "Iteration 238/300\n",
            "Iteration 239/300\n",
            "Iteration 240/300\n",
            "Iteration 241/300\n",
            "Iteration 242/300\n",
            "Iteration 243/300\n",
            "Iteration 244/300\n",
            "Iteration 245/300\n",
            "Iteration 246/300\n",
            "Iteration 247/300\n",
            "Iteration 248/300\n",
            "Iteration 249/300\n",
            "Iteration 250/300\n",
            "Iteration 251/300\n",
            "Iteration 252/300\n",
            "Iteration 253/300\n",
            "Iteration 254/300\n",
            "Iteration 255/300\n",
            "Iteration 256/300\n",
            "Iteration 257/300\n",
            "Iteration 258/300\n",
            "Iteration 259/300\n",
            "Iteration 260/300\n",
            "Iteration 261/300\n",
            "Iteration 262/300\n",
            "Iteration 263/300\n",
            "Iteration 264/300\n",
            "Iteration 265/300\n",
            "Iteration 266/300\n",
            "Iteration 267/300\n",
            "Iteration 268/300\n",
            "Iteration 269/300\n",
            "Iteration 270/300\n",
            "Iteration 271/300\n",
            "Iteration 272/300\n",
            "Iteration 273/300\n",
            "Iteration 274/300\n",
            "Iteration 275/300\n",
            "Iteration 276/300\n",
            "Iteration 277/300\n",
            "Iteration 278/300\n",
            "Iteration 279/300\n",
            "Iteration 280/300\n",
            "Iteration 281/300\n",
            "Iteration 282/300\n",
            "Iteration 283/300\n",
            "Iteration 284/300\n",
            "Iteration 285/300\n",
            "Iteration 286/300\n",
            "Iteration 287/300\n",
            "Iteration 288/300\n",
            "Iteration 289/300\n",
            "Iteration 290/300\n",
            "Iteration 291/300\n",
            "Iteration 292/300\n",
            "Iteration 293/300\n",
            "Iteration 294/300\n",
            "Iteration 295/300\n",
            "Iteration 296/300\n",
            "Iteration 297/300\n",
            "Iteration 298/300\n",
            "Iteration 299/300\n",
            "Iteration 300/300\n",
            "Repeat 2/5\n",
            "Iteration 1/300\n",
            "Iteration 2/300\n",
            "Iteration 3/300\n",
            "Iteration 4/300\n",
            "Iteration 5/300\n",
            "Iteration 6/300\n",
            "Iteration 7/300\n",
            "Iteration 8/300\n",
            "Iteration 9/300\n",
            "Iteration 10/300\n",
            "Iteration 11/300\n",
            "Iteration 12/300\n",
            "Iteration 13/300\n",
            "Iteration 14/300\n",
            "Iteration 15/300\n",
            "Iteration 16/300\n",
            "Iteration 17/300\n",
            "Iteration 18/300\n",
            "Iteration 19/300\n",
            "Iteration 20/300\n",
            "Iteration 21/300\n",
            "Iteration 22/300\n",
            "Iteration 23/300\n",
            "Iteration 24/300\n",
            "Iteration 25/300\n",
            "Iteration 26/300\n",
            "Iteration 27/300\n",
            "Iteration 28/300\n",
            "Iteration 29/300\n",
            "Iteration 30/300\n",
            "Iteration 31/300\n",
            "Iteration 32/300\n",
            "Iteration 33/300\n",
            "Iteration 34/300\n",
            "Iteration 35/300\n",
            "Iteration 36/300\n",
            "Iteration 37/300\n",
            "Iteration 38/300\n",
            "Iteration 39/300\n",
            "Iteration 40/300\n",
            "Iteration 41/300\n",
            "Iteration 42/300\n",
            "Iteration 43/300\n",
            "Iteration 44/300\n",
            "Iteration 45/300\n",
            "Iteration 46/300\n",
            "Iteration 47/300\n",
            "Iteration 48/300\n",
            "Iteration 49/300\n",
            "Iteration 50/300\n",
            "Iteration 51/300\n",
            "Iteration 52/300\n",
            "Iteration 53/300\n",
            "Iteration 54/300\n",
            "Iteration 55/300\n",
            "Iteration 56/300\n",
            "Iteration 57/300\n",
            "Iteration 58/300\n",
            "Iteration 59/300\n",
            "Iteration 60/300\n",
            "Iteration 61/300\n",
            "Iteration 62/300\n",
            "Iteration 63/300\n",
            "Iteration 64/300\n",
            "Iteration 65/300\n",
            "Iteration 66/300\n",
            "Iteration 67/300\n",
            "Iteration 68/300\n",
            "Iteration 69/300\n",
            "Iteration 70/300\n",
            "Iteration 71/300\n",
            "Iteration 72/300\n",
            "Iteration 73/300\n",
            "Iteration 74/300\n",
            "Iteration 75/300\n",
            "Iteration 76/300\n",
            "Iteration 77/300\n",
            "Iteration 78/300\n",
            "Iteration 79/300\n",
            "Iteration 80/300\n",
            "Iteration 81/300\n",
            "Iteration 82/300\n",
            "Iteration 83/300\n",
            "Iteration 84/300\n",
            "Iteration 85/300\n",
            "Iteration 86/300\n",
            "Iteration 87/300\n",
            "Iteration 88/300\n",
            "Iteration 89/300\n",
            "Iteration 90/300\n",
            "Iteration 91/300\n",
            "Iteration 92/300\n",
            "Iteration 93/300\n",
            "Iteration 94/300\n",
            "Iteration 95/300\n",
            "Iteration 96/300\n",
            "Iteration 97/300\n",
            "Iteration 98/300\n",
            "Iteration 99/300\n",
            "Iteration 100/300\n",
            "Iteration 101/300\n",
            "Iteration 102/300\n",
            "Iteration 103/300\n",
            "Iteration 104/300\n",
            "Iteration 105/300\n",
            "Iteration 106/300\n",
            "Iteration 107/300\n",
            "Iteration 108/300\n",
            "Iteration 109/300\n",
            "Iteration 110/300\n",
            "Iteration 111/300\n",
            "Iteration 112/300\n",
            "Iteration 113/300\n",
            "Iteration 114/300\n",
            "Iteration 115/300\n",
            "Iteration 116/300\n",
            "Iteration 117/300\n",
            "Iteration 118/300\n",
            "Iteration 119/300\n",
            "Iteration 120/300\n",
            "Iteration 121/300\n",
            "Iteration 122/300\n",
            "Iteration 123/300\n",
            "Iteration 124/300\n",
            "Iteration 125/300\n",
            "Iteration 126/300\n",
            "Iteration 127/300\n",
            "Iteration 128/300\n",
            "Iteration 129/300\n",
            "Iteration 130/300\n",
            "Iteration 131/300\n",
            "Iteration 132/300\n",
            "Iteration 133/300\n",
            "Iteration 134/300\n",
            "Iteration 135/300\n",
            "Iteration 136/300\n",
            "Iteration 137/300\n",
            "Iteration 138/300\n",
            "Iteration 139/300\n",
            "Iteration 140/300\n",
            "Iteration 141/300\n",
            "Iteration 142/300\n",
            "Iteration 143/300\n",
            "Iteration 144/300\n",
            "Iteration 145/300\n",
            "Iteration 146/300\n",
            "Iteration 147/300\n",
            "Iteration 148/300\n",
            "Iteration 149/300\n",
            "Iteration 150/300\n",
            "Iteration 151/300\n",
            "Iteration 152/300\n",
            "Iteration 153/300\n",
            "Iteration 154/300\n",
            "Iteration 155/300\n",
            "Iteration 156/300\n",
            "Iteration 157/300\n",
            "Iteration 158/300\n",
            "Iteration 159/300\n",
            "Iteration 160/300\n",
            "Iteration 161/300\n",
            "Iteration 162/300\n",
            "Iteration 163/300\n",
            "Iteration 164/300\n",
            "Iteration 165/300\n",
            "Iteration 166/300\n",
            "Iteration 167/300\n",
            "Iteration 168/300\n",
            "Iteration 169/300\n",
            "Iteration 170/300\n",
            "Iteration 171/300\n",
            "Iteration 172/300\n",
            "Iteration 173/300\n",
            "Iteration 174/300\n",
            "Iteration 175/300\n",
            "Iteration 176/300\n",
            "Iteration 177/300\n",
            "Iteration 178/300\n",
            "Iteration 179/300\n",
            "Iteration 180/300\n",
            "Iteration 181/300\n",
            "Iteration 182/300\n",
            "Iteration 183/300\n",
            "Iteration 184/300\n",
            "Iteration 185/300\n",
            "Iteration 186/300\n",
            "Iteration 187/300\n",
            "Iteration 188/300\n",
            "Iteration 189/300\n",
            "Iteration 190/300\n",
            "Iteration 191/300\n",
            "Iteration 192/300\n",
            "Iteration 193/300\n",
            "Iteration 194/300\n",
            "Iteration 195/300\n",
            "Iteration 196/300\n",
            "Iteration 197/300\n",
            "Iteration 198/300\n",
            "Iteration 199/300\n",
            "Iteration 200/300\n",
            "Iteration 201/300\n",
            "Iteration 202/300\n",
            "Iteration 203/300\n",
            "Iteration 204/300\n",
            "Iteration 205/300\n",
            "Iteration 206/300\n",
            "Iteration 207/300\n",
            "Iteration 208/300\n",
            "Iteration 209/300\n",
            "Iteration 210/300\n",
            "Iteration 211/300\n",
            "Iteration 212/300\n",
            "Iteration 213/300\n",
            "Iteration 214/300\n",
            "Iteration 215/300\n",
            "Iteration 216/300\n",
            "Iteration 217/300\n",
            "Iteration 218/300\n",
            "Iteration 219/300\n",
            "Iteration 220/300\n",
            "Iteration 221/300\n",
            "Iteration 222/300\n",
            "Iteration 223/300\n",
            "Iteration 224/300\n",
            "Iteration 225/300\n",
            "Iteration 226/300\n",
            "Iteration 227/300\n",
            "Iteration 228/300\n",
            "Iteration 229/300\n",
            "Iteration 230/300\n",
            "Iteration 231/300\n",
            "Iteration 232/300\n",
            "Iteration 233/300\n",
            "Iteration 234/300\n",
            "Iteration 235/300\n",
            "Iteration 236/300\n",
            "Iteration 237/300\n",
            "Iteration 238/300\n",
            "Iteration 239/300\n",
            "Iteration 240/300\n",
            "Iteration 241/300\n",
            "Iteration 242/300\n",
            "Iteration 243/300\n",
            "Iteration 244/300\n",
            "Iteration 245/300\n",
            "Iteration 246/300\n",
            "Iteration 247/300\n",
            "Iteration 248/300\n",
            "Iteration 249/300\n",
            "Iteration 250/300\n",
            "Iteration 251/300\n",
            "Iteration 252/300\n",
            "Iteration 253/300\n",
            "Iteration 254/300\n",
            "Iteration 255/300\n",
            "Iteration 256/300\n",
            "Iteration 257/300\n",
            "Iteration 258/300\n",
            "Iteration 259/300\n",
            "Iteration 260/300\n",
            "Iteration 261/300\n",
            "Iteration 262/300\n",
            "Iteration 263/300\n",
            "Iteration 264/300\n",
            "Iteration 265/300\n",
            "Iteration 266/300\n",
            "Iteration 267/300\n",
            "Iteration 268/300\n",
            "Iteration 269/300\n",
            "Iteration 270/300\n",
            "Iteration 271/300\n",
            "Iteration 272/300\n",
            "Iteration 273/300\n",
            "Iteration 274/300\n",
            "Iteration 275/300\n",
            "Iteration 276/300\n",
            "Iteration 277/300\n",
            "Iteration 278/300\n",
            "Iteration 279/300\n",
            "Iteration 280/300\n",
            "Iteration 281/300\n",
            "Iteration 282/300\n",
            "Iteration 283/300\n",
            "Iteration 284/300\n",
            "Iteration 285/300\n",
            "Iteration 286/300\n",
            "Iteration 287/300\n",
            "Iteration 288/300\n",
            "Iteration 289/300\n",
            "Iteration 290/300\n",
            "Iteration 291/300\n",
            "Iteration 292/300\n",
            "Iteration 293/300\n",
            "Iteration 294/300\n",
            "Iteration 295/300\n",
            "Iteration 296/300\n",
            "Iteration 297/300\n",
            "Iteration 298/300\n",
            "Iteration 299/300\n",
            "Iteration 300/300\n",
            "Repeat 3/5\n",
            "Iteration 1/300\n",
            "Iteration 2/300\n",
            "Iteration 3/300\n",
            "Iteration 4/300\n",
            "Iteration 5/300\n",
            "Iteration 6/300\n",
            "Iteration 7/300\n",
            "Iteration 8/300\n",
            "Iteration 9/300\n",
            "Iteration 10/300\n",
            "Iteration 11/300\n",
            "Iteration 12/300\n",
            "Iteration 13/300\n",
            "Iteration 14/300\n",
            "Iteration 15/300\n",
            "Iteration 16/300\n",
            "Iteration 17/300\n",
            "Iteration 18/300\n",
            "Iteration 19/300\n",
            "Iteration 20/300\n",
            "Iteration 21/300\n",
            "Iteration 22/300\n",
            "Iteration 23/300\n",
            "Iteration 24/300\n",
            "Iteration 25/300\n",
            "Iteration 26/300\n",
            "Iteration 27/300\n",
            "Iteration 28/300\n",
            "Iteration 29/300\n",
            "Iteration 30/300\n",
            "Iteration 31/300\n",
            "Iteration 32/300\n",
            "Iteration 33/300\n",
            "Iteration 34/300\n",
            "Iteration 35/300\n",
            "Iteration 36/300\n",
            "Iteration 37/300\n",
            "Iteration 38/300\n",
            "Iteration 39/300\n",
            "Iteration 40/300\n",
            "Iteration 41/300\n",
            "Iteration 42/300\n",
            "Iteration 43/300\n",
            "Iteration 44/300\n",
            "Iteration 45/300\n",
            "Iteration 46/300\n",
            "Iteration 47/300\n",
            "Iteration 48/300\n",
            "Iteration 49/300\n",
            "Iteration 50/300\n",
            "Iteration 51/300\n",
            "Iteration 52/300\n",
            "Iteration 53/300\n",
            "Iteration 54/300\n",
            "Iteration 55/300\n",
            "Iteration 56/300\n",
            "Iteration 57/300\n",
            "Iteration 58/300\n",
            "Iteration 59/300\n",
            "Iteration 60/300\n",
            "Iteration 61/300\n",
            "Iteration 62/300\n",
            "Iteration 63/300\n",
            "Iteration 64/300\n",
            "Iteration 65/300\n",
            "Iteration 66/300\n",
            "Iteration 67/300\n",
            "Iteration 68/300\n",
            "Iteration 69/300\n",
            "Iteration 70/300\n",
            "Iteration 71/300\n",
            "Iteration 72/300\n",
            "Iteration 73/300\n",
            "Iteration 74/300\n",
            "Iteration 75/300\n",
            "Iteration 76/300\n",
            "Iteration 77/300\n",
            "Iteration 78/300\n",
            "Iteration 79/300\n",
            "Iteration 80/300\n",
            "Iteration 81/300\n",
            "Iteration 82/300\n",
            "Iteration 83/300\n",
            "Iteration 84/300\n",
            "Iteration 85/300\n",
            "Iteration 86/300\n",
            "Iteration 87/300\n",
            "Iteration 88/300\n",
            "Iteration 89/300\n",
            "Iteration 90/300\n",
            "Iteration 91/300\n",
            "Iteration 92/300\n",
            "Iteration 93/300\n",
            "Iteration 94/300\n",
            "Iteration 95/300\n",
            "Iteration 96/300\n",
            "Iteration 97/300\n",
            "Iteration 98/300\n",
            "Iteration 99/300\n",
            "Iteration 100/300\n",
            "Iteration 101/300\n",
            "Iteration 102/300\n",
            "Iteration 103/300\n",
            "Iteration 104/300\n",
            "Iteration 105/300\n",
            "Iteration 106/300\n",
            "Iteration 107/300\n",
            "Iteration 108/300\n",
            "Iteration 109/300\n",
            "Iteration 110/300\n",
            "Iteration 111/300\n",
            "Iteration 112/300\n",
            "Iteration 113/300\n",
            "Iteration 114/300\n",
            "Iteration 115/300\n",
            "Iteration 116/300\n",
            "Iteration 117/300\n",
            "Iteration 118/300\n",
            "Iteration 119/300\n",
            "Iteration 120/300\n",
            "Iteration 121/300\n",
            "Iteration 122/300\n",
            "Iteration 123/300\n",
            "Iteration 124/300\n",
            "Iteration 125/300\n",
            "Iteration 126/300\n",
            "Iteration 127/300\n",
            "Iteration 128/300\n",
            "Iteration 129/300\n",
            "Iteration 130/300\n",
            "Iteration 131/300\n",
            "Iteration 132/300\n",
            "Iteration 133/300\n",
            "Iteration 134/300\n",
            "Iteration 135/300\n",
            "Iteration 136/300\n",
            "Iteration 137/300\n",
            "Iteration 138/300\n",
            "Iteration 139/300\n",
            "Iteration 140/300\n",
            "Iteration 141/300\n",
            "Iteration 142/300\n",
            "Iteration 143/300\n",
            "Iteration 144/300\n",
            "Iteration 145/300\n",
            "Iteration 146/300\n",
            "Iteration 147/300\n",
            "Iteration 148/300\n",
            "Iteration 149/300\n",
            "Iteration 150/300\n",
            "Iteration 151/300\n",
            "Iteration 152/300\n",
            "Iteration 153/300\n",
            "Iteration 154/300\n",
            "Iteration 155/300\n",
            "Iteration 156/300\n",
            "Iteration 157/300\n",
            "Iteration 158/300\n",
            "Iteration 159/300\n",
            "Iteration 160/300\n",
            "Iteration 161/300\n",
            "Iteration 162/300\n",
            "Iteration 163/300\n",
            "Iteration 164/300\n",
            "Iteration 165/300\n",
            "Iteration 166/300\n",
            "Iteration 167/300\n",
            "Iteration 168/300\n",
            "Iteration 169/300\n",
            "Iteration 170/300\n",
            "Iteration 171/300\n",
            "Iteration 172/300\n",
            "Iteration 173/300\n",
            "Iteration 174/300\n",
            "Iteration 175/300\n",
            "Iteration 176/300\n",
            "Iteration 177/300\n",
            "Iteration 178/300\n",
            "Iteration 179/300\n",
            "Iteration 180/300\n",
            "Iteration 181/300\n",
            "Iteration 182/300\n",
            "Iteration 183/300\n",
            "Iteration 184/300\n",
            "Iteration 185/300\n",
            "Iteration 186/300\n",
            "Iteration 187/300\n",
            "Iteration 188/300\n",
            "Iteration 189/300\n",
            "Iteration 190/300\n",
            "Iteration 191/300\n",
            "Iteration 192/300\n",
            "Iteration 193/300\n",
            "Iteration 194/300\n",
            "Iteration 195/300\n",
            "Iteration 196/300\n",
            "Iteration 197/300\n",
            "Iteration 198/300\n",
            "Iteration 199/300\n",
            "Iteration 200/300\n",
            "Iteration 201/300\n",
            "Iteration 202/300\n",
            "Iteration 203/300\n",
            "Iteration 204/300\n",
            "Iteration 205/300\n",
            "Iteration 206/300\n",
            "Iteration 207/300\n",
            "Iteration 208/300\n",
            "Iteration 209/300\n",
            "Iteration 210/300\n",
            "Iteration 211/300\n",
            "Iteration 212/300\n",
            "Iteration 213/300\n",
            "Iteration 214/300\n",
            "Iteration 215/300\n",
            "Iteration 216/300\n",
            "Iteration 217/300\n",
            "Iteration 218/300\n",
            "Iteration 219/300\n",
            "Iteration 220/300\n",
            "Iteration 221/300\n",
            "Iteration 222/300\n",
            "Iteration 223/300\n",
            "Iteration 224/300\n",
            "Iteration 225/300\n",
            "Iteration 226/300\n",
            "Iteration 227/300\n",
            "Iteration 228/300\n",
            "Iteration 229/300\n",
            "Iteration 230/300\n",
            "Iteration 231/300\n",
            "Iteration 232/300\n",
            "Iteration 233/300\n",
            "Iteration 234/300\n",
            "Iteration 235/300\n",
            "Iteration 236/300\n",
            "Iteration 237/300\n",
            "Iteration 238/300\n",
            "Iteration 239/300\n",
            "Iteration 240/300\n",
            "Iteration 241/300\n",
            "Iteration 242/300\n",
            "Iteration 243/300\n",
            "Iteration 244/300\n",
            "Iteration 245/300\n",
            "Iteration 246/300\n",
            "Iteration 247/300\n",
            "Iteration 248/300\n",
            "Iteration 249/300\n",
            "Iteration 250/300\n",
            "Iteration 251/300\n",
            "Iteration 252/300\n",
            "Iteration 253/300\n",
            "Iteration 254/300\n",
            "Iteration 255/300\n",
            "Iteration 256/300\n",
            "Iteration 257/300\n",
            "Iteration 258/300\n",
            "Iteration 259/300\n",
            "Iteration 260/300\n",
            "Iteration 261/300\n",
            "Iteration 262/300\n",
            "Iteration 263/300\n",
            "Iteration 264/300\n",
            "Iteration 265/300\n",
            "Iteration 266/300\n",
            "Iteration 267/300\n",
            "Iteration 268/300\n",
            "Iteration 269/300\n",
            "Iteration 270/300\n",
            "Iteration 271/300\n",
            "Iteration 272/300\n",
            "Iteration 273/300\n",
            "Iteration 274/300\n",
            "Iteration 275/300\n",
            "Iteration 276/300\n",
            "Iteration 277/300\n",
            "Iteration 278/300\n",
            "Iteration 279/300\n",
            "Iteration 280/300\n",
            "Iteration 281/300\n",
            "Iteration 282/300\n",
            "Iteration 283/300\n",
            "Iteration 284/300\n",
            "Iteration 285/300\n",
            "Iteration 286/300\n",
            "Iteration 287/300\n",
            "Iteration 288/300\n",
            "Iteration 289/300\n",
            "Iteration 290/300\n",
            "Iteration 291/300\n",
            "Iteration 292/300\n",
            "Iteration 293/300\n",
            "Iteration 294/300\n",
            "Iteration 295/300\n",
            "Iteration 296/300\n",
            "Iteration 297/300\n",
            "Iteration 298/300\n",
            "Iteration 299/300\n",
            "Iteration 300/300\n",
            "Repeat 4/5\n",
            "Iteration 1/300\n",
            "Iteration 2/300\n",
            "Iteration 3/300\n",
            "Iteration 4/300\n",
            "Iteration 5/300\n",
            "Iteration 6/300\n",
            "Iteration 7/300\n",
            "Iteration 8/300\n",
            "Iteration 9/300\n",
            "Iteration 10/300\n",
            "Iteration 11/300\n",
            "Iteration 12/300\n",
            "Iteration 13/300\n",
            "Iteration 14/300\n",
            "Iteration 15/300\n",
            "Iteration 16/300\n",
            "Iteration 17/300\n",
            "Iteration 18/300\n",
            "Iteration 19/300\n",
            "Iteration 20/300\n",
            "Iteration 21/300\n",
            "Iteration 22/300\n",
            "Iteration 23/300\n",
            "Iteration 24/300\n",
            "Iteration 25/300\n",
            "Iteration 26/300\n",
            "Iteration 27/300\n",
            "Iteration 28/300\n",
            "Iteration 29/300\n",
            "Iteration 30/300\n",
            "Iteration 31/300\n",
            "Iteration 32/300\n",
            "Iteration 33/300\n",
            "Iteration 34/300\n",
            "Iteration 35/300\n",
            "Iteration 36/300\n",
            "Iteration 37/300\n",
            "Iteration 38/300\n",
            "Iteration 39/300\n",
            "Iteration 40/300\n",
            "Iteration 41/300\n",
            "Iteration 42/300\n",
            "Iteration 43/300\n",
            "Iteration 44/300\n",
            "Iteration 45/300\n",
            "Iteration 46/300\n",
            "Iteration 47/300\n",
            "Iteration 48/300\n",
            "Iteration 49/300\n",
            "Iteration 50/300\n",
            "Iteration 51/300\n",
            "Iteration 52/300\n",
            "Iteration 53/300\n",
            "Iteration 54/300\n",
            "Iteration 55/300\n",
            "Iteration 56/300\n",
            "Iteration 57/300\n",
            "Iteration 58/300\n",
            "Iteration 59/300\n",
            "Iteration 60/300\n",
            "Iteration 61/300\n",
            "Iteration 62/300\n",
            "Iteration 63/300\n",
            "Iteration 64/300\n",
            "Iteration 65/300\n",
            "Iteration 66/300\n",
            "Iteration 67/300\n",
            "Iteration 68/300\n",
            "Iteration 69/300\n",
            "Iteration 70/300\n",
            "Iteration 71/300\n",
            "Iteration 72/300\n",
            "Iteration 73/300\n",
            "Iteration 74/300\n",
            "Iteration 75/300\n",
            "Iteration 76/300\n",
            "Iteration 77/300\n",
            "Iteration 78/300\n",
            "Iteration 79/300\n",
            "Iteration 80/300\n",
            "Iteration 81/300\n",
            "Iteration 82/300\n",
            "Iteration 83/300\n",
            "Iteration 84/300\n",
            "Iteration 85/300\n",
            "Iteration 86/300\n",
            "Iteration 87/300\n",
            "Iteration 88/300\n",
            "Iteration 89/300\n",
            "Iteration 90/300\n",
            "Iteration 91/300\n",
            "Iteration 92/300\n",
            "Iteration 93/300\n",
            "Iteration 94/300\n",
            "Iteration 95/300\n",
            "Iteration 96/300\n",
            "Iteration 97/300\n",
            "Iteration 98/300\n",
            "Iteration 99/300\n",
            "Iteration 100/300\n",
            "Iteration 101/300\n",
            "Iteration 102/300\n",
            "Iteration 103/300\n",
            "Iteration 104/300\n",
            "Iteration 105/300\n",
            "Iteration 106/300\n",
            "Iteration 107/300\n",
            "Iteration 108/300\n",
            "Iteration 109/300\n",
            "Iteration 110/300\n",
            "Iteration 111/300\n",
            "Iteration 112/300\n",
            "Iteration 113/300\n",
            "Iteration 114/300\n",
            "Iteration 115/300\n",
            "Iteration 116/300\n",
            "Iteration 117/300\n",
            "Iteration 118/300\n",
            "Iteration 119/300\n",
            "Iteration 120/300\n",
            "Iteration 121/300\n",
            "Iteration 122/300\n",
            "Iteration 123/300\n",
            "Iteration 124/300\n",
            "Iteration 125/300\n",
            "Iteration 126/300\n",
            "Iteration 127/300\n",
            "Iteration 128/300\n",
            "Iteration 129/300\n",
            "Iteration 130/300\n",
            "Iteration 131/300\n",
            "Iteration 132/300\n",
            "Iteration 133/300\n",
            "Iteration 134/300\n",
            "Iteration 135/300\n",
            "Iteration 136/300\n",
            "Iteration 137/300\n",
            "Iteration 138/300\n",
            "Iteration 139/300\n",
            "Iteration 140/300\n",
            "Iteration 141/300\n",
            "Iteration 142/300\n",
            "Iteration 143/300\n",
            "Iteration 144/300\n",
            "Iteration 145/300\n",
            "Iteration 146/300\n",
            "Iteration 147/300\n",
            "Iteration 148/300\n",
            "Iteration 149/300\n",
            "Iteration 150/300\n",
            "Iteration 151/300\n",
            "Iteration 152/300\n",
            "Iteration 153/300\n",
            "Iteration 154/300\n",
            "Iteration 155/300\n",
            "Iteration 156/300\n",
            "Iteration 157/300\n",
            "Iteration 158/300\n",
            "Iteration 159/300\n",
            "Iteration 160/300\n",
            "Iteration 161/300\n",
            "Iteration 162/300\n",
            "Iteration 163/300\n",
            "Iteration 164/300\n",
            "Iteration 165/300\n",
            "Iteration 166/300\n",
            "Iteration 167/300\n",
            "Iteration 168/300\n",
            "Iteration 169/300\n",
            "Iteration 170/300\n",
            "Iteration 171/300\n",
            "Iteration 172/300\n",
            "Iteration 173/300\n",
            "Iteration 174/300\n",
            "Iteration 175/300\n",
            "Iteration 176/300\n",
            "Iteration 177/300\n",
            "Iteration 178/300\n",
            "Iteration 179/300\n",
            "Iteration 180/300\n",
            "Iteration 181/300\n",
            "Iteration 182/300\n",
            "Iteration 183/300\n",
            "Iteration 184/300\n",
            "Iteration 185/300\n",
            "Iteration 186/300\n",
            "Iteration 187/300\n",
            "Iteration 188/300\n",
            "Iteration 189/300\n",
            "Iteration 190/300\n",
            "Iteration 191/300\n",
            "Iteration 192/300\n",
            "Iteration 193/300\n",
            "Iteration 194/300\n",
            "Iteration 195/300\n",
            "Iteration 196/300\n",
            "Iteration 197/300\n",
            "Iteration 198/300\n",
            "Iteration 199/300\n",
            "Iteration 200/300\n",
            "Iteration 201/300\n",
            "Iteration 202/300\n",
            "Iteration 203/300\n",
            "Iteration 204/300\n",
            "Iteration 205/300\n",
            "Iteration 206/300\n",
            "Iteration 207/300\n",
            "Iteration 208/300\n",
            "Iteration 209/300\n",
            "Iteration 210/300\n",
            "Iteration 211/300\n",
            "Iteration 212/300\n",
            "Iteration 213/300\n",
            "Iteration 214/300\n",
            "Iteration 215/300\n",
            "Iteration 216/300\n",
            "Iteration 217/300\n",
            "Iteration 218/300\n",
            "Iteration 219/300\n",
            "Iteration 220/300\n",
            "Iteration 221/300\n",
            "Iteration 222/300\n",
            "Iteration 223/300\n",
            "Iteration 224/300\n",
            "Iteration 225/300\n",
            "Iteration 226/300\n",
            "Iteration 227/300\n",
            "Iteration 228/300\n",
            "Iteration 229/300\n",
            "Iteration 230/300\n",
            "Iteration 231/300\n",
            "Iteration 232/300\n",
            "Iteration 233/300\n",
            "Iteration 234/300\n",
            "Iteration 235/300\n",
            "Iteration 236/300\n",
            "Iteration 237/300\n",
            "Iteration 238/300\n",
            "Iteration 239/300\n",
            "Iteration 240/300\n",
            "Iteration 241/300\n",
            "Iteration 242/300\n",
            "Iteration 243/300\n",
            "Iteration 244/300\n",
            "Iteration 245/300\n",
            "Iteration 246/300\n",
            "Iteration 247/300\n",
            "Iteration 248/300\n",
            "Iteration 249/300\n",
            "Iteration 250/300\n",
            "Iteration 251/300\n",
            "Iteration 252/300\n",
            "Iteration 253/300\n",
            "Iteration 254/300\n",
            "Iteration 255/300\n",
            "Iteration 256/300\n",
            "Iteration 257/300\n",
            "Iteration 258/300\n",
            "Iteration 259/300\n",
            "Iteration 260/300\n",
            "Iteration 261/300\n",
            "Iteration 262/300\n",
            "Iteration 263/300\n",
            "Iteration 264/300\n",
            "Iteration 265/300\n",
            "Iteration 266/300\n",
            "Iteration 267/300\n",
            "Iteration 268/300\n",
            "Iteration 269/300\n",
            "Iteration 270/300\n",
            "Iteration 271/300\n",
            "Iteration 272/300\n",
            "Iteration 273/300\n",
            "Iteration 274/300\n",
            "Iteration 275/300\n",
            "Iteration 276/300\n",
            "Iteration 277/300\n",
            "Iteration 278/300\n",
            "Iteration 279/300\n",
            "Iteration 280/300\n",
            "Iteration 281/300\n",
            "Iteration 282/300\n",
            "Iteration 283/300\n",
            "Iteration 284/300\n",
            "Iteration 285/300\n",
            "Iteration 286/300\n",
            "Iteration 287/300\n",
            "Iteration 288/300\n",
            "Iteration 289/300\n",
            "Iteration 290/300\n",
            "Iteration 291/300\n",
            "Iteration 292/300\n",
            "Iteration 293/300\n",
            "Iteration 294/300\n",
            "Iteration 295/300\n",
            "Iteration 296/300\n",
            "Iteration 297/300\n",
            "Iteration 298/300\n",
            "Iteration 299/300\n",
            "Iteration 300/300\n",
            "Repeat 5/5\n",
            "Iteration 1/300\n",
            "Iteration 2/300\n",
            "Iteration 3/300\n",
            "Iteration 4/300\n",
            "Iteration 5/300\n",
            "Iteration 6/300\n",
            "Iteration 7/300\n",
            "Iteration 8/300\n",
            "Iteration 9/300\n",
            "Iteration 10/300\n",
            "Iteration 11/300\n",
            "Iteration 12/300\n",
            "Iteration 13/300\n",
            "Iteration 14/300\n",
            "Iteration 15/300\n",
            "Iteration 16/300\n",
            "Iteration 17/300\n",
            "Iteration 18/300\n",
            "Iteration 19/300\n",
            "Iteration 20/300\n",
            "Iteration 21/300\n",
            "Iteration 22/300\n",
            "Iteration 23/300\n",
            "Iteration 24/300\n",
            "Iteration 25/300\n",
            "Iteration 26/300\n",
            "Iteration 27/300\n",
            "Iteration 28/300\n",
            "Iteration 29/300\n",
            "Iteration 30/300\n",
            "Iteration 31/300\n",
            "Iteration 32/300\n",
            "Iteration 33/300\n",
            "Iteration 34/300\n",
            "Iteration 35/300\n",
            "Iteration 36/300\n",
            "Iteration 37/300\n",
            "Iteration 38/300\n",
            "Iteration 39/300\n",
            "Iteration 40/300\n",
            "Iteration 41/300\n",
            "Iteration 42/300\n",
            "Iteration 43/300\n",
            "Iteration 44/300\n",
            "Iteration 45/300\n",
            "Iteration 46/300\n",
            "Iteration 47/300\n",
            "Iteration 48/300\n",
            "Iteration 49/300\n",
            "Iteration 50/300\n",
            "Iteration 51/300\n",
            "Iteration 52/300\n",
            "Iteration 53/300\n",
            "Iteration 54/300\n",
            "Iteration 55/300\n",
            "Iteration 56/300\n",
            "Iteration 57/300\n",
            "Iteration 58/300\n",
            "Iteration 59/300\n",
            "Iteration 60/300\n",
            "Iteration 61/300\n",
            "Iteration 62/300\n",
            "Iteration 63/300\n",
            "Iteration 64/300\n",
            "Iteration 65/300\n",
            "Iteration 66/300\n",
            "Iteration 67/300\n",
            "Iteration 68/300\n",
            "Iteration 69/300\n",
            "Iteration 70/300\n",
            "Iteration 71/300\n",
            "Iteration 72/300\n",
            "Iteration 73/300\n",
            "Iteration 74/300\n",
            "Iteration 75/300\n",
            "Iteration 76/300\n",
            "Iteration 77/300\n",
            "Iteration 78/300\n",
            "Iteration 79/300\n",
            "Iteration 80/300\n",
            "Iteration 81/300\n",
            "Iteration 82/300\n",
            "Iteration 83/300\n",
            "Iteration 84/300\n",
            "Iteration 85/300\n",
            "Iteration 86/300\n",
            "Iteration 87/300\n",
            "Iteration 88/300\n",
            "Iteration 89/300\n",
            "Iteration 90/300\n",
            "Iteration 91/300\n",
            "Iteration 92/300\n",
            "Iteration 93/300\n",
            "Iteration 94/300\n",
            "Iteration 95/300\n",
            "Iteration 96/300\n",
            "Iteration 97/300\n",
            "Iteration 98/300\n",
            "Iteration 99/300\n",
            "Iteration 100/300\n",
            "Iteration 101/300\n",
            "Iteration 102/300\n",
            "Iteration 103/300\n",
            "Iteration 104/300\n",
            "Iteration 105/300\n",
            "Iteration 106/300\n",
            "Iteration 107/300\n",
            "Iteration 108/300\n",
            "Iteration 109/300\n",
            "Iteration 110/300\n",
            "Iteration 111/300\n",
            "Iteration 112/300\n",
            "Iteration 113/300\n",
            "Iteration 114/300\n",
            "Iteration 115/300\n",
            "Iteration 116/300\n",
            "Iteration 117/300\n",
            "Iteration 118/300\n",
            "Iteration 119/300\n",
            "Iteration 120/300\n",
            "Iteration 121/300\n",
            "Iteration 122/300\n",
            "Iteration 123/300\n",
            "Iteration 124/300\n",
            "Iteration 125/300\n",
            "Iteration 126/300\n",
            "Iteration 127/300\n",
            "Iteration 128/300\n",
            "Iteration 129/300\n",
            "Iteration 130/300\n",
            "Iteration 131/300\n",
            "Iteration 132/300\n",
            "Iteration 133/300\n",
            "Iteration 134/300\n",
            "Iteration 135/300\n",
            "Iteration 136/300\n",
            "Iteration 137/300\n",
            "Iteration 138/300\n",
            "Iteration 139/300\n",
            "Iteration 140/300\n",
            "Iteration 141/300\n",
            "Iteration 142/300\n",
            "Iteration 143/300\n",
            "Iteration 144/300\n",
            "Iteration 145/300\n",
            "Iteration 146/300\n",
            "Iteration 147/300\n",
            "Iteration 148/300\n",
            "Iteration 149/300\n",
            "Iteration 150/300\n",
            "Iteration 151/300\n",
            "Iteration 152/300\n",
            "Iteration 153/300\n",
            "Iteration 154/300\n",
            "Iteration 155/300\n",
            "Iteration 156/300\n",
            "Iteration 157/300\n",
            "Iteration 158/300\n",
            "Iteration 159/300\n",
            "Iteration 160/300\n",
            "Iteration 161/300\n",
            "Iteration 162/300\n",
            "Iteration 163/300\n",
            "Iteration 164/300\n",
            "Iteration 165/300\n",
            "Iteration 166/300\n",
            "Iteration 167/300\n",
            "Iteration 168/300\n",
            "Iteration 169/300\n",
            "Iteration 170/300\n",
            "Iteration 171/300\n",
            "Iteration 172/300\n",
            "Iteration 173/300\n",
            "Iteration 174/300\n",
            "Iteration 175/300\n",
            "Iteration 176/300\n",
            "Iteration 177/300\n",
            "Iteration 178/300\n",
            "Iteration 179/300\n",
            "Iteration 180/300\n",
            "Iteration 181/300\n",
            "Iteration 182/300\n",
            "Iteration 183/300\n",
            "Iteration 184/300\n",
            "Iteration 185/300\n",
            "Iteration 186/300\n",
            "Iteration 187/300\n",
            "Iteration 188/300\n",
            "Iteration 189/300\n",
            "Iteration 190/300\n",
            "Iteration 191/300\n",
            "Iteration 192/300\n",
            "Iteration 193/300\n",
            "Iteration 194/300\n",
            "Iteration 195/300\n",
            "Iteration 196/300\n",
            "Iteration 197/300\n",
            "Iteration 198/300\n",
            "Iteration 199/300\n",
            "Iteration 200/300\n",
            "Iteration 201/300\n",
            "Iteration 202/300\n",
            "Iteration 203/300\n",
            "Iteration 204/300\n",
            "Iteration 205/300\n",
            "Iteration 206/300\n",
            "Iteration 207/300\n",
            "Iteration 208/300\n",
            "Iteration 209/300\n",
            "Iteration 210/300\n",
            "Iteration 211/300\n",
            "Iteration 212/300\n",
            "Iteration 213/300\n",
            "Iteration 214/300\n",
            "Iteration 215/300\n",
            "Iteration 216/300\n",
            "Iteration 217/300\n",
            "Iteration 218/300\n",
            "Iteration 219/300\n",
            "Iteration 220/300\n",
            "Iteration 221/300\n",
            "Iteration 222/300\n",
            "Iteration 223/300\n",
            "Iteration 224/300\n",
            "Iteration 225/300\n",
            "Iteration 226/300\n",
            "Iteration 227/300\n",
            "Iteration 228/300\n",
            "Iteration 229/300\n",
            "Iteration 230/300\n",
            "Iteration 231/300\n",
            "Iteration 232/300\n",
            "Iteration 233/300\n",
            "Iteration 234/300\n",
            "Iteration 235/300\n",
            "Iteration 236/300\n",
            "Iteration 237/300\n",
            "Iteration 238/300\n",
            "Iteration 239/300\n",
            "Iteration 240/300\n",
            "Iteration 241/300\n",
            "Iteration 242/300\n",
            "Iteration 243/300\n",
            "Iteration 244/300\n",
            "Iteration 245/300\n",
            "Iteration 246/300\n",
            "Iteration 247/300\n",
            "Iteration 248/300\n",
            "Iteration 249/300\n",
            "Iteration 250/300\n",
            "Iteration 251/300\n",
            "Iteration 252/300\n",
            "Iteration 253/300\n",
            "Iteration 254/300\n",
            "Iteration 255/300\n",
            "Iteration 256/300\n",
            "Iteration 257/300\n",
            "Iteration 258/300\n",
            "Iteration 259/300\n",
            "Iteration 260/300\n",
            "Iteration 261/300\n",
            "Iteration 262/300\n",
            "Iteration 263/300\n",
            "Iteration 264/300\n",
            "Iteration 265/300\n",
            "Iteration 266/300\n",
            "Iteration 267/300\n",
            "Iteration 268/300\n",
            "Iteration 269/300\n",
            "Iteration 270/300\n",
            "Iteration 271/300\n",
            "Iteration 272/300\n",
            "Iteration 273/300\n",
            "Iteration 274/300\n",
            "Iteration 275/300\n",
            "Iteration 276/300\n",
            "Iteration 277/300\n",
            "Iteration 278/300\n",
            "Iteration 279/300\n",
            "Iteration 280/300\n",
            "Iteration 281/300\n",
            "Iteration 282/300\n",
            "Iteration 283/300\n",
            "Iteration 284/300\n",
            "Iteration 285/300\n",
            "Iteration 286/300\n",
            "Iteration 287/300\n",
            "Iteration 288/300\n",
            "Iteration 289/300\n",
            "Iteration 290/300\n",
            "Iteration 291/300\n",
            "Iteration 292/300\n",
            "Iteration 293/300\n",
            "Iteration 294/300\n",
            "Iteration 295/300\n",
            "Iteration 296/300\n",
            "Iteration 297/300\n",
            "Iteration 298/300\n",
            "Iteration 299/300\n",
            "Iteration 300/300\n",
            "Processing test sample 2/2\n",
            "Computing iHVP...\n",
            "Repeat 1/5\n",
            "Iteration 1/300\n",
            "Iteration 2/300\n",
            "Iteration 3/300\n",
            "Iteration 4/300\n",
            "Iteration 5/300\n",
            "Iteration 6/300\n",
            "Iteration 7/300\n",
            "Iteration 8/300\n",
            "Iteration 9/300\n",
            "Iteration 10/300\n",
            "Iteration 11/300\n",
            "Iteration 12/300\n",
            "Iteration 13/300\n",
            "Iteration 14/300\n",
            "Iteration 15/300\n",
            "Iteration 16/300\n",
            "Iteration 17/300\n",
            "Iteration 18/300\n",
            "Iteration 19/300\n",
            "Iteration 20/300\n",
            "Iteration 21/300\n",
            "Iteration 22/300\n",
            "Iteration 23/300\n",
            "Iteration 24/300\n",
            "Iteration 25/300\n",
            "Iteration 26/300\n",
            "Iteration 27/300\n",
            "Iteration 28/300\n",
            "Iteration 29/300\n",
            "Iteration 30/300\n",
            "Iteration 31/300\n",
            "Iteration 32/300\n",
            "Iteration 33/300\n",
            "Iteration 34/300\n",
            "Iteration 35/300\n",
            "Iteration 36/300\n",
            "Iteration 37/300\n",
            "Iteration 38/300\n",
            "Iteration 39/300\n",
            "Iteration 40/300\n",
            "Iteration 41/300\n",
            "Iteration 42/300\n",
            "Iteration 43/300\n",
            "Iteration 44/300\n",
            "Iteration 45/300\n",
            "Iteration 46/300\n",
            "Iteration 47/300\n",
            "Iteration 48/300\n",
            "Iteration 49/300\n",
            "Iteration 50/300\n",
            "Iteration 51/300\n",
            "Iteration 52/300\n",
            "Iteration 53/300\n",
            "Iteration 54/300\n",
            "Iteration 55/300\n",
            "Iteration 56/300\n",
            "Iteration 57/300\n",
            "Iteration 58/300\n",
            "Iteration 59/300\n",
            "Iteration 60/300\n",
            "Iteration 61/300\n",
            "Iteration 62/300\n",
            "Iteration 63/300\n",
            "Iteration 64/300\n",
            "Iteration 65/300\n",
            "Iteration 66/300\n",
            "Iteration 67/300\n",
            "Iteration 68/300\n",
            "Iteration 69/300\n",
            "Iteration 70/300\n",
            "Iteration 71/300\n",
            "Iteration 72/300\n",
            "Iteration 73/300\n",
            "Iteration 74/300\n",
            "Iteration 75/300\n",
            "Iteration 76/300\n",
            "Iteration 77/300\n",
            "Iteration 78/300\n",
            "Iteration 79/300\n",
            "Iteration 80/300\n",
            "Iteration 81/300\n",
            "Iteration 82/300\n",
            "Iteration 83/300\n",
            "Iteration 84/300\n",
            "Iteration 85/300\n",
            "Iteration 86/300\n",
            "Iteration 87/300\n",
            "Iteration 88/300\n",
            "Iteration 89/300\n",
            "Iteration 90/300\n",
            "Iteration 91/300\n",
            "Iteration 92/300\n",
            "Iteration 93/300\n",
            "Iteration 94/300\n",
            "Iteration 95/300\n",
            "Iteration 96/300\n",
            "Iteration 97/300\n",
            "Iteration 98/300\n",
            "Iteration 99/300\n",
            "Iteration 100/300\n",
            "Iteration 101/300\n",
            "Iteration 102/300\n",
            "Iteration 103/300\n",
            "Iteration 104/300\n",
            "Iteration 105/300\n",
            "Iteration 106/300\n",
            "Iteration 107/300\n",
            "Iteration 108/300\n",
            "Iteration 109/300\n",
            "Iteration 110/300\n",
            "Iteration 111/300\n",
            "Iteration 112/300\n",
            "Iteration 113/300\n",
            "Iteration 114/300\n",
            "Iteration 115/300\n",
            "Iteration 116/300\n",
            "Iteration 117/300\n",
            "Iteration 118/300\n",
            "Iteration 119/300\n",
            "Iteration 120/300\n",
            "Iteration 121/300\n",
            "Iteration 122/300\n",
            "Iteration 123/300\n",
            "Iteration 124/300\n",
            "Iteration 125/300\n",
            "Iteration 126/300\n",
            "Iteration 127/300\n",
            "Iteration 128/300\n",
            "Iteration 129/300\n",
            "Iteration 130/300\n",
            "Iteration 131/300\n",
            "Iteration 132/300\n",
            "Iteration 133/300\n",
            "Iteration 134/300\n",
            "Iteration 135/300\n",
            "Iteration 136/300\n",
            "Iteration 137/300\n",
            "Iteration 138/300\n",
            "Iteration 139/300\n",
            "Iteration 140/300\n",
            "Iteration 141/300\n",
            "Iteration 142/300\n",
            "Iteration 143/300\n",
            "Iteration 144/300\n",
            "Iteration 145/300\n",
            "Iteration 146/300\n",
            "Iteration 147/300\n",
            "Iteration 148/300\n",
            "Iteration 149/300\n",
            "Iteration 150/300\n",
            "Iteration 151/300\n",
            "Iteration 152/300\n",
            "Iteration 153/300\n",
            "Iteration 154/300\n",
            "Iteration 155/300\n",
            "Iteration 156/300\n",
            "Iteration 157/300\n",
            "Iteration 158/300\n",
            "Iteration 159/300\n",
            "Iteration 160/300\n",
            "Iteration 161/300\n",
            "Iteration 162/300\n",
            "Iteration 163/300\n",
            "Iteration 164/300\n",
            "Iteration 165/300\n",
            "Iteration 166/300\n",
            "Iteration 167/300\n",
            "Iteration 168/300\n",
            "Iteration 169/300\n",
            "Iteration 170/300\n",
            "Iteration 171/300\n",
            "Iteration 172/300\n",
            "Iteration 173/300\n",
            "Iteration 174/300\n",
            "Iteration 175/300\n",
            "Iteration 176/300\n",
            "Iteration 177/300\n",
            "Iteration 178/300\n",
            "Iteration 179/300\n",
            "Iteration 180/300\n",
            "Iteration 181/300\n",
            "Iteration 182/300\n",
            "Iteration 183/300\n",
            "Iteration 184/300\n",
            "Iteration 185/300\n",
            "Iteration 186/300\n",
            "Iteration 187/300\n",
            "Iteration 188/300\n",
            "Iteration 189/300\n",
            "Iteration 190/300\n",
            "Iteration 191/300\n",
            "Iteration 192/300\n",
            "Iteration 193/300\n",
            "Iteration 194/300\n",
            "Iteration 195/300\n",
            "Iteration 196/300\n",
            "Iteration 197/300\n",
            "Iteration 198/300\n",
            "Iteration 199/300\n",
            "Iteration 200/300\n",
            "Iteration 201/300\n",
            "Iteration 202/300\n",
            "Iteration 203/300\n",
            "Iteration 204/300\n",
            "Iteration 205/300\n",
            "Iteration 206/300\n",
            "Iteration 207/300\n",
            "Iteration 208/300\n",
            "Iteration 209/300\n",
            "Iteration 210/300\n",
            "Iteration 211/300\n",
            "Iteration 212/300\n",
            "Iteration 213/300\n",
            "Iteration 214/300\n",
            "Iteration 215/300\n",
            "Iteration 216/300\n",
            "Iteration 217/300\n",
            "Iteration 218/300\n",
            "Iteration 219/300\n",
            "Iteration 220/300\n",
            "Iteration 221/300\n",
            "Iteration 222/300\n",
            "Iteration 223/300\n",
            "Iteration 224/300\n",
            "Iteration 225/300\n",
            "Iteration 226/300\n",
            "Iteration 227/300\n",
            "Iteration 228/300\n",
            "Iteration 229/300\n",
            "Iteration 230/300\n",
            "Iteration 231/300\n",
            "Iteration 232/300\n",
            "Iteration 233/300\n",
            "Iteration 234/300\n",
            "Iteration 235/300\n",
            "Iteration 236/300\n",
            "Iteration 237/300\n",
            "Iteration 238/300\n",
            "Iteration 239/300\n",
            "Iteration 240/300\n",
            "Iteration 241/300\n",
            "Iteration 242/300\n",
            "Iteration 243/300\n",
            "Iteration 244/300\n",
            "Iteration 245/300\n",
            "Iteration 246/300\n",
            "Iteration 247/300\n",
            "Iteration 248/300\n",
            "Iteration 249/300\n",
            "Iteration 250/300\n",
            "Iteration 251/300\n",
            "Iteration 252/300\n",
            "Iteration 253/300\n",
            "Iteration 254/300\n",
            "Iteration 255/300\n",
            "Iteration 256/300\n",
            "Iteration 257/300\n",
            "Iteration 258/300\n",
            "Iteration 259/300\n",
            "Iteration 260/300\n",
            "Iteration 261/300\n",
            "Iteration 262/300\n",
            "Iteration 263/300\n",
            "Iteration 264/300\n",
            "Iteration 265/300\n",
            "Iteration 266/300\n",
            "Iteration 267/300\n",
            "Iteration 268/300\n",
            "Iteration 269/300\n",
            "Iteration 270/300\n",
            "Iteration 271/300\n",
            "Iteration 272/300\n",
            "Iteration 273/300\n",
            "Iteration 274/300\n",
            "Iteration 275/300\n",
            "Iteration 276/300\n",
            "Iteration 277/300\n",
            "Iteration 278/300\n",
            "Iteration 279/300\n",
            "Iteration 280/300\n",
            "Iteration 281/300\n",
            "Iteration 282/300\n",
            "Iteration 283/300\n",
            "Iteration 284/300\n",
            "Iteration 285/300\n",
            "Iteration 286/300\n",
            "Iteration 287/300\n",
            "Iteration 288/300\n",
            "Iteration 289/300\n",
            "Iteration 290/300\n",
            "Iteration 291/300\n",
            "Iteration 292/300\n",
            "Iteration 293/300\n",
            "Iteration 294/300\n",
            "Iteration 295/300\n",
            "Iteration 296/300\n",
            "Iteration 297/300\n",
            "Iteration 298/300\n",
            "Iteration 299/300\n",
            "Iteration 300/300\n",
            "Repeat 2/5\n",
            "Iteration 1/300\n",
            "Iteration 2/300\n",
            "Iteration 3/300\n",
            "Iteration 4/300\n",
            "Iteration 5/300\n",
            "Iteration 6/300\n",
            "Iteration 7/300\n",
            "Iteration 8/300\n",
            "Iteration 9/300\n",
            "Iteration 10/300\n",
            "Iteration 11/300\n",
            "Iteration 12/300\n",
            "Iteration 13/300\n",
            "Iteration 14/300\n",
            "Iteration 15/300\n",
            "Iteration 16/300\n",
            "Iteration 17/300\n",
            "Iteration 18/300\n",
            "Iteration 19/300\n",
            "Iteration 20/300\n",
            "Iteration 21/300\n",
            "Iteration 22/300\n",
            "Iteration 23/300\n",
            "Iteration 24/300\n",
            "Iteration 25/300\n",
            "Iteration 26/300\n",
            "Iteration 27/300\n",
            "Iteration 28/300\n",
            "Iteration 29/300\n",
            "Iteration 30/300\n",
            "Iteration 31/300\n",
            "Iteration 32/300\n",
            "Iteration 33/300\n",
            "Iteration 34/300\n",
            "Iteration 35/300\n",
            "Iteration 36/300\n",
            "Iteration 37/300\n",
            "Iteration 38/300\n",
            "Iteration 39/300\n",
            "Iteration 40/300\n",
            "Iteration 41/300\n",
            "Iteration 42/300\n",
            "Iteration 43/300\n",
            "Iteration 44/300\n",
            "Iteration 45/300\n",
            "Iteration 46/300\n",
            "Iteration 47/300\n",
            "Iteration 48/300\n",
            "Iteration 49/300\n",
            "Iteration 50/300\n",
            "Iteration 51/300\n",
            "Iteration 52/300\n",
            "Iteration 53/300\n",
            "Iteration 54/300\n",
            "Iteration 55/300\n",
            "Iteration 56/300\n",
            "Iteration 57/300\n",
            "Iteration 58/300\n",
            "Iteration 59/300\n",
            "Iteration 60/300\n",
            "Iteration 61/300\n",
            "Iteration 62/300\n",
            "Iteration 63/300\n",
            "Iteration 64/300\n",
            "Iteration 65/300\n",
            "Iteration 66/300\n",
            "Iteration 67/300\n",
            "Iteration 68/300\n",
            "Iteration 69/300\n",
            "Iteration 70/300\n",
            "Iteration 71/300\n",
            "Iteration 72/300\n",
            "Iteration 73/300\n",
            "Iteration 74/300\n",
            "Iteration 75/300\n",
            "Iteration 76/300\n",
            "Iteration 77/300\n",
            "Iteration 78/300\n",
            "Iteration 79/300\n",
            "Iteration 80/300\n",
            "Iteration 81/300\n",
            "Iteration 82/300\n",
            "Iteration 83/300\n",
            "Iteration 84/300\n",
            "Iteration 85/300\n",
            "Iteration 86/300\n",
            "Iteration 87/300\n",
            "Iteration 88/300\n",
            "Iteration 89/300\n",
            "Iteration 90/300\n",
            "Iteration 91/300\n",
            "Iteration 92/300\n",
            "Iteration 93/300\n",
            "Iteration 94/300\n",
            "Iteration 95/300\n",
            "Iteration 96/300\n",
            "Iteration 97/300\n",
            "Iteration 98/300\n",
            "Iteration 99/300\n",
            "Iteration 100/300\n",
            "Iteration 101/300\n",
            "Iteration 102/300\n",
            "Iteration 103/300\n",
            "Iteration 104/300\n",
            "Iteration 105/300\n",
            "Iteration 106/300\n",
            "Iteration 107/300\n",
            "Iteration 108/300\n",
            "Iteration 109/300\n",
            "Iteration 110/300\n",
            "Iteration 111/300\n",
            "Iteration 112/300\n",
            "Iteration 113/300\n",
            "Iteration 114/300\n",
            "Iteration 115/300\n",
            "Iteration 116/300\n",
            "Iteration 117/300\n",
            "Iteration 118/300\n",
            "Iteration 119/300\n",
            "Iteration 120/300\n",
            "Iteration 121/300\n",
            "Iteration 122/300\n",
            "Iteration 123/300\n",
            "Iteration 124/300\n",
            "Iteration 125/300\n",
            "Iteration 126/300\n",
            "Iteration 127/300\n",
            "Iteration 128/300\n",
            "Iteration 129/300\n",
            "Iteration 130/300\n",
            "Iteration 131/300\n",
            "Iteration 132/300\n",
            "Iteration 133/300\n",
            "Iteration 134/300\n",
            "Iteration 135/300\n",
            "Iteration 136/300\n",
            "Iteration 137/300\n",
            "Iteration 138/300\n",
            "Iteration 139/300\n",
            "Iteration 140/300\n",
            "Iteration 141/300\n",
            "Iteration 142/300\n",
            "Iteration 143/300\n",
            "Iteration 144/300\n",
            "Iteration 145/300\n",
            "Iteration 146/300\n",
            "Iteration 147/300\n",
            "Iteration 148/300\n",
            "Iteration 149/300\n",
            "Iteration 150/300\n",
            "Iteration 151/300\n",
            "Iteration 152/300\n",
            "Iteration 153/300\n",
            "Iteration 154/300\n",
            "Iteration 155/300\n",
            "Iteration 156/300\n",
            "Iteration 157/300\n",
            "Iteration 158/300\n",
            "Iteration 159/300\n",
            "Iteration 160/300\n",
            "Iteration 161/300\n",
            "Iteration 162/300\n",
            "Iteration 163/300\n",
            "Iteration 164/300\n",
            "Iteration 165/300\n",
            "Iteration 166/300\n",
            "Iteration 167/300\n",
            "Iteration 168/300\n",
            "Iteration 169/300\n",
            "Iteration 170/300\n",
            "Iteration 171/300\n",
            "Iteration 172/300\n",
            "Iteration 173/300\n",
            "Iteration 174/300\n",
            "Iteration 175/300\n",
            "Iteration 176/300\n",
            "Iteration 177/300\n",
            "Iteration 178/300\n",
            "Iteration 179/300\n",
            "Iteration 180/300\n",
            "Iteration 181/300\n",
            "Iteration 182/300\n",
            "Iteration 183/300\n",
            "Iteration 184/300\n",
            "Iteration 185/300\n",
            "Iteration 186/300\n",
            "Iteration 187/300\n",
            "Iteration 188/300\n",
            "Iteration 189/300\n",
            "Iteration 190/300\n",
            "Iteration 191/300\n",
            "Iteration 192/300\n",
            "Iteration 193/300\n",
            "Iteration 194/300\n",
            "Iteration 195/300\n",
            "Iteration 196/300\n",
            "Iteration 197/300\n",
            "Iteration 198/300\n",
            "Iteration 199/300\n",
            "Iteration 200/300\n",
            "Iteration 201/300\n",
            "Iteration 202/300\n",
            "Iteration 203/300\n",
            "Iteration 204/300\n",
            "Iteration 205/300\n",
            "Iteration 206/300\n",
            "Iteration 207/300\n",
            "Iteration 208/300\n",
            "Iteration 209/300\n",
            "Iteration 210/300\n",
            "Iteration 211/300\n",
            "Iteration 212/300\n",
            "Iteration 213/300\n",
            "Iteration 214/300\n",
            "Iteration 215/300\n",
            "Iteration 216/300\n",
            "Iteration 217/300\n",
            "Iteration 218/300\n",
            "Iteration 219/300\n",
            "Iteration 220/300\n",
            "Iteration 221/300\n",
            "Iteration 222/300\n",
            "Iteration 223/300\n",
            "Iteration 224/300\n",
            "Iteration 225/300\n",
            "Iteration 226/300\n",
            "Iteration 227/300\n",
            "Iteration 228/300\n",
            "Iteration 229/300\n",
            "Iteration 230/300\n",
            "Iteration 231/300\n",
            "Iteration 232/300\n",
            "Iteration 233/300\n",
            "Iteration 234/300\n",
            "Iteration 235/300\n",
            "Iteration 236/300\n",
            "Iteration 237/300\n",
            "Iteration 238/300\n",
            "Iteration 239/300\n",
            "Iteration 240/300\n",
            "Iteration 241/300\n",
            "Iteration 242/300\n",
            "Iteration 243/300\n",
            "Iteration 244/300\n",
            "Iteration 245/300\n",
            "Iteration 246/300\n",
            "Iteration 247/300\n",
            "Iteration 248/300\n",
            "Iteration 249/300\n",
            "Iteration 250/300\n",
            "Iteration 251/300\n",
            "Iteration 252/300\n",
            "Iteration 253/300\n",
            "Iteration 254/300\n",
            "Iteration 255/300\n",
            "Iteration 256/300\n",
            "Iteration 257/300\n",
            "Iteration 258/300\n",
            "Iteration 259/300\n",
            "Iteration 260/300\n",
            "Iteration 261/300\n",
            "Iteration 262/300\n",
            "Iteration 263/300\n",
            "Iteration 264/300\n",
            "Iteration 265/300\n",
            "Iteration 266/300\n",
            "Iteration 267/300\n",
            "Iteration 268/300\n",
            "Iteration 269/300\n",
            "Iteration 270/300\n",
            "Iteration 271/300\n",
            "Iteration 272/300\n",
            "Iteration 273/300\n",
            "Iteration 274/300\n",
            "Iteration 275/300\n",
            "Iteration 276/300\n",
            "Iteration 277/300\n",
            "Iteration 278/300\n",
            "Iteration 279/300\n",
            "Iteration 280/300\n",
            "Iteration 281/300\n",
            "Iteration 282/300\n",
            "Iteration 283/300\n",
            "Iteration 284/300\n",
            "Iteration 285/300\n",
            "Iteration 286/300\n",
            "Iteration 287/300\n",
            "Iteration 288/300\n",
            "Iteration 289/300\n",
            "Iteration 290/300\n",
            "Iteration 291/300\n",
            "Iteration 292/300\n",
            "Iteration 293/300\n",
            "Iteration 294/300\n",
            "Iteration 295/300\n",
            "Iteration 296/300\n",
            "Iteration 297/300\n",
            "Iteration 298/300\n",
            "Iteration 299/300\n",
            "Iteration 300/300\n",
            "Repeat 3/5\n",
            "Iteration 1/300\n",
            "Iteration 2/300\n",
            "Iteration 3/300\n",
            "Iteration 4/300\n",
            "Iteration 5/300\n",
            "Iteration 6/300\n",
            "Iteration 7/300\n",
            "Iteration 8/300\n",
            "Iteration 9/300\n",
            "Iteration 10/300\n",
            "Iteration 11/300\n",
            "Iteration 12/300\n",
            "Iteration 13/300\n",
            "Iteration 14/300\n",
            "Iteration 15/300\n",
            "Iteration 16/300\n",
            "Iteration 17/300\n",
            "Iteration 18/300\n",
            "Iteration 19/300\n",
            "Iteration 20/300\n",
            "Iteration 21/300\n",
            "Iteration 22/300\n",
            "Iteration 23/300\n",
            "Iteration 24/300\n",
            "Iteration 25/300\n",
            "Iteration 26/300\n",
            "Iteration 27/300\n",
            "Iteration 28/300\n",
            "Iteration 29/300\n",
            "Iteration 30/300\n",
            "Iteration 31/300\n",
            "Iteration 32/300\n",
            "Iteration 33/300\n",
            "Iteration 34/300\n",
            "Iteration 35/300\n",
            "Iteration 36/300\n",
            "Iteration 37/300\n",
            "Iteration 38/300\n",
            "Iteration 39/300\n",
            "Iteration 40/300\n",
            "Iteration 41/300\n",
            "Iteration 42/300\n",
            "Iteration 43/300\n",
            "Iteration 44/300\n",
            "Iteration 45/300\n",
            "Iteration 46/300\n",
            "Iteration 47/300\n",
            "Iteration 48/300\n",
            "Iteration 49/300\n",
            "Iteration 50/300\n",
            "Iteration 51/300\n",
            "Iteration 52/300\n",
            "Iteration 53/300\n",
            "Iteration 54/300\n",
            "Iteration 55/300\n",
            "Iteration 56/300\n",
            "Iteration 57/300\n",
            "Iteration 58/300\n",
            "Iteration 59/300\n",
            "Iteration 60/300\n",
            "Iteration 61/300\n",
            "Iteration 62/300\n",
            "Iteration 63/300\n",
            "Iteration 64/300\n",
            "Iteration 65/300\n",
            "Iteration 66/300\n",
            "Iteration 67/300\n",
            "Iteration 68/300\n",
            "Iteration 69/300\n",
            "Iteration 70/300\n",
            "Iteration 71/300\n",
            "Iteration 72/300\n",
            "Iteration 73/300\n",
            "Iteration 74/300\n",
            "Iteration 75/300\n",
            "Iteration 76/300\n",
            "Iteration 77/300\n",
            "Iteration 78/300\n",
            "Iteration 79/300\n",
            "Iteration 80/300\n",
            "Iteration 81/300\n",
            "Iteration 82/300\n",
            "Iteration 83/300\n",
            "Iteration 84/300\n",
            "Iteration 85/300\n",
            "Iteration 86/300\n",
            "Iteration 87/300\n",
            "Iteration 88/300\n",
            "Iteration 89/300\n",
            "Iteration 90/300\n",
            "Iteration 91/300\n",
            "Iteration 92/300\n",
            "Iteration 93/300\n",
            "Iteration 94/300\n",
            "Iteration 95/300\n",
            "Iteration 96/300\n",
            "Iteration 97/300\n",
            "Iteration 98/300\n",
            "Iteration 99/300\n",
            "Iteration 100/300\n",
            "Iteration 101/300\n",
            "Iteration 102/300\n",
            "Iteration 103/300\n",
            "Iteration 104/300\n",
            "Iteration 105/300\n",
            "Iteration 106/300\n",
            "Iteration 107/300\n",
            "Iteration 108/300\n",
            "Iteration 109/300\n",
            "Iteration 110/300\n",
            "Iteration 111/300\n",
            "Iteration 112/300\n",
            "Iteration 113/300\n",
            "Iteration 114/300\n",
            "Iteration 115/300\n",
            "Iteration 116/300\n",
            "Iteration 117/300\n",
            "Iteration 118/300\n",
            "Iteration 119/300\n",
            "Iteration 120/300\n",
            "Iteration 121/300\n",
            "Iteration 122/300\n",
            "Iteration 123/300\n",
            "Iteration 124/300\n",
            "Iteration 125/300\n",
            "Iteration 126/300\n",
            "Iteration 127/300\n",
            "Iteration 128/300\n",
            "Iteration 129/300\n",
            "Iteration 130/300\n",
            "Iteration 131/300\n",
            "Iteration 132/300\n",
            "Iteration 133/300\n",
            "Iteration 134/300\n",
            "Iteration 135/300\n",
            "Iteration 136/300\n",
            "Iteration 137/300\n",
            "Iteration 138/300\n",
            "Iteration 139/300\n",
            "Iteration 140/300\n",
            "Iteration 141/300\n",
            "Iteration 142/300\n",
            "Iteration 143/300\n",
            "Iteration 144/300\n",
            "Iteration 145/300\n",
            "Iteration 146/300\n",
            "Iteration 147/300\n",
            "Iteration 148/300\n",
            "Iteration 149/300\n",
            "Iteration 150/300\n",
            "Iteration 151/300\n",
            "Iteration 152/300\n",
            "Iteration 153/300\n",
            "Iteration 154/300\n",
            "Iteration 155/300\n",
            "Iteration 156/300\n",
            "Iteration 157/300\n",
            "Iteration 158/300\n",
            "Iteration 159/300\n",
            "Iteration 160/300\n",
            "Iteration 161/300\n",
            "Iteration 162/300\n",
            "Iteration 163/300\n",
            "Iteration 164/300\n",
            "Iteration 165/300\n",
            "Iteration 166/300\n",
            "Iteration 167/300\n",
            "Iteration 168/300\n",
            "Iteration 169/300\n",
            "Iteration 170/300\n",
            "Iteration 171/300\n",
            "Iteration 172/300\n",
            "Iteration 173/300\n",
            "Iteration 174/300\n",
            "Iteration 175/300\n",
            "Iteration 176/300\n",
            "Iteration 177/300\n",
            "Iteration 178/300\n",
            "Iteration 179/300\n",
            "Iteration 180/300\n",
            "Iteration 181/300\n",
            "Iteration 182/300\n",
            "Iteration 183/300\n",
            "Iteration 184/300\n",
            "Iteration 185/300\n",
            "Iteration 186/300\n",
            "Iteration 187/300\n",
            "Iteration 188/300\n",
            "Iteration 189/300\n",
            "Iteration 190/300\n",
            "Iteration 191/300\n",
            "Iteration 192/300\n",
            "Iteration 193/300\n",
            "Iteration 194/300\n",
            "Iteration 195/300\n",
            "Iteration 196/300\n",
            "Iteration 197/300\n",
            "Iteration 198/300\n",
            "Iteration 199/300\n",
            "Iteration 200/300\n",
            "Iteration 201/300\n",
            "Iteration 202/300\n",
            "Iteration 203/300\n",
            "Iteration 204/300\n",
            "Iteration 205/300\n",
            "Iteration 206/300\n",
            "Iteration 207/300\n",
            "Iteration 208/300\n",
            "Iteration 209/300\n",
            "Iteration 210/300\n",
            "Iteration 211/300\n",
            "Iteration 212/300\n",
            "Iteration 213/300\n",
            "Iteration 214/300\n",
            "Iteration 215/300\n",
            "Iteration 216/300\n",
            "Iteration 217/300\n",
            "Iteration 218/300\n",
            "Iteration 219/300\n",
            "Iteration 220/300\n",
            "Iteration 221/300\n",
            "Iteration 222/300\n",
            "Iteration 223/300\n",
            "Iteration 224/300\n",
            "Iteration 225/300\n",
            "Iteration 226/300\n",
            "Iteration 227/300\n",
            "Iteration 228/300\n",
            "Iteration 229/300\n",
            "Iteration 230/300\n",
            "Iteration 231/300\n",
            "Iteration 232/300\n",
            "Iteration 233/300\n",
            "Iteration 234/300\n",
            "Iteration 235/300\n",
            "Iteration 236/300\n",
            "Iteration 237/300\n",
            "Iteration 238/300\n",
            "Iteration 239/300\n",
            "Iteration 240/300\n",
            "Iteration 241/300\n",
            "Iteration 242/300\n",
            "Iteration 243/300\n",
            "Iteration 244/300\n",
            "Iteration 245/300\n",
            "Iteration 246/300\n",
            "Iteration 247/300\n",
            "Iteration 248/300\n",
            "Iteration 249/300\n",
            "Iteration 250/300\n",
            "Iteration 251/300\n",
            "Iteration 252/300\n",
            "Iteration 253/300\n",
            "Iteration 254/300\n",
            "Iteration 255/300\n",
            "Iteration 256/300\n",
            "Iteration 257/300\n",
            "Iteration 258/300\n",
            "Iteration 259/300\n",
            "Iteration 260/300\n",
            "Iteration 261/300\n",
            "Iteration 262/300\n",
            "Iteration 263/300\n",
            "Iteration 264/300\n",
            "Iteration 265/300\n",
            "Iteration 266/300\n",
            "Iteration 267/300\n",
            "Iteration 268/300\n",
            "Iteration 269/300\n",
            "Iteration 270/300\n",
            "Iteration 271/300\n",
            "Iteration 272/300\n",
            "Iteration 273/300\n",
            "Iteration 274/300\n",
            "Iteration 275/300\n",
            "Iteration 276/300\n",
            "Iteration 277/300\n",
            "Iteration 278/300\n",
            "Iteration 279/300\n",
            "Iteration 280/300\n",
            "Iteration 281/300\n",
            "Iteration 282/300\n",
            "Iteration 283/300\n",
            "Iteration 284/300\n",
            "Iteration 285/300\n",
            "Iteration 286/300\n",
            "Iteration 287/300\n",
            "Iteration 288/300\n",
            "Iteration 289/300\n",
            "Iteration 290/300\n",
            "Iteration 291/300\n",
            "Iteration 292/300\n",
            "Iteration 293/300\n",
            "Iteration 294/300\n",
            "Iteration 295/300\n",
            "Iteration 296/300\n",
            "Iteration 297/300\n",
            "Iteration 298/300\n",
            "Iteration 299/300\n",
            "Iteration 300/300\n",
            "Repeat 4/5\n",
            "Iteration 1/300\n",
            "Iteration 2/300\n",
            "Iteration 3/300\n",
            "Iteration 4/300\n",
            "Iteration 5/300\n",
            "Iteration 6/300\n",
            "Iteration 7/300\n",
            "Iteration 8/300\n",
            "Iteration 9/300\n",
            "Iteration 10/300\n",
            "Iteration 11/300\n",
            "Iteration 12/300\n",
            "Iteration 13/300\n",
            "Iteration 14/300\n",
            "Iteration 15/300\n",
            "Iteration 16/300\n",
            "Iteration 17/300\n",
            "Iteration 18/300\n",
            "Iteration 19/300\n",
            "Iteration 20/300\n",
            "Iteration 21/300\n",
            "Iteration 22/300\n",
            "Iteration 23/300\n",
            "Iteration 24/300\n",
            "Iteration 25/300\n",
            "Iteration 26/300\n",
            "Iteration 27/300\n",
            "Iteration 28/300\n",
            "Iteration 29/300\n",
            "Iteration 30/300\n",
            "Iteration 31/300\n",
            "Iteration 32/300\n",
            "Iteration 33/300\n",
            "Iteration 34/300\n",
            "Iteration 35/300\n",
            "Iteration 36/300\n",
            "Iteration 37/300\n",
            "Iteration 38/300\n",
            "Iteration 39/300\n",
            "Iteration 40/300\n",
            "Iteration 41/300\n",
            "Iteration 42/300\n",
            "Iteration 43/300\n",
            "Iteration 44/300\n",
            "Iteration 45/300\n",
            "Iteration 46/300\n",
            "Iteration 47/300\n",
            "Iteration 48/300\n",
            "Iteration 49/300\n",
            "Iteration 50/300\n",
            "Iteration 51/300\n",
            "Iteration 52/300\n",
            "Iteration 53/300\n",
            "Iteration 54/300\n",
            "Iteration 55/300\n",
            "Iteration 56/300\n",
            "Iteration 57/300\n",
            "Iteration 58/300\n",
            "Iteration 59/300\n",
            "Iteration 60/300\n",
            "Iteration 61/300\n",
            "Iteration 62/300\n",
            "Iteration 63/300\n",
            "Iteration 64/300\n",
            "Iteration 65/300\n",
            "Iteration 66/300\n",
            "Iteration 67/300\n",
            "Iteration 68/300\n",
            "Iteration 69/300\n",
            "Iteration 70/300\n",
            "Iteration 71/300\n",
            "Iteration 72/300\n",
            "Iteration 73/300\n",
            "Iteration 74/300\n",
            "Iteration 75/300\n",
            "Iteration 76/300\n",
            "Iteration 77/300\n",
            "Iteration 78/300\n",
            "Iteration 79/300\n",
            "Iteration 80/300\n",
            "Iteration 81/300\n",
            "Iteration 82/300\n",
            "Iteration 83/300\n",
            "Iteration 84/300\n",
            "Iteration 85/300\n",
            "Iteration 86/300\n",
            "Iteration 87/300\n",
            "Iteration 88/300\n",
            "Iteration 89/300\n",
            "Iteration 90/300\n",
            "Iteration 91/300\n",
            "Iteration 92/300\n",
            "Iteration 93/300\n",
            "Iteration 94/300\n",
            "Iteration 95/300\n",
            "Iteration 96/300\n",
            "Iteration 97/300\n",
            "Iteration 98/300\n",
            "Iteration 99/300\n",
            "Iteration 100/300\n",
            "Iteration 101/300\n",
            "Iteration 102/300\n",
            "Iteration 103/300\n",
            "Iteration 104/300\n",
            "Iteration 105/300\n",
            "Iteration 106/300\n",
            "Iteration 107/300\n",
            "Iteration 108/300\n",
            "Iteration 109/300\n",
            "Iteration 110/300\n",
            "Iteration 111/300\n",
            "Iteration 112/300\n",
            "Iteration 113/300\n",
            "Iteration 114/300\n",
            "Iteration 115/300\n",
            "Iteration 116/300\n",
            "Iteration 117/300\n",
            "Iteration 118/300\n",
            "Iteration 119/300\n",
            "Iteration 120/300\n",
            "Iteration 121/300\n",
            "Iteration 122/300\n",
            "Iteration 123/300\n",
            "Iteration 124/300\n",
            "Iteration 125/300\n",
            "Iteration 126/300\n",
            "Iteration 127/300\n",
            "Iteration 128/300\n",
            "Iteration 129/300\n",
            "Iteration 130/300\n",
            "Iteration 131/300\n",
            "Iteration 132/300\n",
            "Iteration 133/300\n",
            "Iteration 134/300\n",
            "Iteration 135/300\n",
            "Iteration 136/300\n",
            "Iteration 137/300\n",
            "Iteration 138/300\n",
            "Iteration 139/300\n",
            "Iteration 140/300\n",
            "Iteration 141/300\n",
            "Iteration 142/300\n",
            "Iteration 143/300\n",
            "Iteration 144/300\n",
            "Iteration 145/300\n",
            "Iteration 146/300\n",
            "Iteration 147/300\n",
            "Iteration 148/300\n",
            "Iteration 149/300\n",
            "Iteration 150/300\n",
            "Iteration 151/300\n",
            "Iteration 152/300\n",
            "Iteration 153/300\n",
            "Iteration 154/300\n",
            "Iteration 155/300\n",
            "Iteration 156/300\n",
            "Iteration 157/300\n",
            "Iteration 158/300\n",
            "Iteration 159/300\n",
            "Iteration 160/300\n",
            "Iteration 161/300\n",
            "Iteration 162/300\n",
            "Iteration 163/300\n",
            "Iteration 164/300\n",
            "Iteration 165/300\n",
            "Iteration 166/300\n",
            "Iteration 167/300\n",
            "Iteration 168/300\n",
            "Iteration 169/300\n",
            "Iteration 170/300\n",
            "Iteration 171/300\n",
            "Iteration 172/300\n",
            "Iteration 173/300\n",
            "Iteration 174/300\n",
            "Iteration 175/300\n",
            "Iteration 176/300\n",
            "Iteration 177/300\n",
            "Iteration 178/300\n",
            "Iteration 179/300\n",
            "Iteration 180/300\n",
            "Iteration 181/300\n",
            "Iteration 182/300\n",
            "Iteration 183/300\n",
            "Iteration 184/300\n",
            "Iteration 185/300\n",
            "Iteration 186/300\n",
            "Iteration 187/300\n",
            "Iteration 188/300\n",
            "Iteration 189/300\n",
            "Iteration 190/300\n",
            "Iteration 191/300\n",
            "Iteration 192/300\n",
            "Iteration 193/300\n",
            "Iteration 194/300\n",
            "Iteration 195/300\n",
            "Iteration 196/300\n",
            "Iteration 197/300\n",
            "Iteration 198/300\n",
            "Iteration 199/300\n",
            "Iteration 200/300\n",
            "Iteration 201/300\n",
            "Iteration 202/300\n",
            "Iteration 203/300\n",
            "Iteration 204/300\n",
            "Iteration 205/300\n",
            "Iteration 206/300\n",
            "Iteration 207/300\n",
            "Iteration 208/300\n",
            "Iteration 209/300\n",
            "Iteration 210/300\n",
            "Iteration 211/300\n",
            "Iteration 212/300\n",
            "Iteration 213/300\n",
            "Iteration 214/300\n",
            "Iteration 215/300\n",
            "Iteration 216/300\n",
            "Iteration 217/300\n",
            "Iteration 218/300\n",
            "Iteration 219/300\n",
            "Iteration 220/300\n",
            "Iteration 221/300\n",
            "Iteration 222/300\n",
            "Iteration 223/300\n",
            "Iteration 224/300\n",
            "Iteration 225/300\n",
            "Iteration 226/300\n",
            "Iteration 227/300\n",
            "Iteration 228/300\n",
            "Iteration 229/300\n",
            "Iteration 230/300\n",
            "Iteration 231/300\n",
            "Iteration 232/300\n",
            "Iteration 233/300\n",
            "Iteration 234/300\n",
            "Iteration 235/300\n",
            "Iteration 236/300\n",
            "Iteration 237/300\n",
            "Iteration 238/300\n",
            "Iteration 239/300\n",
            "Iteration 240/300\n",
            "Iteration 241/300\n",
            "Iteration 242/300\n",
            "Iteration 243/300\n",
            "Iteration 244/300\n",
            "Iteration 245/300\n",
            "Iteration 246/300\n",
            "Iteration 247/300\n",
            "Iteration 248/300\n",
            "Iteration 249/300\n",
            "Iteration 250/300\n",
            "Iteration 251/300\n",
            "Iteration 252/300\n",
            "Iteration 253/300\n",
            "Iteration 254/300\n",
            "Iteration 255/300\n",
            "Iteration 256/300\n",
            "Iteration 257/300\n",
            "Iteration 258/300\n",
            "Iteration 259/300\n",
            "Iteration 260/300\n",
            "Iteration 261/300\n",
            "Iteration 262/300\n",
            "Iteration 263/300\n",
            "Iteration 264/300\n",
            "Iteration 265/300\n",
            "Iteration 266/300\n",
            "Iteration 267/300\n",
            "Iteration 268/300\n",
            "Iteration 269/300\n",
            "Iteration 270/300\n",
            "Iteration 271/300\n",
            "Iteration 272/300\n",
            "Iteration 273/300\n",
            "Iteration 274/300\n",
            "Iteration 275/300\n",
            "Iteration 276/300\n",
            "Iteration 277/300\n",
            "Iteration 278/300\n",
            "Iteration 279/300\n",
            "Iteration 280/300\n",
            "Iteration 281/300\n",
            "Iteration 282/300\n",
            "Iteration 283/300\n",
            "Iteration 284/300\n",
            "Iteration 285/300\n",
            "Iteration 286/300\n",
            "Iteration 287/300\n",
            "Iteration 288/300\n",
            "Iteration 289/300\n",
            "Iteration 290/300\n",
            "Iteration 291/300\n",
            "Iteration 292/300\n",
            "Iteration 293/300\n",
            "Iteration 294/300\n",
            "Iteration 295/300\n",
            "Iteration 296/300\n",
            "Iteration 297/300\n",
            "Iteration 298/300\n",
            "Iteration 299/300\n",
            "Iteration 300/300\n",
            "Repeat 5/5\n",
            "Iteration 1/300\n",
            "Iteration 2/300\n",
            "Iteration 3/300\n",
            "Iteration 4/300\n",
            "Iteration 5/300\n",
            "Iteration 6/300\n",
            "Iteration 7/300\n",
            "Iteration 8/300\n",
            "Iteration 9/300\n",
            "Iteration 10/300\n",
            "Iteration 11/300\n",
            "Iteration 12/300\n",
            "Iteration 13/300\n",
            "Iteration 14/300\n",
            "Iteration 15/300\n",
            "Iteration 16/300\n",
            "Iteration 17/300\n",
            "Iteration 18/300\n",
            "Iteration 19/300\n",
            "Iteration 20/300\n",
            "Iteration 21/300\n",
            "Iteration 22/300\n",
            "Iteration 23/300\n",
            "Iteration 24/300\n",
            "Iteration 25/300\n",
            "Iteration 26/300\n",
            "Iteration 27/300\n",
            "Iteration 28/300\n",
            "Iteration 29/300\n",
            "Iteration 30/300\n",
            "Iteration 31/300\n",
            "Iteration 32/300\n",
            "Iteration 33/300\n",
            "Iteration 34/300\n",
            "Iteration 35/300\n",
            "Iteration 36/300\n",
            "Iteration 37/300\n",
            "Iteration 38/300\n",
            "Iteration 39/300\n",
            "Iteration 40/300\n",
            "Iteration 41/300\n",
            "Iteration 42/300\n",
            "Iteration 43/300\n",
            "Iteration 44/300\n",
            "Iteration 45/300\n",
            "Iteration 46/300\n",
            "Iteration 47/300\n",
            "Iteration 48/300\n",
            "Iteration 49/300\n",
            "Iteration 50/300\n",
            "Iteration 51/300\n",
            "Iteration 52/300\n",
            "Iteration 53/300\n",
            "Iteration 54/300\n",
            "Iteration 55/300\n",
            "Iteration 56/300\n",
            "Iteration 57/300\n",
            "Iteration 58/300\n",
            "Iteration 59/300\n",
            "Iteration 60/300\n",
            "Iteration 61/300\n",
            "Iteration 62/300\n",
            "Iteration 63/300\n",
            "Iteration 64/300\n",
            "Iteration 65/300\n",
            "Iteration 66/300\n",
            "Iteration 67/300\n",
            "Iteration 68/300\n",
            "Iteration 69/300\n",
            "Iteration 70/300\n",
            "Iteration 71/300\n",
            "Iteration 72/300\n",
            "Iteration 73/300\n",
            "Iteration 74/300\n",
            "Iteration 75/300\n",
            "Iteration 76/300\n",
            "Iteration 77/300\n",
            "Iteration 78/300\n",
            "Iteration 79/300\n",
            "Iteration 80/300\n",
            "Iteration 81/300\n",
            "Iteration 82/300\n",
            "Iteration 83/300\n",
            "Iteration 84/300\n",
            "Iteration 85/300\n",
            "Iteration 86/300\n",
            "Iteration 87/300\n",
            "Iteration 88/300\n",
            "Iteration 89/300\n",
            "Iteration 90/300\n",
            "Iteration 91/300\n",
            "Iteration 92/300\n",
            "Iteration 93/300\n",
            "Iteration 94/300\n",
            "Iteration 95/300\n",
            "Iteration 96/300\n",
            "Iteration 97/300\n",
            "Iteration 98/300\n",
            "Iteration 99/300\n",
            "Iteration 100/300\n",
            "Iteration 101/300\n",
            "Iteration 102/300\n",
            "Iteration 103/300\n",
            "Iteration 104/300\n",
            "Iteration 105/300\n",
            "Iteration 106/300\n",
            "Iteration 107/300\n",
            "Iteration 108/300\n",
            "Iteration 109/300\n",
            "Iteration 110/300\n",
            "Iteration 111/300\n",
            "Iteration 112/300\n",
            "Iteration 113/300\n",
            "Iteration 114/300\n",
            "Iteration 115/300\n",
            "Iteration 116/300\n",
            "Iteration 117/300\n",
            "Iteration 118/300\n",
            "Iteration 119/300\n",
            "Iteration 120/300\n",
            "Iteration 121/300\n",
            "Iteration 122/300\n",
            "Iteration 123/300\n",
            "Iteration 124/300\n",
            "Iteration 125/300\n",
            "Iteration 126/300\n",
            "Iteration 127/300\n",
            "Iteration 128/300\n",
            "Iteration 129/300\n",
            "Iteration 130/300\n",
            "Iteration 131/300\n",
            "Iteration 132/300\n",
            "Iteration 133/300\n",
            "Iteration 134/300\n",
            "Iteration 135/300\n",
            "Iteration 136/300\n",
            "Iteration 137/300\n",
            "Iteration 138/300\n",
            "Iteration 139/300\n",
            "Iteration 140/300\n",
            "Iteration 141/300\n",
            "Iteration 142/300\n",
            "Iteration 143/300\n",
            "Iteration 144/300\n",
            "Iteration 145/300\n",
            "Iteration 146/300\n",
            "Iteration 147/300\n",
            "Iteration 148/300\n",
            "Iteration 149/300\n",
            "Iteration 150/300\n",
            "Iteration 151/300\n",
            "Iteration 152/300\n",
            "Iteration 153/300\n",
            "Iteration 154/300\n",
            "Iteration 155/300\n",
            "Iteration 156/300\n",
            "Iteration 157/300\n",
            "Iteration 158/300\n",
            "Iteration 159/300\n",
            "Iteration 160/300\n",
            "Iteration 161/300\n",
            "Iteration 162/300\n",
            "Iteration 163/300\n",
            "Iteration 164/300\n",
            "Iteration 165/300\n",
            "Iteration 166/300\n",
            "Iteration 167/300\n",
            "Iteration 168/300\n",
            "Iteration 169/300\n",
            "Iteration 170/300\n",
            "Iteration 171/300\n",
            "Iteration 172/300\n",
            "Iteration 173/300\n",
            "Iteration 174/300\n",
            "Iteration 175/300\n",
            "Iteration 176/300\n",
            "Iteration 177/300\n",
            "Iteration 178/300\n",
            "Iteration 179/300\n",
            "Iteration 180/300\n",
            "Iteration 181/300\n",
            "Iteration 182/300\n",
            "Iteration 183/300\n",
            "Iteration 184/300\n",
            "Iteration 185/300\n",
            "Iteration 186/300\n",
            "Iteration 187/300\n",
            "Iteration 188/300\n",
            "Iteration 189/300\n",
            "Iteration 190/300\n",
            "Iteration 191/300\n",
            "Iteration 192/300\n",
            "Iteration 193/300\n",
            "Iteration 194/300\n",
            "Iteration 195/300\n",
            "Iteration 196/300\n",
            "Iteration 197/300\n",
            "Iteration 198/300\n",
            "Iteration 199/300\n",
            "Iteration 200/300\n",
            "Iteration 201/300\n",
            "Iteration 202/300\n",
            "Iteration 203/300\n",
            "Iteration 204/300\n",
            "Iteration 205/300\n",
            "Iteration 206/300\n",
            "Iteration 207/300\n",
            "Iteration 208/300\n",
            "Iteration 209/300\n",
            "Iteration 210/300\n",
            "Iteration 211/300\n",
            "Iteration 212/300\n",
            "Iteration 213/300\n",
            "Iteration 214/300\n",
            "Iteration 215/300\n",
            "Iteration 216/300\n",
            "Iteration 217/300\n",
            "Iteration 218/300\n",
            "Iteration 219/300\n",
            "Iteration 220/300\n",
            "Iteration 221/300\n",
            "Iteration 222/300\n",
            "Iteration 223/300\n",
            "Iteration 224/300\n",
            "Iteration 225/300\n",
            "Iteration 226/300\n",
            "Iteration 227/300\n",
            "Iteration 228/300\n",
            "Iteration 229/300\n",
            "Iteration 230/300\n",
            "Iteration 231/300\n",
            "Iteration 232/300\n",
            "Iteration 233/300\n",
            "Iteration 234/300\n",
            "Iteration 235/300\n",
            "Iteration 236/300\n",
            "Iteration 237/300\n",
            "Iteration 238/300\n",
            "Iteration 239/300\n",
            "Iteration 240/300\n",
            "Iteration 241/300\n",
            "Iteration 242/300\n",
            "Iteration 243/300\n",
            "Iteration 244/300\n",
            "Iteration 245/300\n",
            "Iteration 246/300\n",
            "Iteration 247/300\n",
            "Iteration 248/300\n",
            "Iteration 249/300\n",
            "Iteration 250/300\n",
            "Iteration 251/300\n",
            "Iteration 252/300\n",
            "Iteration 253/300\n",
            "Iteration 254/300\n",
            "Iteration 255/300\n",
            "Iteration 256/300\n",
            "Iteration 257/300\n",
            "Iteration 258/300\n",
            "Iteration 259/300\n",
            "Iteration 260/300\n",
            "Iteration 261/300\n",
            "Iteration 262/300\n",
            "Iteration 263/300\n",
            "Iteration 264/300\n",
            "Iteration 265/300\n",
            "Iteration 266/300\n",
            "Iteration 267/300\n",
            "Iteration 268/300\n",
            "Iteration 269/300\n",
            "Iteration 270/300\n",
            "Iteration 271/300\n",
            "Iteration 272/300\n",
            "Iteration 273/300\n",
            "Iteration 274/300\n",
            "Iteration 275/300\n",
            "Iteration 276/300\n",
            "Iteration 277/300\n",
            "Iteration 278/300\n",
            "Iteration 279/300\n",
            "Iteration 280/300\n",
            "Iteration 281/300\n",
            "Iteration 282/300\n",
            "Iteration 283/300\n",
            "Iteration 284/300\n",
            "Iteration 285/300\n",
            "Iteration 286/300\n",
            "Iteration 287/300\n",
            "Iteration 288/300\n",
            "Iteration 289/300\n",
            "Iteration 290/300\n",
            "Iteration 291/300\n",
            "Iteration 292/300\n",
            "Iteration 293/300\n",
            "Iteration 294/300\n",
            "Iteration 295/300\n",
            "Iteration 296/300\n",
            "Iteration 297/300\n",
            "Iteration 298/300\n",
            "Iteration 299/300\n",
            "Iteration 300/300\n",
            "/content/nnti-project-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing iHVP for full test set\n",
        "test_ihvps = []\n",
        "ihvp = compute_test_ihvp_all(regression_model, test_dataloader, combined_train_dataloader,\n",
        "                          num_samples=300, num_repeats=5, criterion=criterion)\n",
        "test_ihvps.append(ihvp)\n",
        "\n",
        "# Save the iHVP\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "torch.save(test_ihvps, f\"test_ihvps_full_set.pt\")\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "4TZCIucZjNeb",
        "outputId": "0cc1b1cb-32d7-49c2-ded3-1225e77bd28c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing iHVP...\n",
            "Repeat 1/5\n",
            "Iteration 1/300\n",
            "Iteration 2/300\n",
            "Iteration 3/300\n",
            "Iteration 4/300\n",
            "Iteration 5/300\n",
            "Iteration 6/300\n",
            "Iteration 7/300\n",
            "Iteration 8/300\n",
            "Iteration 9/300\n",
            "Iteration 10/300\n",
            "Iteration 11/300\n",
            "Iteration 12/300\n",
            "Iteration 13/300\n",
            "Iteration 14/300\n",
            "Iteration 15/300\n",
            "Iteration 16/300\n",
            "Iteration 17/300\n",
            "Iteration 18/300\n",
            "Iteration 19/300\n",
            "Iteration 20/300\n",
            "Iteration 21/300\n",
            "Iteration 22/300\n",
            "Iteration 23/300\n",
            "Iteration 24/300\n",
            "Iteration 25/300\n",
            "Iteration 26/300\n",
            "Iteration 27/300\n",
            "Iteration 28/300\n",
            "Iteration 29/300\n",
            "Iteration 30/300\n",
            "Iteration 31/300\n",
            "Iteration 32/300\n",
            "Iteration 33/300\n",
            "Iteration 34/300\n",
            "Iteration 35/300\n",
            "Iteration 36/300\n",
            "Iteration 37/300\n",
            "Iteration 38/300\n",
            "Iteration 39/300\n",
            "Iteration 40/300\n",
            "Iteration 41/300\n",
            "Iteration 42/300\n",
            "Iteration 43/300\n",
            "Iteration 44/300\n",
            "Iteration 45/300\n",
            "Iteration 46/300\n",
            "Iteration 47/300\n",
            "Iteration 48/300\n",
            "Iteration 49/300\n",
            "Iteration 50/300\n",
            "Iteration 51/300\n",
            "Iteration 52/300\n",
            "Iteration 53/300\n",
            "Iteration 54/300\n",
            "Iteration 55/300\n",
            "Iteration 56/300\n",
            "Iteration 57/300\n",
            "Iteration 58/300\n",
            "Iteration 59/300\n",
            "Iteration 60/300\n",
            "Iteration 61/300\n",
            "Iteration 62/300\n",
            "Iteration 63/300\n",
            "Iteration 64/300\n",
            "Iteration 65/300\n",
            "Iteration 66/300\n",
            "Iteration 67/300\n",
            "Iteration 68/300\n",
            "Iteration 69/300\n",
            "Iteration 70/300\n",
            "Iteration 71/300\n",
            "Iteration 72/300\n",
            "Iteration 73/300\n",
            "Iteration 74/300\n",
            "Iteration 75/300\n",
            "Iteration 76/300\n",
            "Iteration 77/300\n",
            "Iteration 78/300\n",
            "Iteration 79/300\n",
            "Iteration 80/300\n",
            "Iteration 81/300\n",
            "Iteration 82/300\n",
            "Iteration 83/300\n",
            "Iteration 84/300\n",
            "Iteration 85/300\n",
            "Iteration 86/300\n",
            "Iteration 87/300\n",
            "Iteration 88/300\n",
            "Iteration 89/300\n",
            "Iteration 90/300\n",
            "Iteration 91/300\n",
            "Iteration 92/300\n",
            "Iteration 93/300\n",
            "Iteration 94/300\n",
            "Iteration 95/300\n",
            "Iteration 96/300\n",
            "Iteration 97/300\n",
            "Iteration 98/300\n",
            "Iteration 99/300\n",
            "Iteration 100/300\n",
            "Iteration 101/300\n",
            "Iteration 102/300\n",
            "Iteration 103/300\n",
            "Iteration 104/300\n",
            "Iteration 105/300\n",
            "Iteration 106/300\n",
            "Iteration 107/300\n",
            "Iteration 108/300\n",
            "Iteration 109/300\n",
            "Iteration 110/300\n",
            "Iteration 111/300\n",
            "Iteration 112/300\n",
            "Iteration 113/300\n",
            "Iteration 114/300\n",
            "Iteration 115/300\n",
            "Iteration 116/300\n",
            "Iteration 117/300\n",
            "Iteration 118/300\n",
            "Iteration 119/300\n",
            "Iteration 120/300\n",
            "Iteration 121/300\n",
            "Iteration 122/300\n",
            "Iteration 123/300\n",
            "Iteration 124/300\n",
            "Iteration 125/300\n",
            "Iteration 126/300\n",
            "Iteration 127/300\n",
            "Iteration 128/300\n",
            "Iteration 129/300\n",
            "Iteration 130/300\n",
            "Iteration 131/300\n",
            "Iteration 132/300\n",
            "Iteration 133/300\n",
            "Iteration 134/300\n",
            "Iteration 135/300\n",
            "Iteration 136/300\n",
            "Iteration 137/300\n",
            "Iteration 138/300\n",
            "Iteration 139/300\n",
            "Iteration 140/300\n",
            "Iteration 141/300\n",
            "Iteration 142/300\n",
            "Iteration 143/300\n",
            "Iteration 144/300\n",
            "Iteration 145/300\n",
            "Iteration 146/300\n",
            "Iteration 147/300\n",
            "Iteration 148/300\n",
            "Iteration 149/300\n",
            "Iteration 150/300\n",
            "Iteration 151/300\n",
            "Iteration 152/300\n",
            "Iteration 153/300\n",
            "Iteration 154/300\n",
            "Iteration 155/300\n",
            "Iteration 156/300\n",
            "Iteration 157/300\n",
            "Iteration 158/300\n",
            "Iteration 159/300\n",
            "Iteration 160/300\n",
            "Iteration 161/300\n",
            "Iteration 162/300\n",
            "Iteration 163/300\n",
            "Iteration 164/300\n",
            "Iteration 165/300\n",
            "Iteration 166/300\n",
            "Iteration 167/300\n",
            "Iteration 168/300\n",
            "Iteration 169/300\n",
            "Iteration 170/300\n",
            "Iteration 171/300\n",
            "Iteration 172/300\n",
            "Iteration 173/300\n",
            "Iteration 174/300\n",
            "Iteration 175/300\n",
            "Iteration 176/300\n",
            "Iteration 177/300\n",
            "Iteration 178/300\n",
            "Iteration 179/300\n",
            "Iteration 180/300\n",
            "Iteration 181/300\n",
            "Iteration 182/300\n",
            "Iteration 183/300\n",
            "Iteration 184/300\n",
            "Iteration 185/300\n",
            "Iteration 186/300\n",
            "Iteration 187/300\n",
            "Iteration 188/300\n",
            "Iteration 189/300\n",
            "Iteration 190/300\n",
            "Iteration 191/300\n",
            "Iteration 192/300\n",
            "Iteration 193/300\n",
            "Iteration 194/300\n",
            "Iteration 195/300\n",
            "Iteration 196/300\n",
            "Iteration 197/300\n",
            "Iteration 198/300\n",
            "Iteration 199/300\n",
            "Iteration 200/300\n",
            "Iteration 201/300\n",
            "Iteration 202/300\n",
            "Iteration 203/300\n",
            "Iteration 204/300\n",
            "Iteration 205/300\n",
            "Iteration 206/300\n",
            "Iteration 207/300\n",
            "Iteration 208/300\n",
            "Iteration 209/300\n",
            "Iteration 210/300\n",
            "Iteration 211/300\n",
            "Iteration 212/300\n",
            "Iteration 213/300\n",
            "Iteration 214/300\n",
            "Iteration 215/300\n",
            "Iteration 216/300\n",
            "Iteration 217/300\n",
            "Iteration 218/300\n",
            "Iteration 219/300\n",
            "Iteration 220/300\n",
            "Iteration 221/300\n",
            "Iteration 222/300\n",
            "Iteration 223/300\n",
            "Iteration 224/300\n",
            "Iteration 225/300\n",
            "Iteration 226/300\n",
            "Iteration 227/300\n",
            "Iteration 228/300\n",
            "Iteration 229/300\n",
            "Iteration 230/300\n",
            "Iteration 231/300\n",
            "Iteration 232/300\n",
            "Iteration 233/300\n",
            "Iteration 234/300\n",
            "Iteration 235/300\n",
            "Iteration 236/300\n",
            "Iteration 237/300\n",
            "Iteration 238/300\n",
            "Iteration 239/300\n",
            "Iteration 240/300\n",
            "Iteration 241/300\n",
            "Iteration 242/300\n",
            "Iteration 243/300\n",
            "Iteration 244/300\n",
            "Iteration 245/300\n",
            "Iteration 246/300\n",
            "Iteration 247/300\n",
            "Iteration 248/300\n",
            "Iteration 249/300\n",
            "Iteration 250/300\n",
            "Iteration 251/300\n",
            "Iteration 252/300\n",
            "Iteration 253/300\n",
            "Iteration 254/300\n",
            "Iteration 255/300\n",
            "Iteration 256/300\n",
            "Iteration 257/300\n",
            "Iteration 258/300\n",
            "Iteration 259/300\n",
            "Iteration 260/300\n",
            "Iteration 261/300\n",
            "Iteration 262/300\n",
            "Iteration 263/300\n",
            "Iteration 264/300\n",
            "Iteration 265/300\n",
            "Iteration 266/300\n",
            "Iteration 267/300\n",
            "Iteration 268/300\n",
            "Iteration 269/300\n",
            "Iteration 270/300\n",
            "Iteration 271/300\n",
            "Iteration 272/300\n",
            "Iteration 273/300\n",
            "Iteration 274/300\n",
            "Iteration 275/300\n",
            "Iteration 276/300\n",
            "Iteration 277/300\n",
            "Iteration 278/300\n",
            "Iteration 279/300\n",
            "Iteration 280/300\n",
            "Iteration 281/300\n",
            "Iteration 282/300\n",
            "Iteration 283/300\n",
            "Iteration 284/300\n",
            "Iteration 285/300\n",
            "Iteration 286/300\n",
            "Iteration 287/300\n",
            "Iteration 288/300\n",
            "Iteration 289/300\n",
            "Iteration 290/300\n",
            "Iteration 291/300\n",
            "Iteration 292/300\n",
            "Iteration 293/300\n",
            "Iteration 294/300\n",
            "Iteration 295/300\n",
            "Iteration 296/300\n",
            "Iteration 297/300\n",
            "Iteration 298/300\n",
            "Iteration 299/300\n",
            "Iteration 300/300\n",
            "Repeat 2/5\n",
            "Iteration 1/300\n",
            "Iteration 2/300\n",
            "Iteration 3/300\n",
            "Iteration 4/300\n",
            "Iteration 5/300\n",
            "Iteration 6/300\n",
            "Iteration 7/300\n",
            "Iteration 8/300\n",
            "Iteration 9/300\n",
            "Iteration 10/300\n",
            "Iteration 11/300\n",
            "Iteration 12/300\n",
            "Iteration 13/300\n",
            "Iteration 14/300\n",
            "Iteration 15/300\n",
            "Iteration 16/300\n",
            "Iteration 17/300\n",
            "Iteration 18/300\n",
            "Iteration 19/300\n",
            "Iteration 20/300\n",
            "Iteration 21/300\n",
            "Iteration 22/300\n",
            "Iteration 23/300\n",
            "Iteration 24/300\n",
            "Iteration 25/300\n",
            "Iteration 26/300\n",
            "Iteration 27/300\n",
            "Iteration 28/300\n",
            "Iteration 29/300\n",
            "Iteration 30/300\n",
            "Iteration 31/300\n",
            "Iteration 32/300\n",
            "Iteration 33/300\n",
            "Iteration 34/300\n",
            "Iteration 35/300\n",
            "Iteration 36/300\n",
            "Iteration 37/300\n",
            "Iteration 38/300\n",
            "Iteration 39/300\n",
            "Iteration 40/300\n",
            "Iteration 41/300\n",
            "Iteration 42/300\n",
            "Iteration 43/300\n",
            "Iteration 44/300\n",
            "Iteration 45/300\n",
            "Iteration 46/300\n",
            "Iteration 47/300\n",
            "Iteration 48/300\n",
            "Iteration 49/300\n",
            "Iteration 50/300\n",
            "Iteration 51/300\n",
            "Iteration 52/300\n",
            "Iteration 53/300\n",
            "Iteration 54/300\n",
            "Iteration 55/300\n",
            "Iteration 56/300\n",
            "Iteration 57/300\n",
            "Iteration 58/300\n",
            "Iteration 59/300\n",
            "Iteration 60/300\n",
            "Iteration 61/300\n",
            "Iteration 62/300\n",
            "Iteration 63/300\n",
            "Iteration 64/300\n",
            "Iteration 65/300\n",
            "Iteration 66/300\n",
            "Iteration 67/300\n",
            "Iteration 68/300\n",
            "Iteration 69/300\n",
            "Iteration 70/300\n",
            "Iteration 71/300\n",
            "Iteration 72/300\n",
            "Iteration 73/300\n",
            "Iteration 74/300\n",
            "Iteration 75/300\n",
            "Iteration 76/300\n",
            "Iteration 77/300\n",
            "Iteration 78/300\n",
            "Iteration 79/300\n",
            "Iteration 80/300\n",
            "Iteration 81/300\n",
            "Iteration 82/300\n",
            "Iteration 83/300\n",
            "Iteration 84/300\n",
            "Iteration 85/300\n",
            "Iteration 86/300\n",
            "Iteration 87/300\n",
            "Iteration 88/300\n",
            "Iteration 89/300\n",
            "Iteration 90/300\n",
            "Iteration 91/300\n",
            "Iteration 92/300\n",
            "Iteration 93/300\n",
            "Iteration 94/300\n",
            "Iteration 95/300\n",
            "Iteration 96/300\n",
            "Iteration 97/300\n",
            "Iteration 98/300\n",
            "Iteration 99/300\n",
            "Iteration 100/300\n",
            "Iteration 101/300\n",
            "Iteration 102/300\n",
            "Iteration 103/300\n",
            "Iteration 104/300\n",
            "Iteration 105/300\n",
            "Iteration 106/300\n",
            "Iteration 107/300\n",
            "Iteration 108/300\n",
            "Iteration 109/300\n",
            "Iteration 110/300\n",
            "Iteration 111/300\n",
            "Iteration 112/300\n",
            "Iteration 113/300\n",
            "Iteration 114/300\n",
            "Iteration 115/300\n",
            "Iteration 116/300\n",
            "Iteration 117/300\n",
            "Iteration 118/300\n",
            "Iteration 119/300\n",
            "Iteration 120/300\n",
            "Iteration 121/300\n",
            "Iteration 122/300\n",
            "Iteration 123/300\n",
            "Iteration 124/300\n",
            "Iteration 125/300\n",
            "Iteration 126/300\n",
            "Iteration 127/300\n",
            "Iteration 128/300\n",
            "Iteration 129/300\n",
            "Iteration 130/300\n",
            "Iteration 131/300\n",
            "Iteration 132/300\n",
            "Iteration 133/300\n",
            "Iteration 134/300\n",
            "Iteration 135/300\n",
            "Iteration 136/300\n",
            "Iteration 137/300\n",
            "Iteration 138/300\n",
            "Iteration 139/300\n",
            "Iteration 140/300\n",
            "Iteration 141/300\n",
            "Iteration 142/300\n",
            "Iteration 143/300\n",
            "Iteration 144/300\n",
            "Iteration 145/300\n",
            "Iteration 146/300\n",
            "Iteration 147/300\n",
            "Iteration 148/300\n",
            "Iteration 149/300\n",
            "Iteration 150/300\n",
            "Iteration 151/300\n",
            "Iteration 152/300\n",
            "Iteration 153/300\n",
            "Iteration 154/300\n",
            "Iteration 155/300\n",
            "Iteration 156/300\n",
            "Iteration 157/300\n",
            "Iteration 158/300\n",
            "Iteration 159/300\n",
            "Iteration 160/300\n",
            "Iteration 161/300\n",
            "Iteration 162/300\n",
            "Iteration 163/300\n",
            "Iteration 164/300\n",
            "Iteration 165/300\n",
            "Iteration 166/300\n",
            "Iteration 167/300\n",
            "Iteration 168/300\n",
            "Iteration 169/300\n",
            "Iteration 170/300\n",
            "Iteration 171/300\n",
            "Iteration 172/300\n",
            "Iteration 173/300\n",
            "Iteration 174/300\n",
            "Iteration 175/300\n",
            "Iteration 176/300\n",
            "Iteration 177/300\n",
            "Iteration 178/300\n",
            "Iteration 179/300\n",
            "Iteration 180/300\n",
            "Iteration 181/300\n",
            "Iteration 182/300\n",
            "Iteration 183/300\n",
            "Iteration 184/300\n",
            "Iteration 185/300\n",
            "Iteration 186/300\n",
            "Iteration 187/300\n",
            "Iteration 188/300\n",
            "Iteration 189/300\n",
            "Iteration 190/300\n",
            "Iteration 191/300\n",
            "Iteration 192/300\n",
            "Iteration 193/300\n",
            "Iteration 194/300\n",
            "Iteration 195/300\n",
            "Iteration 196/300\n",
            "Iteration 197/300\n",
            "Iteration 198/300\n",
            "Iteration 199/300\n",
            "Iteration 200/300\n",
            "Iteration 201/300\n",
            "Iteration 202/300\n",
            "Iteration 203/300\n",
            "Iteration 204/300\n",
            "Iteration 205/300\n",
            "Iteration 206/300\n",
            "Iteration 207/300\n",
            "Iteration 208/300\n",
            "Iteration 209/300\n",
            "Iteration 210/300\n",
            "Iteration 211/300\n",
            "Iteration 212/300\n",
            "Iteration 213/300\n",
            "Iteration 214/300\n",
            "Iteration 215/300\n",
            "Iteration 216/300\n",
            "Iteration 217/300\n",
            "Iteration 218/300\n",
            "Iteration 219/300\n",
            "Iteration 220/300\n",
            "Iteration 221/300\n",
            "Iteration 222/300\n",
            "Iteration 223/300\n",
            "Iteration 224/300\n",
            "Iteration 225/300\n",
            "Iteration 226/300\n",
            "Iteration 227/300\n",
            "Iteration 228/300\n",
            "Iteration 229/300\n",
            "Iteration 230/300\n",
            "Iteration 231/300\n",
            "Iteration 232/300\n",
            "Iteration 233/300\n",
            "Iteration 234/300\n",
            "Iteration 235/300\n",
            "Iteration 236/300\n",
            "Iteration 237/300\n",
            "Iteration 238/300\n",
            "Iteration 239/300\n",
            "Iteration 240/300\n",
            "Iteration 241/300\n",
            "Iteration 242/300\n",
            "Iteration 243/300\n",
            "Iteration 244/300\n",
            "Iteration 245/300\n",
            "Iteration 246/300\n",
            "Iteration 247/300\n",
            "Iteration 248/300\n",
            "Iteration 249/300\n",
            "Iteration 250/300\n",
            "Iteration 251/300\n",
            "Iteration 252/300\n",
            "Iteration 253/300\n",
            "Iteration 254/300\n",
            "Iteration 255/300\n",
            "Iteration 256/300\n",
            "Iteration 257/300\n",
            "Iteration 258/300\n",
            "Iteration 259/300\n",
            "Iteration 260/300\n",
            "Iteration 261/300\n",
            "Iteration 262/300\n",
            "Iteration 263/300\n",
            "Iteration 264/300\n",
            "Iteration 265/300\n",
            "Iteration 266/300\n",
            "Iteration 267/300\n",
            "Iteration 268/300\n",
            "Iteration 269/300\n",
            "Iteration 270/300\n",
            "Iteration 271/300\n",
            "Iteration 272/300\n",
            "Iteration 273/300\n",
            "Iteration 274/300\n",
            "Iteration 275/300\n",
            "Iteration 276/300\n",
            "Iteration 277/300\n",
            "Iteration 278/300\n",
            "Iteration 279/300\n",
            "Iteration 280/300\n",
            "Iteration 281/300\n",
            "Iteration 282/300\n",
            "Iteration 283/300\n",
            "Iteration 284/300\n",
            "Iteration 285/300\n",
            "Iteration 286/300\n",
            "Iteration 287/300\n",
            "Iteration 288/300\n",
            "Iteration 289/300\n",
            "Iteration 290/300\n",
            "Iteration 291/300\n",
            "Iteration 292/300\n",
            "Iteration 293/300\n",
            "Iteration 294/300\n",
            "Iteration 295/300\n",
            "Iteration 296/300\n",
            "Iteration 297/300\n",
            "Iteration 298/300\n",
            "Iteration 299/300\n",
            "Iteration 300/300\n",
            "Repeat 3/5\n",
            "Iteration 1/300\n",
            "Iteration 2/300\n",
            "Iteration 3/300\n",
            "Iteration 4/300\n",
            "Iteration 5/300\n",
            "Iteration 6/300\n",
            "Iteration 7/300\n",
            "Iteration 8/300\n",
            "Iteration 9/300\n",
            "Iteration 10/300\n",
            "Iteration 11/300\n",
            "Iteration 12/300\n",
            "Iteration 13/300\n",
            "Iteration 14/300\n",
            "Iteration 15/300\n",
            "Iteration 16/300\n",
            "Iteration 17/300\n",
            "Iteration 18/300\n",
            "Iteration 19/300\n",
            "Iteration 20/300\n",
            "Iteration 21/300\n",
            "Iteration 22/300\n",
            "Iteration 23/300\n",
            "Iteration 24/300\n",
            "Iteration 25/300\n",
            "Iteration 26/300\n",
            "Iteration 27/300\n",
            "Iteration 28/300\n",
            "Iteration 29/300\n",
            "Iteration 30/300\n",
            "Iteration 31/300\n",
            "Iteration 32/300\n",
            "Iteration 33/300\n",
            "Iteration 34/300\n",
            "Iteration 35/300\n",
            "Iteration 36/300\n",
            "Iteration 37/300\n",
            "Iteration 38/300\n",
            "Iteration 39/300\n",
            "Iteration 40/300\n",
            "Iteration 41/300\n",
            "Iteration 42/300\n",
            "Iteration 43/300\n",
            "Iteration 44/300\n",
            "Iteration 45/300\n",
            "Iteration 46/300\n",
            "Iteration 47/300\n",
            "Iteration 48/300\n",
            "Iteration 49/300\n",
            "Iteration 50/300\n",
            "Iteration 51/300\n",
            "Iteration 52/300\n",
            "Iteration 53/300\n",
            "Iteration 54/300\n",
            "Iteration 55/300\n",
            "Iteration 56/300\n",
            "Iteration 57/300\n",
            "Iteration 58/300\n",
            "Iteration 59/300\n",
            "Iteration 60/300\n",
            "Iteration 61/300\n",
            "Iteration 62/300\n",
            "Iteration 63/300\n",
            "Iteration 64/300\n",
            "Iteration 65/300\n",
            "Iteration 66/300\n",
            "Iteration 67/300\n",
            "Iteration 68/300\n",
            "Iteration 69/300\n",
            "Iteration 70/300\n",
            "Iteration 71/300\n",
            "Iteration 72/300\n",
            "Iteration 73/300\n",
            "Iteration 74/300\n",
            "Iteration 75/300\n",
            "Iteration 76/300\n",
            "Iteration 77/300\n",
            "Iteration 78/300\n",
            "Iteration 79/300\n",
            "Iteration 80/300\n",
            "Iteration 81/300\n",
            "Iteration 82/300\n",
            "Iteration 83/300\n",
            "Iteration 84/300\n",
            "Iteration 85/300\n",
            "Iteration 86/300\n",
            "Iteration 87/300\n",
            "Iteration 88/300\n",
            "Iteration 89/300\n",
            "Iteration 90/300\n",
            "Iteration 91/300\n",
            "Iteration 92/300\n",
            "Iteration 93/300\n",
            "Iteration 94/300\n",
            "Iteration 95/300\n",
            "Iteration 96/300\n",
            "Iteration 97/300\n",
            "Iteration 98/300\n",
            "Iteration 99/300\n",
            "Iteration 100/300\n",
            "Iteration 101/300\n",
            "Iteration 102/300\n",
            "Iteration 103/300\n",
            "Iteration 104/300\n",
            "Iteration 105/300\n",
            "Iteration 106/300\n",
            "Iteration 107/300\n",
            "Iteration 108/300\n",
            "Iteration 109/300\n",
            "Iteration 110/300\n",
            "Iteration 111/300\n",
            "Iteration 112/300\n",
            "Iteration 113/300\n",
            "Iteration 114/300\n",
            "Iteration 115/300\n",
            "Iteration 116/300\n",
            "Iteration 117/300\n",
            "Iteration 118/300\n",
            "Iteration 119/300\n",
            "Iteration 120/300\n",
            "Iteration 121/300\n",
            "Iteration 122/300\n",
            "Iteration 123/300\n",
            "Iteration 124/300\n",
            "Iteration 125/300\n",
            "Iteration 126/300\n",
            "Iteration 127/300\n",
            "Iteration 128/300\n",
            "Iteration 129/300\n",
            "Iteration 130/300\n",
            "Iteration 131/300\n",
            "Iteration 132/300\n",
            "Iteration 133/300\n",
            "Iteration 134/300\n",
            "Iteration 135/300\n",
            "Iteration 136/300\n",
            "Iteration 137/300\n",
            "Iteration 138/300\n",
            "Iteration 139/300\n",
            "Iteration 140/300\n",
            "Iteration 141/300\n",
            "Iteration 142/300\n",
            "Iteration 143/300\n",
            "Iteration 144/300\n",
            "Iteration 145/300\n",
            "Iteration 146/300\n",
            "Iteration 147/300\n",
            "Iteration 148/300\n",
            "Iteration 149/300\n",
            "Iteration 150/300\n",
            "Iteration 151/300\n",
            "Iteration 152/300\n",
            "Iteration 153/300\n",
            "Iteration 154/300\n",
            "Iteration 155/300\n",
            "Iteration 156/300\n",
            "Iteration 157/300\n",
            "Iteration 158/300\n",
            "Iteration 159/300\n",
            "Iteration 160/300\n",
            "Iteration 161/300\n",
            "Iteration 162/300\n",
            "Iteration 163/300\n",
            "Iteration 164/300\n",
            "Iteration 165/300\n",
            "Iteration 166/300\n",
            "Iteration 167/300\n",
            "Iteration 168/300\n",
            "Iteration 169/300\n",
            "Iteration 170/300\n",
            "Iteration 171/300\n",
            "Iteration 172/300\n",
            "Iteration 173/300\n",
            "Iteration 174/300\n",
            "Iteration 175/300\n",
            "Iteration 176/300\n",
            "Iteration 177/300\n",
            "Iteration 178/300\n",
            "Iteration 179/300\n",
            "Iteration 180/300\n",
            "Iteration 181/300\n",
            "Iteration 182/300\n",
            "Iteration 183/300\n",
            "Iteration 184/300\n",
            "Iteration 185/300\n",
            "Iteration 186/300\n",
            "Iteration 187/300\n",
            "Iteration 188/300\n",
            "Iteration 189/300\n",
            "Iteration 190/300\n",
            "Iteration 191/300\n",
            "Iteration 192/300\n",
            "Iteration 193/300\n",
            "Iteration 194/300\n",
            "Iteration 195/300\n",
            "Iteration 196/300\n",
            "Iteration 197/300\n",
            "Iteration 198/300\n",
            "Iteration 199/300\n",
            "Iteration 200/300\n",
            "Iteration 201/300\n",
            "Iteration 202/300\n",
            "Iteration 203/300\n",
            "Iteration 204/300\n",
            "Iteration 205/300\n",
            "Iteration 206/300\n",
            "Iteration 207/300\n",
            "Iteration 208/300\n",
            "Iteration 209/300\n",
            "Iteration 210/300\n",
            "Iteration 211/300\n",
            "Iteration 212/300\n",
            "Iteration 213/300\n",
            "Iteration 214/300\n",
            "Iteration 215/300\n",
            "Iteration 216/300\n",
            "Iteration 217/300\n",
            "Iteration 218/300\n",
            "Iteration 219/300\n",
            "Iteration 220/300\n",
            "Iteration 221/300\n",
            "Iteration 222/300\n",
            "Iteration 223/300\n",
            "Iteration 224/300\n",
            "Iteration 225/300\n",
            "Iteration 226/300\n",
            "Iteration 227/300\n",
            "Iteration 228/300\n",
            "Iteration 229/300\n",
            "Iteration 230/300\n",
            "Iteration 231/300\n",
            "Iteration 232/300\n",
            "Iteration 233/300\n",
            "Iteration 234/300\n",
            "Iteration 235/300\n",
            "Iteration 236/300\n",
            "Iteration 237/300\n",
            "Iteration 238/300\n",
            "Iteration 239/300\n",
            "Iteration 240/300\n",
            "Iteration 241/300\n",
            "Iteration 242/300\n",
            "Iteration 243/300\n",
            "Iteration 244/300\n",
            "Iteration 245/300\n",
            "Iteration 246/300\n",
            "Iteration 247/300\n",
            "Iteration 248/300\n",
            "Iteration 249/300\n",
            "Iteration 250/300\n",
            "Iteration 251/300\n",
            "Iteration 252/300\n",
            "Iteration 253/300\n",
            "Iteration 254/300\n",
            "Iteration 255/300\n",
            "Iteration 256/300\n",
            "Iteration 257/300\n",
            "Iteration 258/300\n",
            "Iteration 259/300\n",
            "Iteration 260/300\n",
            "Iteration 261/300\n",
            "Iteration 262/300\n",
            "Iteration 263/300\n",
            "Iteration 264/300\n",
            "Iteration 265/300\n",
            "Iteration 266/300\n",
            "Iteration 267/300\n",
            "Iteration 268/300\n",
            "Iteration 269/300\n",
            "Iteration 270/300\n",
            "Iteration 271/300\n",
            "Iteration 272/300\n",
            "Iteration 273/300\n",
            "Iteration 274/300\n",
            "Iteration 275/300\n",
            "Iteration 276/300\n",
            "Iteration 277/300\n",
            "Iteration 278/300\n",
            "Iteration 279/300\n",
            "Iteration 280/300\n",
            "Iteration 281/300\n",
            "Iteration 282/300\n",
            "Iteration 283/300\n",
            "Iteration 284/300\n",
            "Iteration 285/300\n",
            "Iteration 286/300\n",
            "Iteration 287/300\n",
            "Iteration 288/300\n",
            "Iteration 289/300\n",
            "Iteration 290/300\n",
            "Iteration 291/300\n",
            "Iteration 292/300\n",
            "Iteration 293/300\n",
            "Iteration 294/300\n",
            "Iteration 295/300\n",
            "Iteration 296/300\n",
            "Iteration 297/300\n",
            "Iteration 298/300\n",
            "Iteration 299/300\n",
            "Iteration 300/300\n",
            "Repeat 4/5\n",
            "Iteration 1/300\n",
            "Iteration 2/300\n",
            "Iteration 3/300\n",
            "Iteration 4/300\n",
            "Iteration 5/300\n",
            "Iteration 6/300\n",
            "Iteration 7/300\n",
            "Iteration 8/300\n",
            "Iteration 9/300\n",
            "Iteration 10/300\n",
            "Iteration 11/300\n",
            "Iteration 12/300\n",
            "Iteration 13/300\n",
            "Iteration 14/300\n",
            "Iteration 15/300\n",
            "Iteration 16/300\n",
            "Iteration 17/300\n",
            "Iteration 18/300\n",
            "Iteration 19/300\n",
            "Iteration 20/300\n",
            "Iteration 21/300\n",
            "Iteration 22/300\n",
            "Iteration 23/300\n",
            "Iteration 24/300\n",
            "Iteration 25/300\n",
            "Iteration 26/300\n",
            "Iteration 27/300\n",
            "Iteration 28/300\n",
            "Iteration 29/300\n",
            "Iteration 30/300\n",
            "Iteration 31/300\n",
            "Iteration 32/300\n",
            "Iteration 33/300\n",
            "Iteration 34/300\n",
            "Iteration 35/300\n",
            "Iteration 36/300\n",
            "Iteration 37/300\n",
            "Iteration 38/300\n",
            "Iteration 39/300\n",
            "Iteration 40/300\n",
            "Iteration 41/300\n",
            "Iteration 42/300\n",
            "Iteration 43/300\n",
            "Iteration 44/300\n",
            "Iteration 45/300\n",
            "Iteration 46/300\n",
            "Iteration 47/300\n",
            "Iteration 48/300\n",
            "Iteration 49/300\n",
            "Iteration 50/300\n",
            "Iteration 51/300\n",
            "Iteration 52/300\n",
            "Iteration 53/300\n",
            "Iteration 54/300\n",
            "Iteration 55/300\n",
            "Iteration 56/300\n",
            "Iteration 57/300\n",
            "Iteration 58/300\n",
            "Iteration 59/300\n",
            "Iteration 60/300\n",
            "Iteration 61/300\n",
            "Iteration 62/300\n",
            "Iteration 63/300\n",
            "Iteration 64/300\n",
            "Iteration 65/300\n",
            "Iteration 66/300\n",
            "Iteration 67/300\n",
            "Iteration 68/300\n",
            "Iteration 69/300\n",
            "Iteration 70/300\n",
            "Iteration 71/300\n",
            "Iteration 72/300\n",
            "Iteration 73/300\n",
            "Iteration 74/300\n",
            "Iteration 75/300\n",
            "Iteration 76/300\n",
            "Iteration 77/300\n",
            "Iteration 78/300\n",
            "Iteration 79/300\n",
            "Iteration 80/300\n",
            "Iteration 81/300\n",
            "Iteration 82/300\n",
            "Iteration 83/300\n",
            "Iteration 84/300\n",
            "Iteration 85/300\n",
            "Iteration 86/300\n",
            "Iteration 87/300\n",
            "Iteration 88/300\n",
            "Iteration 89/300\n",
            "Iteration 90/300\n",
            "Iteration 91/300\n",
            "Iteration 92/300\n",
            "Iteration 93/300\n",
            "Iteration 94/300\n",
            "Iteration 95/300\n",
            "Iteration 96/300\n",
            "Iteration 97/300\n",
            "Iteration 98/300\n",
            "Iteration 99/300\n",
            "Iteration 100/300\n",
            "Iteration 101/300\n",
            "Iteration 102/300\n",
            "Iteration 103/300\n",
            "Iteration 104/300\n",
            "Iteration 105/300\n",
            "Iteration 106/300\n",
            "Iteration 107/300\n",
            "Iteration 108/300\n",
            "Iteration 109/300\n",
            "Iteration 110/300\n",
            "Iteration 111/300\n",
            "Iteration 112/300\n",
            "Iteration 113/300\n",
            "Iteration 114/300\n",
            "Iteration 115/300\n",
            "Iteration 116/300\n",
            "Iteration 117/300\n",
            "Iteration 118/300\n",
            "Iteration 119/300\n",
            "Iteration 120/300\n",
            "Iteration 121/300\n",
            "Iteration 122/300\n",
            "Iteration 123/300\n",
            "Iteration 124/300\n",
            "Iteration 125/300\n",
            "Iteration 126/300\n",
            "Iteration 127/300\n",
            "Iteration 128/300\n",
            "Iteration 129/300\n",
            "Iteration 130/300\n",
            "Iteration 131/300\n",
            "Iteration 132/300\n",
            "Iteration 133/300\n",
            "Iteration 134/300\n",
            "Iteration 135/300\n",
            "Iteration 136/300\n",
            "Iteration 137/300\n",
            "Iteration 138/300\n",
            "Iteration 139/300\n",
            "Iteration 140/300\n",
            "Iteration 141/300\n",
            "Iteration 142/300\n",
            "Iteration 143/300\n",
            "Iteration 144/300\n",
            "Iteration 145/300\n",
            "Iteration 146/300\n",
            "Iteration 147/300\n",
            "Iteration 148/300\n",
            "Iteration 149/300\n",
            "Iteration 150/300\n",
            "Iteration 151/300\n",
            "Iteration 152/300\n",
            "Iteration 153/300\n",
            "Iteration 154/300\n",
            "Iteration 155/300\n",
            "Iteration 156/300\n",
            "Iteration 157/300\n",
            "Iteration 158/300\n",
            "Iteration 159/300\n",
            "Iteration 160/300\n",
            "Iteration 161/300\n",
            "Iteration 162/300\n",
            "Iteration 163/300\n",
            "Iteration 164/300\n",
            "Iteration 165/300\n",
            "Iteration 166/300\n",
            "Iteration 167/300\n",
            "Iteration 168/300\n",
            "Iteration 169/300\n",
            "Iteration 170/300\n",
            "Iteration 171/300\n",
            "Iteration 172/300\n",
            "Iteration 173/300\n",
            "Iteration 174/300\n",
            "Iteration 175/300\n",
            "Iteration 176/300\n",
            "Iteration 177/300\n",
            "Iteration 178/300\n",
            "Iteration 179/300\n",
            "Iteration 180/300\n",
            "Iteration 181/300\n",
            "Iteration 182/300\n",
            "Iteration 183/300\n",
            "Iteration 184/300\n",
            "Iteration 185/300\n",
            "Iteration 186/300\n",
            "Iteration 187/300\n",
            "Iteration 188/300\n",
            "Iteration 189/300\n",
            "Iteration 190/300\n",
            "Iteration 191/300\n",
            "Iteration 192/300\n",
            "Iteration 193/300\n",
            "Iteration 194/300\n",
            "Iteration 195/300\n",
            "Iteration 196/300\n",
            "Iteration 197/300\n",
            "Iteration 198/300\n",
            "Iteration 199/300\n",
            "Iteration 200/300\n",
            "Iteration 201/300\n",
            "Iteration 202/300\n",
            "Iteration 203/300\n",
            "Iteration 204/300\n",
            "Iteration 205/300\n",
            "Iteration 206/300\n",
            "Iteration 207/300\n",
            "Iteration 208/300\n",
            "Iteration 209/300\n",
            "Iteration 210/300\n",
            "Iteration 211/300\n",
            "Iteration 212/300\n",
            "Iteration 213/300\n",
            "Iteration 214/300\n",
            "Iteration 215/300\n",
            "Iteration 216/300\n",
            "Iteration 217/300\n",
            "Iteration 218/300\n",
            "Iteration 219/300\n",
            "Iteration 220/300\n",
            "Iteration 221/300\n",
            "Iteration 222/300\n",
            "Iteration 223/300\n",
            "Iteration 224/300\n",
            "Iteration 225/300\n",
            "Iteration 226/300\n",
            "Iteration 227/300\n",
            "Iteration 228/300\n",
            "Iteration 229/300\n",
            "Iteration 230/300\n",
            "Iteration 231/300\n",
            "Iteration 232/300\n",
            "Iteration 233/300\n",
            "Iteration 234/300\n",
            "Iteration 235/300\n",
            "Iteration 236/300\n",
            "Iteration 237/300\n",
            "Iteration 238/300\n",
            "Iteration 239/300\n",
            "Iteration 240/300\n",
            "Iteration 241/300\n",
            "Iteration 242/300\n",
            "Iteration 243/300\n",
            "Iteration 244/300\n",
            "Iteration 245/300\n",
            "Iteration 246/300\n",
            "Iteration 247/300\n",
            "Iteration 248/300\n",
            "Iteration 249/300\n",
            "Iteration 250/300\n",
            "Iteration 251/300\n",
            "Iteration 252/300\n",
            "Iteration 253/300\n",
            "Iteration 254/300\n",
            "Iteration 255/300\n",
            "Iteration 256/300\n",
            "Iteration 257/300\n",
            "Iteration 258/300\n",
            "Iteration 259/300\n",
            "Iteration 260/300\n",
            "Iteration 261/300\n",
            "Iteration 262/300\n",
            "Iteration 263/300\n",
            "Iteration 264/300\n",
            "Iteration 265/300\n",
            "Iteration 266/300\n",
            "Iteration 267/300\n",
            "Iteration 268/300\n",
            "Iteration 269/300\n",
            "Iteration 270/300\n",
            "Iteration 271/300\n",
            "Iteration 272/300\n",
            "Iteration 273/300\n",
            "Iteration 274/300\n",
            "Iteration 275/300\n",
            "Iteration 276/300\n",
            "Iteration 277/300\n",
            "Iteration 278/300\n",
            "Iteration 279/300\n",
            "Iteration 280/300\n",
            "Iteration 281/300\n",
            "Iteration 282/300\n",
            "Iteration 283/300\n",
            "Iteration 284/300\n",
            "Iteration 285/300\n",
            "Iteration 286/300\n",
            "Iteration 287/300\n",
            "Iteration 288/300\n",
            "Iteration 289/300\n",
            "Iteration 290/300\n",
            "Iteration 291/300\n",
            "Iteration 292/300\n",
            "Iteration 293/300\n",
            "Iteration 294/300\n",
            "Iteration 295/300\n",
            "Iteration 296/300\n",
            "Iteration 297/300\n",
            "Iteration 298/300\n",
            "Iteration 299/300\n",
            "Iteration 300/300\n",
            "Repeat 5/5\n",
            "Iteration 1/300\n",
            "Iteration 2/300\n",
            "Iteration 3/300\n",
            "Iteration 4/300\n",
            "Iteration 5/300\n",
            "Iteration 6/300\n",
            "Iteration 7/300\n",
            "Iteration 8/300\n",
            "Iteration 9/300\n",
            "Iteration 10/300\n",
            "Iteration 11/300\n",
            "Iteration 12/300\n",
            "Iteration 13/300\n",
            "Iteration 14/300\n",
            "Iteration 15/300\n",
            "Iteration 16/300\n",
            "Iteration 17/300\n",
            "Iteration 18/300\n",
            "Iteration 19/300\n",
            "Iteration 20/300\n",
            "Iteration 21/300\n",
            "Iteration 22/300\n",
            "Iteration 23/300\n",
            "Iteration 24/300\n",
            "Iteration 25/300\n",
            "Iteration 26/300\n",
            "Iteration 27/300\n",
            "Iteration 28/300\n",
            "Iteration 29/300\n",
            "Iteration 30/300\n",
            "Iteration 31/300\n",
            "Iteration 32/300\n",
            "Iteration 33/300\n",
            "Iteration 34/300\n",
            "Iteration 35/300\n",
            "Iteration 36/300\n",
            "Iteration 37/300\n",
            "Iteration 38/300\n",
            "Iteration 39/300\n",
            "Iteration 40/300\n",
            "Iteration 41/300\n",
            "Iteration 42/300\n",
            "Iteration 43/300\n",
            "Iteration 44/300\n",
            "Iteration 45/300\n",
            "Iteration 46/300\n",
            "Iteration 47/300\n",
            "Iteration 48/300\n",
            "Iteration 49/300\n",
            "Iteration 50/300\n",
            "Iteration 51/300\n",
            "Iteration 52/300\n",
            "Iteration 53/300\n",
            "Iteration 54/300\n",
            "Iteration 55/300\n",
            "Iteration 56/300\n",
            "Iteration 57/300\n",
            "Iteration 58/300\n",
            "Iteration 59/300\n",
            "Iteration 60/300\n",
            "Iteration 61/300\n",
            "Iteration 62/300\n",
            "Iteration 63/300\n",
            "Iteration 64/300\n",
            "Iteration 65/300\n",
            "Iteration 66/300\n",
            "Iteration 67/300\n",
            "Iteration 68/300\n",
            "Iteration 69/300\n",
            "Iteration 70/300\n",
            "Iteration 71/300\n",
            "Iteration 72/300\n",
            "Iteration 73/300\n",
            "Iteration 74/300\n",
            "Iteration 75/300\n",
            "Iteration 76/300\n",
            "Iteration 77/300\n",
            "Iteration 78/300\n",
            "Iteration 79/300\n",
            "Iteration 80/300\n",
            "Iteration 81/300\n",
            "Iteration 82/300\n",
            "Iteration 83/300\n",
            "Iteration 84/300\n",
            "Iteration 85/300\n",
            "Iteration 86/300\n",
            "Iteration 87/300\n",
            "Iteration 88/300\n",
            "Iteration 89/300\n",
            "Iteration 90/300\n",
            "Iteration 91/300\n",
            "Iteration 92/300\n",
            "Iteration 93/300\n",
            "Iteration 94/300\n",
            "Iteration 95/300\n",
            "Iteration 96/300\n",
            "Iteration 97/300\n",
            "Iteration 98/300\n",
            "Iteration 99/300\n",
            "Iteration 100/300\n",
            "Iteration 101/300\n",
            "Iteration 102/300\n",
            "Iteration 103/300\n",
            "Iteration 104/300\n",
            "Iteration 105/300\n",
            "Iteration 106/300\n",
            "Iteration 107/300\n",
            "Iteration 108/300\n",
            "Iteration 109/300\n",
            "Iteration 110/300\n",
            "Iteration 111/300\n",
            "Iteration 112/300\n",
            "Iteration 113/300\n",
            "Iteration 114/300\n",
            "Iteration 115/300\n",
            "Iteration 116/300\n",
            "Iteration 117/300\n",
            "Iteration 118/300\n",
            "Iteration 119/300\n",
            "Iteration 120/300\n",
            "Iteration 121/300\n",
            "Iteration 122/300\n",
            "Iteration 123/300\n",
            "Iteration 124/300\n",
            "Iteration 125/300\n",
            "Iteration 126/300\n",
            "Iteration 127/300\n",
            "Iteration 128/300\n",
            "Iteration 129/300\n",
            "Iteration 130/300\n",
            "Iteration 131/300\n",
            "Iteration 132/300\n",
            "Iteration 133/300\n",
            "Iteration 134/300\n",
            "Iteration 135/300\n",
            "Iteration 136/300\n",
            "Iteration 137/300\n",
            "Iteration 138/300\n",
            "Iteration 139/300\n",
            "Iteration 140/300\n",
            "Iteration 141/300\n",
            "Iteration 142/300\n",
            "Iteration 143/300\n",
            "Iteration 144/300\n",
            "Iteration 145/300\n",
            "Iteration 146/300\n",
            "Iteration 147/300\n",
            "Iteration 148/300\n",
            "Iteration 149/300\n",
            "Iteration 150/300\n",
            "Iteration 151/300\n",
            "Iteration 152/300\n",
            "Iteration 153/300\n",
            "Iteration 154/300\n",
            "Iteration 155/300\n",
            "Iteration 156/300\n",
            "Iteration 157/300\n",
            "Iteration 158/300\n",
            "Iteration 159/300\n",
            "Iteration 160/300\n",
            "Iteration 161/300\n",
            "Iteration 162/300\n",
            "Iteration 163/300\n",
            "Iteration 164/300\n",
            "Iteration 165/300\n",
            "Iteration 166/300\n",
            "Iteration 167/300\n",
            "Iteration 168/300\n",
            "Iteration 169/300\n",
            "Iteration 170/300\n",
            "Iteration 171/300\n",
            "Iteration 172/300\n",
            "Iteration 173/300\n",
            "Iteration 174/300\n",
            "Iteration 175/300\n",
            "Iteration 176/300\n",
            "Iteration 177/300\n",
            "Iteration 178/300\n",
            "Iteration 179/300\n",
            "Iteration 180/300\n",
            "Iteration 181/300\n",
            "Iteration 182/300\n",
            "Iteration 183/300\n",
            "Iteration 184/300\n",
            "Iteration 185/300\n",
            "Iteration 186/300\n",
            "Iteration 187/300\n",
            "Iteration 188/300\n",
            "Iteration 189/300\n",
            "Iteration 190/300\n",
            "Iteration 191/300\n",
            "Iteration 192/300\n",
            "Iteration 193/300\n",
            "Iteration 194/300\n",
            "Iteration 195/300\n",
            "Iteration 196/300\n",
            "Iteration 197/300\n",
            "Iteration 198/300\n",
            "Iteration 199/300\n",
            "Iteration 200/300\n",
            "Iteration 201/300\n",
            "Iteration 202/300\n",
            "Iteration 203/300\n",
            "Iteration 204/300\n",
            "Iteration 205/300\n",
            "Iteration 206/300\n",
            "Iteration 207/300\n",
            "Iteration 208/300\n",
            "Iteration 209/300\n",
            "Iteration 210/300\n",
            "Iteration 211/300\n",
            "Iteration 212/300\n",
            "Iteration 213/300\n",
            "Iteration 214/300\n",
            "Iteration 215/300\n",
            "Iteration 216/300\n",
            "Iteration 217/300\n",
            "Iteration 218/300\n",
            "Iteration 219/300\n",
            "Iteration 220/300\n",
            "Iteration 221/300\n",
            "Iteration 222/300\n",
            "Iteration 223/300\n",
            "Iteration 224/300\n",
            "Iteration 225/300\n",
            "Iteration 226/300\n",
            "Iteration 227/300\n",
            "Iteration 228/300\n",
            "Iteration 229/300\n",
            "Iteration 230/300\n",
            "Iteration 231/300\n",
            "Iteration 232/300\n",
            "Iteration 233/300\n",
            "Iteration 234/300\n",
            "Iteration 235/300\n",
            "Iteration 236/300\n",
            "Iteration 237/300\n",
            "Iteration 238/300\n",
            "Iteration 239/300\n",
            "Iteration 240/300\n",
            "Iteration 241/300\n",
            "Iteration 242/300\n",
            "Iteration 243/300\n",
            "Iteration 244/300\n",
            "Iteration 245/300\n",
            "Iteration 246/300\n",
            "Iteration 247/300\n",
            "Iteration 248/300\n",
            "Iteration 249/300\n",
            "Iteration 250/300\n",
            "Iteration 251/300\n",
            "Iteration 252/300\n",
            "Iteration 253/300\n",
            "Iteration 254/300\n",
            "Iteration 255/300\n",
            "Iteration 256/300\n",
            "Iteration 257/300\n",
            "Iteration 258/300\n",
            "Iteration 259/300\n",
            "Iteration 260/300\n",
            "Iteration 261/300\n",
            "Iteration 262/300\n",
            "Iteration 263/300\n",
            "Iteration 264/300\n",
            "Iteration 265/300\n",
            "Iteration 266/300\n",
            "Iteration 267/300\n",
            "Iteration 268/300\n",
            "Iteration 269/300\n",
            "Iteration 270/300\n",
            "Iteration 271/300\n",
            "Iteration 272/300\n",
            "Iteration 273/300\n",
            "Iteration 274/300\n",
            "Iteration 275/300\n",
            "Iteration 276/300\n",
            "Iteration 277/300\n",
            "Iteration 278/300\n",
            "Iteration 279/300\n",
            "Iteration 280/300\n",
            "Iteration 281/300\n",
            "Iteration 282/300\n",
            "Iteration 283/300\n",
            "Iteration 284/300\n",
            "Iteration 285/300\n",
            "Iteration 286/300\n",
            "Iteration 287/300\n",
            "Iteration 288/300\n",
            "Iteration 289/300\n",
            "Iteration 290/300\n",
            "Iteration 291/300\n",
            "Iteration 292/300\n",
            "Iteration 293/300\n",
            "Iteration 294/300\n",
            "Iteration 295/300\n",
            "Iteration 296/300\n",
            "Iteration 297/300\n",
            "Iteration 298/300\n",
            "Iteration 299/300\n",
            "Iteration 300/300\n",
            "/content/nnti-project-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Influence for Each External Data Point"
      ],
      "metadata": {
        "id": "K974vRa9CzfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# computing influence of each external data point on individual test samples\n",
        "# load pre-computed iHVP\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "index_ranges = [(0, 10), (10, 12)] # test sample values as stored after computing iHVP\n",
        "test_ihvps = []\n",
        "for start_idx, end_idx in index_ranges:\n",
        "    test_ihvps.extend(torch.load(f\"test_ihvps_{start_idx}_{end_idx}.pt\"))\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())\n",
        "\n",
        "# Computing influence for each sample in external dataset\n",
        "influences = []\n",
        "influences_per_test_sample = []\n",
        "for train_batch in ext_influence_dataloader:\n",
        "    print(f\"External data sample {len(influences) + 1}/{len(ext_influence_dataloader)}\")\n",
        "    train_input_ids = train_batch['input_ids'].to(device)\n",
        "    train_attention_mask = train_batch['attention_mask'].to(device)\n",
        "    train_label = train_batch['target'].to(device)\n",
        "\n",
        "    train_point = {'input_ids': train_input_ids, 'attention_mask': train_attention_mask}\n",
        "\n",
        "    # for all test points\n",
        "    influence_scores = []\n",
        "    for ihvp in test_ihvps:\n",
        "        influence = influence_by_train_point(train_point, train_label, ihvp, regression_model, criterion)\n",
        "        influence_scores.append(influence.item())\n",
        "\n",
        "    # storing all test scores separately\n",
        "    influences_per_test_sample.append({\n",
        "        \"train_index\": len(influences),\n",
        "        \"influences\": influence_scores.copy()\n",
        "    })\n",
        "    influences.append(sum(influence_scores) / len(influence_scores)) # mean influence over all test samples\n",
        "    print(f\"Influence for current training sample: {influences[-1]}\")\n",
        "\n",
        "# Rank external data points by influence\n",
        "ranked_indices = sorted(enumerate(influences), key=lambda x: x[1], reverse=True)  # sorted by influence score\n",
        "print(\"Most influential training points:\", ranked_indices)\n",
        "\n",
        "# Save the influence score\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "influence_scores = pd.DataFrame(ranked_indices, columns=[\"Index\", \"Influence Score\"])\n",
        "influence_scores.to_csv(\"ranked_indices.csv\", index=False)\n",
        "# saving the influence for for each individual test samples\n",
        "influence_scores_separate = pd.DataFrame.from_records(influences_per_test_sample)\n",
        "influence_scores_separate = influence_scores_separate.explode(\"influences\").reset_index(drop=True)\n",
        "influence_scores_separate[\"train_index\"] = influence_scores_separate[\"train_index\"].astype(int)\n",
        "influence_scores_separate[\"test_index\"] = influence_scores_separate.groupby(\"train_index\").cumcount()\n",
        "influence_scores_separate = influence_scores_separate.pivot(index=\"train_index\", columns=\"test_index\", values=\"influences\")\n",
        "influence_scores_separate.columns = [f\"Test Sample {i+1}\" for i in range(len(influence_scores_separate.columns))]\n",
        "influence_scores_separate.to_csv(\"influence_scores_separate.csv\", index=True)\n",
        "\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3tfviL9C9Ar",
        "outputId": "ed37290a-2dfe-43d2-d8d3-22868e7a061c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-1adf2833bb18>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  test_ihvps.extend(torch.load(f\"test_ihvps_{start_idx}_{end_idx}.pt\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nnti-project-25\n",
            "External data sample 1/300\n",
            "Influence for current training sample: -184609.02180989584\n",
            "External data sample 2/300\n",
            "Influence for current training sample: 103597.876953125\n",
            "External data sample 3/300\n",
            "Influence for current training sample: -316927.1953125\n",
            "External data sample 4/300\n",
            "Influence for current training sample: 289419.7955729167\n",
            "External data sample 5/300\n",
            "Influence for current training sample: -164343.64518229166\n",
            "External data sample 6/300\n",
            "Influence for current training sample: -185660.736328125\n",
            "External data sample 7/300\n",
            "Influence for current training sample: -96637.15494791667\n",
            "External data sample 8/300\n",
            "Influence for current training sample: -166085.224609375\n",
            "External data sample 9/300\n",
            "Influence for current training sample: 6098.886393229167\n",
            "External data sample 10/300\n",
            "Influence for current training sample: -179477.61783854166\n",
            "External data sample 11/300\n",
            "Influence for current training sample: -65699.0517578125\n",
            "External data sample 12/300\n",
            "Influence for current training sample: 164799.91080729166\n",
            "External data sample 13/300\n",
            "Influence for current training sample: -242736.26171875\n",
            "External data sample 14/300\n",
            "Influence for current training sample: -63341.300455729164\n",
            "External data sample 15/300\n",
            "Influence for current training sample: -100109.1962890625\n",
            "External data sample 16/300\n",
            "Influence for current training sample: -117476.953125\n",
            "External data sample 17/300\n",
            "Influence for current training sample: -217552.78580729166\n",
            "External data sample 18/300\n",
            "Influence for current training sample: -88120.4677734375\n",
            "External data sample 19/300\n",
            "Influence for current training sample: 65351.55342610677\n",
            "External data sample 20/300\n",
            "Influence for current training sample: -197818.556640625\n",
            "External data sample 21/300\n",
            "Influence for current training sample: -44905.06034342448\n",
            "External data sample 22/300\n",
            "Influence for current training sample: -54656.481770833336\n",
            "External data sample 23/300\n",
            "Influence for current training sample: 89001.27376302083\n",
            "External data sample 24/300\n",
            "Influence for current training sample: -384298.5234375\n",
            "External data sample 25/300\n",
            "Influence for current training sample: 137875.44270833334\n",
            "External data sample 26/300\n",
            "Influence for current training sample: 46094.9618733724\n",
            "External data sample 27/300\n",
            "Influence for current training sample: 91127.6903483073\n",
            "External data sample 28/300\n",
            "Influence for current training sample: 37507.058268229164\n",
            "External data sample 29/300\n",
            "Influence for current training sample: 442317.5755208333\n",
            "External data sample 30/300\n",
            "Influence for current training sample: -268782.8841145833\n",
            "External data sample 31/300\n",
            "Influence for current training sample: 58214.273986816406\n",
            "External data sample 32/300\n",
            "Influence for current training sample: -164622.04947916666\n",
            "External data sample 33/300\n",
            "Influence for current training sample: -112843.009765625\n",
            "External data sample 34/300\n",
            "Influence for current training sample: -96559.25895182292\n",
            "External data sample 35/300\n",
            "Influence for current training sample: -44934.99784342448\n",
            "External data sample 36/300\n",
            "Influence for current training sample: 68561.19856770833\n",
            "External data sample 37/300\n",
            "Influence for current training sample: 200436.42252604166\n",
            "External data sample 38/300\n",
            "Influence for current training sample: -67904.71895345052\n",
            "External data sample 39/300\n",
            "Influence for current training sample: -206174.44010416666\n",
            "External data sample 40/300\n",
            "Influence for current training sample: -317256.7682291667\n",
            "External data sample 41/300\n",
            "Influence for current training sample: 155860.07063802084\n",
            "External data sample 42/300\n",
            "Influence for current training sample: 92993.01236979167\n",
            "External data sample 43/300\n",
            "Influence for current training sample: 193103.54166666666\n",
            "External data sample 44/300\n",
            "Influence for current training sample: -256316.255859375\n",
            "External data sample 45/300\n",
            "Influence for current training sample: -4826.9678955078125\n",
            "External data sample 46/300\n",
            "Influence for current training sample: -43716.7177734375\n",
            "External data sample 47/300\n",
            "Influence for current training sample: 22689.852884928387\n",
            "External data sample 48/300\n",
            "Influence for current training sample: -307969.1276041667\n",
            "External data sample 49/300\n",
            "Influence for current training sample: -52788.03243001302\n",
            "External data sample 50/300\n",
            "Influence for current training sample: -13915.408528645834\n",
            "External data sample 51/300\n",
            "Influence for current training sample: 307305.291015625\n",
            "External data sample 52/300\n",
            "Influence for current training sample: 223732.82747395834\n",
            "External data sample 53/300\n",
            "Influence for current training sample: -306856.6354166667\n",
            "External data sample 54/300\n",
            "Influence for current training sample: 146584.39453125\n",
            "External data sample 55/300\n",
            "Influence for current training sample: 88170.15673828125\n",
            "External data sample 56/300\n",
            "Influence for current training sample: -129399.66243489583\n",
            "External data sample 57/300\n",
            "Influence for current training sample: 242644.10807291666\n",
            "External data sample 58/300\n",
            "Influence for current training sample: 147071.80338541666\n",
            "External data sample 59/300\n",
            "Influence for current training sample: -223656.62760416666\n",
            "External data sample 60/300\n",
            "Influence for current training sample: 283715.7975260417\n",
            "External data sample 61/300\n",
            "Influence for current training sample: 42736.07187906901\n",
            "External data sample 62/300\n",
            "Influence for current training sample: 176473.47916666666\n",
            "External data sample 63/300\n",
            "Influence for current training sample: -40224.673014322914\n",
            "External data sample 64/300\n",
            "Influence for current training sample: -74835.06640625\n",
            "External data sample 65/300\n",
            "Influence for current training sample: 218404.49186197916\n",
            "External data sample 66/300\n",
            "Influence for current training sample: 162675.4392903646\n",
            "External data sample 67/300\n",
            "Influence for current training sample: 244902.6015625\n",
            "External data sample 68/300\n",
            "Influence for current training sample: 256954.130859375\n",
            "External data sample 69/300\n",
            "Influence for current training sample: 6218.291422526042\n",
            "External data sample 70/300\n",
            "Influence for current training sample: 45720.588541666664\n",
            "External data sample 71/300\n",
            "Influence for current training sample: -135156.529296875\n",
            "External data sample 72/300\n",
            "Influence for current training sample: -15194.75390625\n",
            "External data sample 73/300\n",
            "Influence for current training sample: 32319.516682942707\n",
            "External data sample 74/300\n",
            "Influence for current training sample: 128211.251953125\n",
            "External data sample 75/300\n",
            "Influence for current training sample: 354821.1809895833\n",
            "External data sample 76/300\n",
            "Influence for current training sample: 34548.57743326823\n",
            "External data sample 77/300\n",
            "Influence for current training sample: 9073.460978190104\n",
            "External data sample 78/300\n",
            "Influence for current training sample: 105443.62565104167\n",
            "External data sample 79/300\n",
            "Influence for current training sample: -146141.62825520834\n",
            "External data sample 80/300\n",
            "Influence for current training sample: -276363.1315104167\n",
            "External data sample 81/300\n",
            "Influence for current training sample: 84082.1192220052\n",
            "External data sample 82/300\n",
            "Influence for current training sample: -9218.820760091146\n",
            "External data sample 83/300\n",
            "Influence for current training sample: 168681.31770833334\n",
            "External data sample 84/300\n",
            "Influence for current training sample: -83528.751953125\n",
            "External data sample 85/300\n",
            "Influence for current training sample: 194822.333984375\n",
            "External data sample 86/300\n",
            "Influence for current training sample: 162288.19986979166\n",
            "External data sample 87/300\n",
            "Influence for current training sample: 164623.09375\n",
            "External data sample 88/300\n",
            "Influence for current training sample: -214443.23307291666\n",
            "External data sample 89/300\n",
            "Influence for current training sample: 459840.4388020833\n",
            "External data sample 90/300\n",
            "Influence for current training sample: 355863.6809895833\n",
            "External data sample 91/300\n",
            "Influence for current training sample: 421562.9622395833\n",
            "External data sample 92/300\n",
            "Influence for current training sample: -241134.57942708334\n",
            "External data sample 93/300\n",
            "Influence for current training sample: 55297.330729166664\n",
            "External data sample 94/300\n",
            "Influence for current training sample: -24031.220292727154\n",
            "External data sample 95/300\n",
            "Influence for current training sample: -87541.27213541667\n",
            "External data sample 96/300\n",
            "Influence for current training sample: -147081.76204427084\n",
            "External data sample 97/300\n",
            "Influence for current training sample: 136336.322265625\n",
            "External data sample 98/300\n",
            "Influence for current training sample: 305219.3860677083\n",
            "External data sample 99/300\n",
            "Influence for current training sample: -225102.21354166666\n",
            "External data sample 100/300\n",
            "Influence for current training sample: -242512.35286458334\n",
            "External data sample 101/300\n",
            "Influence for current training sample: 32810.02345275879\n",
            "External data sample 102/300\n",
            "Influence for current training sample: -1456.395751953125\n",
            "External data sample 103/300\n",
            "Influence for current training sample: 229244.630859375\n",
            "External data sample 104/300\n",
            "Influence for current training sample: -9881.862101236979\n",
            "External data sample 105/300\n",
            "Influence for current training sample: 535172.2630208334\n",
            "External data sample 106/300\n",
            "Influence for current training sample: -119901.24576822917\n",
            "External data sample 107/300\n",
            "Influence for current training sample: 13374.559641520182\n",
            "External data sample 108/300\n",
            "Influence for current training sample: 79575.486328125\n",
            "External data sample 109/300\n",
            "Influence for current training sample: 250599.96744791666\n",
            "External data sample 110/300\n",
            "Influence for current training sample: 27217.670857747395\n",
            "External data sample 111/300\n",
            "Influence for current training sample: 150956.33642578125\n",
            "External data sample 112/300\n",
            "Influence for current training sample: 169070.8515625\n",
            "External data sample 113/300\n",
            "Influence for current training sample: 38132.48828125\n",
            "External data sample 114/300\n",
            "Influence for current training sample: -7307.045491536458\n",
            "External data sample 115/300\n",
            "Influence for current training sample: 114995.92936197917\n",
            "External data sample 116/300\n",
            "Influence for current training sample: 217682.35416666666\n",
            "External data sample 117/300\n",
            "Influence for current training sample: 120000.2421875\n",
            "External data sample 118/300\n",
            "Influence for current training sample: -261716.81640625\n",
            "External data sample 119/300\n",
            "Influence for current training sample: 96762.62662760417\n",
            "External data sample 120/300\n",
            "Influence for current training sample: 237144.60546875\n",
            "External data sample 121/300\n",
            "Influence for current training sample: 190666.712890625\n",
            "External data sample 122/300\n",
            "Influence for current training sample: -87285.05192057292\n",
            "External data sample 123/300\n",
            "Influence for current training sample: -227908.72135416666\n",
            "External data sample 124/300\n",
            "Influence for current training sample: 38734.259928385414\n",
            "External data sample 125/300\n",
            "Influence for current training sample: 45846.070149739586\n",
            "External data sample 126/300\n",
            "Influence for current training sample: -141509.23470052084\n",
            "External data sample 127/300\n",
            "Influence for current training sample: 100611.81705729167\n",
            "External data sample 128/300\n",
            "Influence for current training sample: -16064.637166341146\n",
            "External data sample 129/300\n",
            "Influence for current training sample: 122442.70084635417\n",
            "External data sample 130/300\n",
            "Influence for current training sample: 64160.59020996094\n",
            "External data sample 131/300\n",
            "Influence for current training sample: 124365.75520833333\n",
            "External data sample 132/300\n",
            "Influence for current training sample: -54729.48563639323\n",
            "External data sample 133/300\n",
            "Influence for current training sample: 177017.14615885416\n",
            "External data sample 134/300\n",
            "Influence for current training sample: 199914.78450520834\n",
            "External data sample 135/300\n",
            "Influence for current training sample: 416735.2552083333\n",
            "External data sample 136/300\n",
            "Influence for current training sample: -29254.601420084637\n",
            "External data sample 137/300\n",
            "Influence for current training sample: -87453.6015625\n",
            "External data sample 138/300\n",
            "Influence for current training sample: -178513.29296875\n",
            "External data sample 139/300\n",
            "Influence for current training sample: 5768.5213623046875\n",
            "External data sample 140/300\n",
            "Influence for current training sample: -135401.619140625\n",
            "External data sample 141/300\n",
            "Influence for current training sample: 135378.67919921875\n",
            "External data sample 142/300\n",
            "Influence for current training sample: -116497.41373697917\n",
            "External data sample 143/300\n",
            "Influence for current training sample: 95498.26708984375\n",
            "External data sample 144/300\n",
            "Influence for current training sample: -3163.4124348958335\n",
            "External data sample 145/300\n",
            "Influence for current training sample: 50788.055338541664\n",
            "External data sample 146/300\n",
            "Influence for current training sample: 174592.18424479166\n",
            "External data sample 147/300\n",
            "Influence for current training sample: 298097.4029947917\n",
            "External data sample 148/300\n",
            "Influence for current training sample: -48838.80448404948\n",
            "External data sample 149/300\n",
            "Influence for current training sample: -98998.88541666667\n",
            "External data sample 150/300\n",
            "Influence for current training sample: 145105.72819010416\n",
            "External data sample 151/300\n",
            "Influence for current training sample: 4792.2871170043945\n",
            "External data sample 152/300\n",
            "Influence for current training sample: 48384.384602864586\n",
            "External data sample 153/300\n",
            "Influence for current training sample: -293827.9348958333\n",
            "External data sample 154/300\n",
            "Influence for current training sample: 208142.57552083334\n",
            "External data sample 155/300\n",
            "Influence for current training sample: 150132.18619791666\n",
            "External data sample 156/300\n",
            "Influence for current training sample: -200129.2099609375\n",
            "External data sample 157/300\n",
            "Influence for current training sample: 81422.56998697917\n",
            "External data sample 158/300\n",
            "Influence for current training sample: 288261.0494791667\n",
            "External data sample 159/300\n",
            "Influence for current training sample: -153348.408203125\n",
            "External data sample 160/300\n",
            "Influence for current training sample: -407589.6627604167\n",
            "External data sample 161/300\n",
            "Influence for current training sample: 7048.848937988281\n",
            "External data sample 162/300\n",
            "Influence for current training sample: 122077.49088541667\n",
            "External data sample 163/300\n",
            "Influence for current training sample: 77106.48111979167\n",
            "External data sample 164/300\n",
            "Influence for current training sample: 253761.78450520834\n",
            "External data sample 165/300\n",
            "Influence for current training sample: 79249.1348470052\n",
            "External data sample 166/300\n",
            "Influence for current training sample: -46465.0380859375\n",
            "External data sample 167/300\n",
            "Influence for current training sample: -65994.66569010417\n",
            "External data sample 168/300\n",
            "Influence for current training sample: -35908.055338541664\n",
            "External data sample 169/300\n",
            "Influence for current training sample: -182239.36555989584\n",
            "External data sample 170/300\n",
            "Influence for current training sample: 237029.84830729166\n",
            "External data sample 171/300\n",
            "Influence for current training sample: -52921.582682291664\n",
            "External data sample 172/300\n",
            "Influence for current training sample: -92243.88639322917\n",
            "External data sample 173/300\n",
            "Influence for current training sample: 208668.94401041666\n",
            "External data sample 174/300\n",
            "Influence for current training sample: 105070.30745442708\n",
            "External data sample 175/300\n",
            "Influence for current training sample: 60206.42578125\n",
            "External data sample 176/300\n",
            "Influence for current training sample: -121735.2744140625\n",
            "External data sample 177/300\n",
            "Influence for current training sample: -162132.89453125\n",
            "External data sample 178/300\n",
            "Influence for current training sample: 10439.211710611979\n",
            "External data sample 179/300\n",
            "Influence for current training sample: 227177.251953125\n",
            "External data sample 180/300\n",
            "Influence for current training sample: 98337.505859375\n",
            "External data sample 181/300\n",
            "Influence for current training sample: -419794.3020833333\n",
            "External data sample 182/300\n",
            "Influence for current training sample: 91051.9267578125\n",
            "External data sample 183/300\n",
            "Influence for current training sample: 207749.837890625\n",
            "External data sample 184/300\n",
            "Influence for current training sample: -214061.57421875\n",
            "External data sample 185/300\n",
            "Influence for current training sample: 153485.30598958334\n",
            "External data sample 186/300\n",
            "Influence for current training sample: 67915.68180338542\n",
            "External data sample 187/300\n",
            "Influence for current training sample: 131299.072265625\n",
            "External data sample 188/300\n",
            "Influence for current training sample: 68726.36100260417\n",
            "External data sample 189/300\n",
            "Influence for current training sample: 36553.39005533854\n",
            "External data sample 190/300\n",
            "Influence for current training sample: 244963.642578125\n",
            "External data sample 191/300\n",
            "Influence for current training sample: 223949.47395833334\n",
            "External data sample 192/300\n",
            "Influence for current training sample: 203904.3984375\n",
            "External data sample 193/300\n",
            "Influence for current training sample: 154457.76302083334\n",
            "External data sample 194/300\n",
            "Influence for current training sample: 64489.840169270836\n",
            "External data sample 195/300\n",
            "Influence for current training sample: -221731.861328125\n",
            "External data sample 196/300\n",
            "Influence for current training sample: 121508.6611328125\n",
            "External data sample 197/300\n",
            "Influence for current training sample: 31205.384440104168\n",
            "External data sample 198/300\n",
            "Influence for current training sample: -252269.19075520834\n",
            "External data sample 199/300\n",
            "Influence for current training sample: 135187.79036458334\n",
            "External data sample 200/300\n",
            "Influence for current training sample: 38209.050944010414\n",
            "External data sample 201/300\n",
            "Influence for current training sample: 74235.07088216145\n",
            "External data sample 202/300\n",
            "Influence for current training sample: 128181.86328125\n",
            "External data sample 203/300\n",
            "Influence for current training sample: 76524.12174479167\n",
            "External data sample 204/300\n",
            "Influence for current training sample: -434784.5924479167\n",
            "External data sample 205/300\n",
            "Influence for current training sample: -69381.71809895833\n",
            "External data sample 206/300\n",
            "Influence for current training sample: -145130.140625\n",
            "External data sample 207/300\n",
            "Influence for current training sample: 149040.1171875\n",
            "External data sample 208/300\n",
            "Influence for current training sample: -292247.2864583333\n",
            "External data sample 209/300\n",
            "Influence for current training sample: -165123.84147135416\n",
            "External data sample 210/300\n",
            "Influence for current training sample: -478639.4739583333\n",
            "External data sample 211/300\n",
            "Influence for current training sample: -650273.7083333334\n",
            "External data sample 212/300\n",
            "Influence for current training sample: -252238.87174479166\n",
            "External data sample 213/300\n",
            "Influence for current training sample: -153188.64713541666\n",
            "External data sample 214/300\n",
            "Influence for current training sample: 42617.08056640625\n",
            "External data sample 215/300\n",
            "Influence for current training sample: -269854.8893229167\n",
            "External data sample 216/300\n",
            "Influence for current training sample: -69158.4716796875\n",
            "External data sample 217/300\n",
            "Influence for current training sample: -262308.55859375\n",
            "External data sample 218/300\n",
            "Influence for current training sample: -171345.24153645834\n",
            "External data sample 219/300\n",
            "Influence for current training sample: -92559.6727701823\n",
            "External data sample 220/300\n",
            "Influence for current training sample: -207042.93815104166\n",
            "External data sample 221/300\n",
            "Influence for current training sample: -170809.39192708334\n",
            "External data sample 222/300\n",
            "Influence for current training sample: 68518.01936848958\n",
            "External data sample 223/300\n",
            "Influence for current training sample: -291650.3658854167\n",
            "External data sample 224/300\n",
            "Influence for current training sample: 147893.43717447916\n",
            "External data sample 225/300\n",
            "Influence for current training sample: -39451.652018229164\n",
            "External data sample 226/300\n",
            "Influence for current training sample: 32110.086181640625\n",
            "External data sample 227/300\n",
            "Influence for current training sample: 262853.6647135417\n",
            "External data sample 228/300\n",
            "Influence for current training sample: 82722.33268229167\n",
            "External data sample 229/300\n",
            "Influence for current training sample: -243020.27799479166\n",
            "External data sample 230/300\n",
            "Influence for current training sample: 417597.0755208333\n",
            "External data sample 231/300\n",
            "Influence for current training sample: -293996.5572916667\n",
            "External data sample 232/300\n",
            "Influence for current training sample: -35448.86436971029\n",
            "External data sample 233/300\n",
            "Influence for current training sample: -86952.0302734375\n",
            "External data sample 234/300\n",
            "Influence for current training sample: -5070.782165527344\n",
            "External data sample 235/300\n",
            "Influence for current training sample: 21786.974772135418\n",
            "External data sample 236/300\n",
            "Influence for current training sample: 171974.54036458334\n",
            "External data sample 237/300\n",
            "Influence for current training sample: 2391.1077677408853\n",
            "External data sample 238/300\n",
            "Influence for current training sample: 160184.1619466146\n",
            "External data sample 239/300\n",
            "Influence for current training sample: -221510.92708333334\n",
            "External data sample 240/300\n",
            "Influence for current training sample: 126455.4267578125\n",
            "External data sample 241/300\n",
            "Influence for current training sample: 241335.38151041666\n",
            "External data sample 242/300\n",
            "Influence for current training sample: 218403.6796875\n",
            "External data sample 243/300\n",
            "Influence for current training sample: 39305.40193684896\n",
            "External data sample 244/300\n",
            "Influence for current training sample: 111778.29427083333\n",
            "External data sample 245/300\n",
            "Influence for current training sample: -139042.1220703125\n",
            "External data sample 246/300\n",
            "Influence for current training sample: -26952.75117746989\n",
            "External data sample 247/300\n",
            "Influence for current training sample: -197691.478515625\n",
            "External data sample 248/300\n",
            "Influence for current training sample: 223049.8525390625\n",
            "External data sample 249/300\n",
            "Influence for current training sample: -94283.0284016927\n",
            "External data sample 250/300\n",
            "Influence for current training sample: 120867.4208984375\n",
            "External data sample 251/300\n",
            "Influence for current training sample: 253382.595703125\n",
            "External data sample 252/300\n",
            "Influence for current training sample: -159190.08919270834\n",
            "External data sample 253/300\n",
            "Influence for current training sample: -77924.46451822917\n",
            "External data sample 254/300\n",
            "Influence for current training sample: 201871.41731770834\n",
            "External data sample 255/300\n",
            "Influence for current training sample: -270361.3177083333\n",
            "External data sample 256/300\n",
            "Influence for current training sample: -165972.86393229166\n",
            "External data sample 257/300\n",
            "Influence for current training sample: 284006.1647135417\n",
            "External data sample 258/300\n",
            "Influence for current training sample: 58714.448893229164\n",
            "External data sample 259/300\n",
            "Influence for current training sample: 139900.84244791666\n",
            "External data sample 260/300\n",
            "Influence for current training sample: -41941.77392578125\n",
            "External data sample 261/300\n",
            "Influence for current training sample: 183129.04654947916\n",
            "External data sample 262/300\n",
            "Influence for current training sample: 136583.74609375\n",
            "External data sample 263/300\n",
            "Influence for current training sample: 136850.97493489584\n",
            "External data sample 264/300\n",
            "Influence for current training sample: 146139.23111979166\n",
            "External data sample 265/300\n",
            "Influence for current training sample: -38983.424153645836\n",
            "External data sample 266/300\n",
            "Influence for current training sample: 31812.020182291668\n",
            "External data sample 267/300\n",
            "Influence for current training sample: 23690.39892578125\n",
            "External data sample 268/300\n",
            "Influence for current training sample: -205795.49739583334\n",
            "External data sample 269/300\n",
            "Influence for current training sample: 305405.37109375\n",
            "External data sample 270/300\n",
            "Influence for current training sample: 134267.6416015625\n",
            "External data sample 271/300\n",
            "Influence for current training sample: 172307.61328125\n",
            "External data sample 272/300\n",
            "Influence for current training sample: 343050.5703125\n",
            "External data sample 273/300\n",
            "Influence for current training sample: 7872.295796712239\n",
            "External data sample 274/300\n",
            "Influence for current training sample: 150251.1474609375\n",
            "External data sample 275/300\n",
            "Influence for current training sample: -98252.84586588542\n",
            "External data sample 276/300\n",
            "Influence for current training sample: 171077.828125\n",
            "External data sample 277/300\n",
            "Influence for current training sample: -23626.077311197918\n",
            "External data sample 278/300\n",
            "Influence for current training sample: 72529.533203125\n",
            "External data sample 279/300\n",
            "Influence for current training sample: 202349.72916666666\n",
            "External data sample 280/300\n",
            "Influence for current training sample: 49670.03918457031\n",
            "External data sample 281/300\n",
            "Influence for current training sample: 70005.08756510417\n",
            "External data sample 282/300\n",
            "Influence for current training sample: 142247.5068359375\n",
            "External data sample 283/300\n",
            "Influence for current training sample: 230610.49283854166\n",
            "External data sample 284/300\n",
            "Influence for current training sample: 14066.368347167969\n",
            "External data sample 285/300\n",
            "Influence for current training sample: 81992.1534016927\n",
            "External data sample 286/300\n",
            "Influence for current training sample: 102056.30582682292\n",
            "External data sample 287/300\n",
            "Influence for current training sample: 59568.02197265625\n",
            "External data sample 288/300\n",
            "Influence for current training sample: 156640.07682291666\n",
            "External data sample 289/300\n",
            "Influence for current training sample: -287303.232421875\n",
            "External data sample 290/300\n",
            "Influence for current training sample: 71514.32747395833\n",
            "External data sample 291/300\n",
            "Influence for current training sample: 220795.05729166666\n",
            "External data sample 292/300\n",
            "Influence for current training sample: -49725.93896484375\n",
            "External data sample 293/300\n",
            "Influence for current training sample: -27797.656127929688\n",
            "External data sample 294/300\n",
            "Influence for current training sample: -124209.02864583333\n",
            "External data sample 295/300\n",
            "Influence for current training sample: 61493.60298665365\n",
            "External data sample 296/300\n",
            "Influence for current training sample: -43594.919759114586\n",
            "External data sample 297/300\n",
            "Influence for current training sample: 180877.23893229166\n",
            "External data sample 298/300\n",
            "Influence for current training sample: -164329.21940104166\n",
            "External data sample 299/300\n",
            "Influence for current training sample: 255874.00065104166\n",
            "External data sample 300/300\n",
            "Influence for current training sample: 22266.342864990234\n",
            "Most influential training points: [(104, 535172.2630208334), (88, 459840.4388020833), (28, 442317.5755208333), (90, 421562.9622395833), (229, 417597.0755208333), (134, 416735.2552083333), (89, 355863.6809895833), (74, 354821.1809895833), (271, 343050.5703125), (50, 307305.291015625), (268, 305405.37109375), (97, 305219.3860677083), (146, 298097.4029947917), (3, 289419.7955729167), (157, 288261.0494791667), (256, 284006.1647135417), (59, 283715.7975260417), (226, 262853.6647135417), (67, 256954.130859375), (298, 255874.00065104166), (163, 253761.78450520834), (250, 253382.595703125), (108, 250599.96744791666), (189, 244963.642578125), (66, 244902.6015625), (56, 242644.10807291666), (240, 241335.38151041666), (119, 237144.60546875), (169, 237029.84830729166), (282, 230610.49283854166), (102, 229244.630859375), (178, 227177.251953125), (190, 223949.47395833334), (51, 223732.82747395834), (247, 223049.8525390625), (290, 220795.05729166666), (64, 218404.49186197916), (241, 218403.6796875), (115, 217682.35416666666), (172, 208668.94401041666), (153, 208142.57552083334), (182, 207749.837890625), (191, 203904.3984375), (278, 202349.72916666666), (253, 201871.41731770834), (36, 200436.42252604166), (133, 199914.78450520834), (84, 194822.333984375), (42, 193103.54166666666), (120, 190666.712890625), (260, 183129.04654947916), (296, 180877.23893229166), (132, 177017.14615885416), (61, 176473.47916666666), (145, 174592.18424479166), (270, 172307.61328125), (235, 171974.54036458334), (275, 171077.828125), (111, 169070.8515625), (82, 168681.31770833334), (11, 164799.91080729166), (86, 164623.09375), (65, 162675.4392903646), (85, 162288.19986979166), (237, 160184.1619466146), (287, 156640.07682291666), (40, 155860.07063802084), (192, 154457.76302083334), (184, 153485.30598958334), (110, 150956.33642578125), (273, 150251.1474609375), (154, 150132.18619791666), (206, 149040.1171875), (223, 147893.43717447916), (57, 147071.80338541666), (53, 146584.39453125), (263, 146139.23111979166), (149, 145105.72819010416), (281, 142247.5068359375), (258, 139900.84244791666), (24, 137875.44270833334), (262, 136850.97493489584), (261, 136583.74609375), (96, 136336.322265625), (140, 135378.67919921875), (198, 135187.79036458334), (269, 134267.6416015625), (186, 131299.072265625), (73, 128211.251953125), (201, 128181.86328125), (239, 126455.4267578125), (130, 124365.75520833333), (128, 122442.70084635417), (161, 122077.49088541667), (195, 121508.6611328125), (249, 120867.4208984375), (116, 120000.2421875), (114, 114995.92936197917), (243, 111778.29427083333), (77, 105443.62565104167), (173, 105070.30745442708), (1, 103597.876953125), (285, 102056.30582682292), (126, 100611.81705729167), (179, 98337.505859375), (118, 96762.62662760417), (142, 95498.26708984375), (41, 92993.01236979167), (26, 91127.6903483073), (181, 91051.9267578125), (22, 89001.27376302083), (54, 88170.15673828125), (80, 84082.1192220052), (227, 82722.33268229167), (284, 81992.1534016927), (156, 81422.56998697917), (107, 79575.486328125), (164, 79249.1348470052), (162, 77106.48111979167), (202, 76524.12174479167), (200, 74235.07088216145), (277, 72529.533203125), (289, 71514.32747395833), (280, 70005.08756510417), (187, 68726.36100260417), (35, 68561.19856770833), (221, 68518.01936848958), (185, 67915.68180338542), (18, 65351.55342610677), (193, 64489.840169270836), (129, 64160.59020996094), (294, 61493.60298665365), (174, 60206.42578125), (286, 59568.02197265625), (257, 58714.448893229164), (30, 58214.273986816406), (92, 55297.330729166664), (144, 50788.055338541664), (279, 49670.03918457031), (151, 48384.384602864586), (25, 46094.9618733724), (124, 45846.070149739586), (69, 45720.588541666664), (60, 42736.07187906901), (213, 42617.08056640625), (242, 39305.40193684896), (123, 38734.259928385414), (199, 38209.050944010414), (112, 38132.48828125), (27, 37507.058268229164), (188, 36553.39005533854), (75, 34548.57743326823), (100, 32810.02345275879), (72, 32319.516682942707), (225, 32110.086181640625), (265, 31812.020182291668), (196, 31205.384440104168), (109, 27217.670857747395), (266, 23690.39892578125), (46, 22689.852884928387), (299, 22266.342864990234), (234, 21786.974772135418), (283, 14066.368347167969), (106, 13374.559641520182), (177, 10439.211710611979), (76, 9073.460978190104), (272, 7872.295796712239), (160, 7048.848937988281), (68, 6218.291422526042), (8, 6098.886393229167), (138, 5768.5213623046875), (150, 4792.2871170043945), (236, 2391.1077677408853), (101, -1456.395751953125), (143, -3163.4124348958335), (44, -4826.9678955078125), (233, -5070.782165527344), (113, -7307.045491536458), (81, -9218.820760091146), (103, -9881.862101236979), (49, -13915.408528645834), (71, -15194.75390625), (127, -16064.637166341146), (276, -23626.077311197918), (93, -24031.220292727154), (245, -26952.75117746989), (292, -27797.656127929688), (135, -29254.601420084637), (231, -35448.86436971029), (167, -35908.055338541664), (264, -38983.424153645836), (224, -39451.652018229164), (62, -40224.673014322914), (259, -41941.77392578125), (295, -43594.919759114586), (45, -43716.7177734375), (20, -44905.06034342448), (34, -44934.99784342448), (165, -46465.0380859375), (147, -48838.80448404948), (291, -49725.93896484375), (48, -52788.03243001302), (170, -52921.582682291664), (21, -54656.481770833336), (131, -54729.48563639323), (13, -63341.300455729164), (10, -65699.0517578125), (166, -65994.66569010417), (37, -67904.71895345052), (215, -69158.4716796875), (204, -69381.71809895833), (63, -74835.06640625), (252, -77924.46451822917), (83, -83528.751953125), (232, -86952.0302734375), (121, -87285.05192057292), (136, -87453.6015625), (94, -87541.27213541667), (17, -88120.4677734375), (171, -92243.88639322917), (218, -92559.6727701823), (248, -94283.0284016927), (33, -96559.25895182292), (6, -96637.15494791667), (274, -98252.84586588542), (148, -98998.88541666667), (14, -100109.1962890625), (32, -112843.009765625), (141, -116497.41373697917), (15, -117476.953125), (105, -119901.24576822917), (175, -121735.2744140625), (293, -124209.02864583333), (55, -129399.66243489583), (70, -135156.529296875), (139, -135401.619140625), (244, -139042.1220703125), (125, -141509.23470052084), (205, -145130.140625), (78, -146141.62825520834), (95, -147081.76204427084), (212, -153188.64713541666), (158, -153348.408203125), (251, -159190.08919270834), (176, -162132.89453125), (297, -164329.21940104166), (4, -164343.64518229166), (31, -164622.04947916666), (208, -165123.84147135416), (255, -165972.86393229166), (7, -166085.224609375), (220, -170809.39192708334), (217, -171345.24153645834), (137, -178513.29296875), (9, -179477.61783854166), (168, -182239.36555989584), (0, -184609.02180989584), (5, -185660.736328125), (246, -197691.478515625), (19, -197818.556640625), (155, -200129.2099609375), (267, -205795.49739583334), (38, -206174.44010416666), (219, -207042.93815104166), (183, -214061.57421875), (87, -214443.23307291666), (16, -217552.78580729166), (238, -221510.92708333334), (194, -221731.861328125), (58, -223656.62760416666), (98, -225102.21354166666), (122, -227908.72135416666), (91, -241134.57942708334), (99, -242512.35286458334), (12, -242736.26171875), (228, -243020.27799479166), (211, -252238.87174479166), (197, -252269.19075520834), (43, -256316.255859375), (117, -261716.81640625), (216, -262308.55859375), (29, -268782.8841145833), (214, -269854.8893229167), (254, -270361.3177083333), (79, -276363.1315104167), (288, -287303.232421875), (222, -291650.3658854167), (207, -292247.2864583333), (152, -293827.9348958333), (230, -293996.5572916667), (52, -306856.6354166667), (47, -307969.1276041667), (2, -316927.1953125), (39, -317256.7682291667), (23, -384298.5234375), (159, -407589.6627604167), (180, -419794.3020833333), (203, -434784.5924479167), (209, -478639.4739583333), (210, -650273.7083333334)]\n",
            "/content/nnti-project-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# computing influence of each external data point on test set\n",
        "# load pre-computed iHVP\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "test_ihvps.extend(torch.load(f\"test_ihvps_full_set.pt\"))\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())\n",
        "\n",
        "# Computing influence for each sample in external dataset\n",
        "influences = []\n",
        "for train_batch in ext_influence_dataloader:\n",
        "    print(f\"External data sample {len(influences) + 1}/{len(ext_influence_dataloader)}\")\n",
        "    train_input_ids = train_batch['input_ids'].to(device)\n",
        "    train_attention_mask = train_batch['attention_mask'].to(device)\n",
        "    train_label = train_batch['target'].to(device)\n",
        "\n",
        "    train_point = {'input_ids': train_input_ids, 'attention_mask': train_attention_mask}\n",
        "\n",
        "    ihvp = test_ihvps[0] # pre-computed iHVP over full test set\n",
        "    influence_scores = influence_by_train_point(train_point, train_label, ihvp, regression_model, criterion)\n",
        "\n",
        "    influences.append(influence_scores.item())\n",
        "    print(f\"Influence for current training sample: {influence_scores}\")\n",
        "\n",
        "# Rank external data points by influence\n",
        "ranked_indices = sorted(enumerate(influences), key=lambda x: x[1], reverse=True)  # sorted by influence score\n",
        "print(\"Most influential training points:\", ranked_indices)\n",
        "\n",
        "# Save the influence score\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "influence_scores = pd.DataFrame(ranked_indices, columns=[\"Index\", \"Influence Score\"])\n",
        "influence_scores.to_csv(\"ranked_indices_full_set.csv\", index=False)\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "D3ICRiINoNS2",
        "outputId": "a5fef759-9fa3-4fed-99c9-e062b96102af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-eb399fcdef76>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  test_ihvps.extend(torch.load(f\"test_ihvps_full_set.pt\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nnti-project-25\n",
            "External data sample 1/300\n",
            "Influence for current training sample: -180.46450805664062\n",
            "External data sample 2/300\n",
            "Influence for current training sample: 95.83807373046875\n",
            "External data sample 3/300\n",
            "Influence for current training sample: -339.0596618652344\n",
            "External data sample 4/300\n",
            "Influence for current training sample: 648.889892578125\n",
            "External data sample 5/300\n",
            "Influence for current training sample: -157.52743530273438\n",
            "External data sample 6/300\n",
            "Influence for current training sample: -267.3226623535156\n",
            "External data sample 7/300\n",
            "Influence for current training sample: -128.4178009033203\n",
            "External data sample 8/300\n",
            "Influence for current training sample: -132.17430114746094\n",
            "External data sample 9/300\n",
            "Influence for current training sample: 37.25246047973633\n",
            "External data sample 10/300\n",
            "Influence for current training sample: -290.90106201171875\n",
            "External data sample 11/300\n",
            "Influence for current training sample: -105.2376708984375\n",
            "External data sample 12/300\n",
            "Influence for current training sample: 520.5252075195312\n",
            "External data sample 13/300\n",
            "Influence for current training sample: -193.526611328125\n",
            "External data sample 14/300\n",
            "Influence for current training sample: -410.25860595703125\n",
            "External data sample 15/300\n",
            "Influence for current training sample: -141.1981964111328\n",
            "External data sample 16/300\n",
            "Influence for current training sample: -39.91143798828125\n",
            "External data sample 17/300\n",
            "Influence for current training sample: -266.0405578613281\n",
            "External data sample 18/300\n",
            "Influence for current training sample: -110.88407135009766\n",
            "External data sample 19/300\n",
            "Influence for current training sample: 27.691017150878906\n",
            "External data sample 20/300\n",
            "Influence for current training sample: -168.62701416015625\n",
            "External data sample 21/300\n",
            "Influence for current training sample: -84.03826141357422\n",
            "External data sample 22/300\n",
            "Influence for current training sample: 36.78423309326172\n",
            "External data sample 23/300\n",
            "Influence for current training sample: 200.32980346679688\n",
            "External data sample 24/300\n",
            "Influence for current training sample: -256.1189270019531\n",
            "External data sample 25/300\n",
            "Influence for current training sample: 182.62985229492188\n",
            "External data sample 26/300\n",
            "Influence for current training sample: 50.669151306152344\n",
            "External data sample 27/300\n",
            "Influence for current training sample: 129.8501739501953\n",
            "External data sample 28/300\n",
            "Influence for current training sample: 25.833568572998047\n",
            "External data sample 29/300\n",
            "Influence for current training sample: 472.4814453125\n",
            "External data sample 30/300\n",
            "Influence for current training sample: -376.5777282714844\n",
            "External data sample 31/300\n",
            "Influence for current training sample: 162.97471618652344\n",
            "External data sample 32/300\n",
            "Influence for current training sample: 73.64009094238281\n",
            "External data sample 33/300\n",
            "Influence for current training sample: 11.155182838439941\n",
            "External data sample 34/300\n",
            "Influence for current training sample: -8.961633682250977\n",
            "External data sample 35/300\n",
            "Influence for current training sample: -63.38135528564453\n",
            "External data sample 36/300\n",
            "Influence for current training sample: -3.7520856857299805\n",
            "External data sample 37/300\n",
            "Influence for current training sample: 279.8090515136719\n",
            "External data sample 38/300\n",
            "Influence for current training sample: -9.50151252746582\n",
            "External data sample 39/300\n",
            "Influence for current training sample: -9.450958251953125\n",
            "External data sample 40/300\n",
            "Influence for current training sample: 8.626972198486328\n",
            "External data sample 41/300\n",
            "Influence for current training sample: 54.12518310546875\n",
            "External data sample 42/300\n",
            "Influence for current training sample: -89.04771423339844\n",
            "External data sample 43/300\n",
            "Influence for current training sample: 87.13249206542969\n",
            "External data sample 44/300\n",
            "Influence for current training sample: -204.76998901367188\n",
            "External data sample 45/300\n",
            "Influence for current training sample: 67.35066223144531\n",
            "External data sample 46/300\n",
            "Influence for current training sample: -17.297489166259766\n",
            "External data sample 47/300\n",
            "Influence for current training sample: 46.275760650634766\n",
            "External data sample 48/300\n",
            "Influence for current training sample: -224.31912231445312\n",
            "External data sample 49/300\n",
            "Influence for current training sample: -76.98944091796875\n",
            "External data sample 50/300\n",
            "Influence for current training sample: -0.4061005711555481\n",
            "External data sample 51/300\n",
            "Influence for current training sample: 399.8251647949219\n",
            "External data sample 52/300\n",
            "Influence for current training sample: 46.18017578125\n",
            "External data sample 53/300\n",
            "Influence for current training sample: -359.9624328613281\n",
            "External data sample 54/300\n",
            "Influence for current training sample: -78.65729522705078\n",
            "External data sample 55/300\n",
            "Influence for current training sample: 22.37122917175293\n",
            "External data sample 56/300\n",
            "Influence for current training sample: -238.28030395507812\n",
            "External data sample 57/300\n",
            "Influence for current training sample: 254.85226440429688\n",
            "External data sample 58/300\n",
            "Influence for current training sample: 205.56210327148438\n",
            "External data sample 59/300\n",
            "Influence for current training sample: -144.33920288085938\n",
            "External data sample 60/300\n",
            "Influence for current training sample: 133.91714477539062\n",
            "External data sample 61/300\n",
            "Influence for current training sample: -1.4095838069915771\n",
            "External data sample 62/300\n",
            "Influence for current training sample: 57.54473876953125\n",
            "External data sample 63/300\n",
            "Influence for current training sample: -2.739863395690918\n",
            "External data sample 64/300\n",
            "Influence for current training sample: 1.4420409202575684\n",
            "External data sample 65/300\n",
            "Influence for current training sample: 68.6878662109375\n",
            "External data sample 66/300\n",
            "Influence for current training sample: 56.169429779052734\n",
            "External data sample 67/300\n",
            "Influence for current training sample: 243.5226593017578\n",
            "External data sample 68/300\n",
            "Influence for current training sample: 189.01763916015625\n",
            "External data sample 69/300\n",
            "Influence for current training sample: 0.381960928440094\n",
            "External data sample 70/300\n",
            "Influence for current training sample: 135.01455688476562\n",
            "External data sample 71/300\n",
            "Influence for current training sample: -136.05300903320312\n",
            "External data sample 72/300\n",
            "Influence for current training sample: 27.089763641357422\n",
            "External data sample 73/300\n",
            "Influence for current training sample: 32.907997131347656\n",
            "External data sample 74/300\n",
            "Influence for current training sample: 50.15657043457031\n",
            "External data sample 75/300\n",
            "Influence for current training sample: 216.46368408203125\n",
            "External data sample 76/300\n",
            "Influence for current training sample: 17.7576847076416\n",
            "External data sample 77/300\n",
            "Influence for current training sample: 23.1452579498291\n",
            "External data sample 78/300\n",
            "Influence for current training sample: 58.73402404785156\n",
            "External data sample 79/300\n",
            "Influence for current training sample: -138.7368621826172\n",
            "External data sample 80/300\n",
            "Influence for current training sample: -258.67822265625\n",
            "External data sample 81/300\n",
            "Influence for current training sample: 18.385623931884766\n",
            "External data sample 82/300\n",
            "Influence for current training sample: 56.94601821899414\n",
            "External data sample 83/300\n",
            "Influence for current training sample: 101.21566772460938\n",
            "External data sample 84/300\n",
            "Influence for current training sample: -116.97663879394531\n",
            "External data sample 85/300\n",
            "Influence for current training sample: 137.22132873535156\n",
            "External data sample 86/300\n",
            "Influence for current training sample: 47.45850372314453\n",
            "External data sample 87/300\n",
            "Influence for current training sample: 34.70182418823242\n",
            "External data sample 88/300\n",
            "Influence for current training sample: -296.3984069824219\n",
            "External data sample 89/300\n",
            "Influence for current training sample: 556.17626953125\n",
            "External data sample 90/300\n",
            "Influence for current training sample: 367.0245361328125\n",
            "External data sample 91/300\n",
            "Influence for current training sample: 628.1036376953125\n",
            "External data sample 92/300\n",
            "Influence for current training sample: 93.54623413085938\n",
            "External data sample 93/300\n",
            "Influence for current training sample: 18.616741180419922\n",
            "External data sample 94/300\n",
            "Influence for current training sample: -22.37355613708496\n",
            "External data sample 95/300\n",
            "Influence for current training sample: -116.48665618896484\n",
            "External data sample 96/300\n",
            "Influence for current training sample: -146.1603240966797\n",
            "External data sample 97/300\n",
            "Influence for current training sample: 96.65048217773438\n",
            "External data sample 98/300\n",
            "Influence for current training sample: 322.9530029296875\n",
            "External data sample 99/300\n",
            "Influence for current training sample: 24.859149932861328\n",
            "External data sample 100/300\n",
            "Influence for current training sample: -235.45877075195312\n",
            "External data sample 101/300\n",
            "Influence for current training sample: -8.365758895874023\n",
            "External data sample 102/300\n",
            "Influence for current training sample: 21.688064575195312\n",
            "External data sample 103/300\n",
            "Influence for current training sample: 124.80982971191406\n",
            "External data sample 104/300\n",
            "Influence for current training sample: 63.63408660888672\n",
            "External data sample 105/300\n",
            "Influence for current training sample: 693.0750732421875\n",
            "External data sample 106/300\n",
            "Influence for current training sample: 5.302321910858154\n",
            "External data sample 107/300\n",
            "Influence for current training sample: 9.745346069335938\n",
            "External data sample 108/300\n",
            "Influence for current training sample: 86.81546783447266\n",
            "External data sample 109/300\n",
            "Influence for current training sample: 178.11276245117188\n",
            "External data sample 110/300\n",
            "Influence for current training sample: -26.721965789794922\n",
            "External data sample 111/300\n",
            "Influence for current training sample: 87.33763885498047\n",
            "External data sample 112/300\n",
            "Influence for current training sample: 388.7033996582031\n",
            "External data sample 113/300\n",
            "Influence for current training sample: 84.00386047363281\n",
            "External data sample 114/300\n",
            "Influence for current training sample: -12.604130744934082\n",
            "External data sample 115/300\n",
            "Influence for current training sample: 173.9536590576172\n",
            "External data sample 116/300\n",
            "Influence for current training sample: -103.8309097290039\n",
            "External data sample 117/300\n",
            "Influence for current training sample: -58.78936004638672\n",
            "External data sample 118/300\n",
            "Influence for current training sample: -112.03282165527344\n",
            "External data sample 119/300\n",
            "Influence for current training sample: -36.80668640136719\n",
            "External data sample 120/300\n",
            "Influence for current training sample: 154.33294677734375\n",
            "External data sample 121/300\n",
            "Influence for current training sample: 17.850854873657227\n",
            "External data sample 122/300\n",
            "Influence for current training sample: 21.186532974243164\n",
            "External data sample 123/300\n",
            "Influence for current training sample: -135.0305938720703\n",
            "External data sample 124/300\n",
            "Influence for current training sample: -6.812227725982666\n",
            "External data sample 125/300\n",
            "Influence for current training sample: 130.47982788085938\n",
            "External data sample 126/300\n",
            "Influence for current training sample: -36.7988395690918\n",
            "External data sample 127/300\n",
            "Influence for current training sample: 149.80398559570312\n",
            "External data sample 128/300\n",
            "Influence for current training sample: -3.59098482131958\n",
            "External data sample 129/300\n",
            "Influence for current training sample: -80.30960083007812\n",
            "External data sample 130/300\n",
            "Influence for current training sample: -18.791282653808594\n",
            "External data sample 131/300\n",
            "Influence for current training sample: -36.21219253540039\n",
            "External data sample 132/300\n",
            "Influence for current training sample: -6.778732776641846\n",
            "External data sample 133/300\n",
            "Influence for current training sample: -168.2659912109375\n",
            "External data sample 134/300\n",
            "Influence for current training sample: -207.34349060058594\n",
            "External data sample 135/300\n",
            "Influence for current training sample: 354.4434509277344\n",
            "External data sample 136/300\n",
            "Influence for current training sample: 11.803017616271973\n",
            "External data sample 137/300\n",
            "Influence for current training sample: 47.316131591796875\n",
            "External data sample 138/300\n",
            "Influence for current training sample: -42.46892547607422\n",
            "External data sample 139/300\n",
            "Influence for current training sample: 1.0140241384506226\n",
            "External data sample 140/300\n",
            "Influence for current training sample: 97.4774169921875\n",
            "External data sample 141/300\n",
            "Influence for current training sample: 20.436267852783203\n",
            "External data sample 142/300\n",
            "Influence for current training sample: 38.43949508666992\n",
            "External data sample 143/300\n",
            "Influence for current training sample: 52.47957992553711\n",
            "External data sample 144/300\n",
            "Influence for current training sample: -6.277654647827148\n",
            "External data sample 145/300\n",
            "Influence for current training sample: -19.23260498046875\n",
            "External data sample 146/300\n",
            "Influence for current training sample: -13.733287811279297\n",
            "External data sample 147/300\n",
            "Influence for current training sample: 0.9477443695068359\n",
            "External data sample 148/300\n",
            "Influence for current training sample: 4.713265419006348\n",
            "External data sample 149/300\n",
            "Influence for current training sample: 86.13690185546875\n",
            "External data sample 150/300\n",
            "Influence for current training sample: 218.2434539794922\n",
            "External data sample 151/300\n",
            "Influence for current training sample: -12.804771423339844\n",
            "External data sample 152/300\n",
            "Influence for current training sample: -59.16553497314453\n",
            "External data sample 153/300\n",
            "Influence for current training sample: -78.19522094726562\n",
            "External data sample 154/300\n",
            "Influence for current training sample: 78.7949447631836\n",
            "External data sample 155/300\n",
            "Influence for current training sample: 91.45616912841797\n",
            "External data sample 156/300\n",
            "Influence for current training sample: 31.3763370513916\n",
            "External data sample 157/300\n",
            "Influence for current training sample: 76.73143005371094\n",
            "External data sample 158/300\n",
            "Influence for current training sample: 59.15813064575195\n",
            "External data sample 159/300\n",
            "Influence for current training sample: 32.45988464355469\n",
            "External data sample 160/300\n",
            "Influence for current training sample: -280.550537109375\n",
            "External data sample 161/300\n",
            "Influence for current training sample: -3.994511127471924\n",
            "External data sample 162/300\n",
            "Influence for current training sample: 105.22944641113281\n",
            "External data sample 163/300\n",
            "Influence for current training sample: -46.9572639465332\n",
            "External data sample 164/300\n",
            "Influence for current training sample: 159.51321411132812\n",
            "External data sample 165/300\n",
            "Influence for current training sample: -0.30746424198150635\n",
            "External data sample 166/300\n",
            "Influence for current training sample: 0.5850897431373596\n",
            "External data sample 167/300\n",
            "Influence for current training sample: -32.64027404785156\n",
            "External data sample 168/300\n",
            "Influence for current training sample: -0.48284852504730225\n",
            "External data sample 169/300\n",
            "Influence for current training sample: -52.09834671020508\n",
            "External data sample 170/300\n",
            "Influence for current training sample: -119.82117462158203\n",
            "External data sample 171/300\n",
            "Influence for current training sample: -52.241519927978516\n",
            "External data sample 172/300\n",
            "Influence for current training sample: 17.715229034423828\n",
            "External data sample 173/300\n",
            "Influence for current training sample: 188.3133087158203\n",
            "External data sample 174/300\n",
            "Influence for current training sample: 4.078575134277344\n",
            "External data sample 175/300\n",
            "Influence for current training sample: 35.55614471435547\n",
            "External data sample 176/300\n",
            "Influence for current training sample: 27.58711814880371\n",
            "External data sample 177/300\n",
            "Influence for current training sample: 8.069419860839844\n",
            "External data sample 178/300\n",
            "Influence for current training sample: -55.90617370605469\n",
            "External data sample 179/300\n",
            "Influence for current training sample: -76.06481170654297\n",
            "External data sample 180/300\n",
            "Influence for current training sample: -20.58566665649414\n",
            "External data sample 181/300\n",
            "Influence for current training sample: -189.33984375\n",
            "External data sample 182/300\n",
            "Influence for current training sample: -9.114181518554688\n",
            "External data sample 183/300\n",
            "Influence for current training sample: -64.43890380859375\n",
            "External data sample 184/300\n",
            "Influence for current training sample: 12.891317367553711\n",
            "External data sample 185/300\n",
            "Influence for current training sample: 56.4591178894043\n",
            "External data sample 186/300\n",
            "Influence for current training sample: -27.107633590698242\n",
            "External data sample 187/300\n",
            "Influence for current training sample: 74.9536361694336\n",
            "External data sample 188/300\n",
            "Influence for current training sample: 147.6434326171875\n",
            "External data sample 189/300\n",
            "Influence for current training sample: 6.30320405960083\n",
            "External data sample 190/300\n",
            "Influence for current training sample: 68.29035949707031\n",
            "External data sample 191/300\n",
            "Influence for current training sample: 47.97561264038086\n",
            "External data sample 192/300\n",
            "Influence for current training sample: 42.381736755371094\n",
            "External data sample 193/300\n",
            "Influence for current training sample: -32.702049255371094\n",
            "External data sample 194/300\n",
            "Influence for current training sample: -14.613431930541992\n",
            "External data sample 195/300\n",
            "Influence for current training sample: -127.02286529541016\n",
            "External data sample 196/300\n",
            "Influence for current training sample: 46.23274612426758\n",
            "External data sample 197/300\n",
            "Influence for current training sample: 13.907093048095703\n",
            "External data sample 198/300\n",
            "Influence for current training sample: -120.8275146484375\n",
            "External data sample 199/300\n",
            "Influence for current training sample: -69.6760482788086\n",
            "External data sample 200/300\n",
            "Influence for current training sample: -1.1407006978988647\n",
            "External data sample 201/300\n",
            "Influence for current training sample: 27.033905029296875\n",
            "External data sample 202/300\n",
            "Influence for current training sample: 65.18962860107422\n",
            "External data sample 203/300\n",
            "Influence for current training sample: 57.148685455322266\n",
            "External data sample 204/300\n",
            "Influence for current training sample: -224.48809814453125\n",
            "External data sample 205/300\n",
            "Influence for current training sample: -41.79303741455078\n",
            "External data sample 206/300\n",
            "Influence for current training sample: -55.71286392211914\n",
            "External data sample 207/300\n",
            "Influence for current training sample: 4.974015712738037\n",
            "External data sample 208/300\n",
            "Influence for current training sample: -158.73834228515625\n",
            "External data sample 209/300\n",
            "Influence for current training sample: -4.08292818069458\n",
            "External data sample 210/300\n",
            "Influence for current training sample: -387.056396484375\n",
            "External data sample 211/300\n",
            "Influence for current training sample: -286.06036376953125\n",
            "External data sample 212/300\n",
            "Influence for current training sample: -240.48983764648438\n",
            "External data sample 213/300\n",
            "Influence for current training sample: -168.54051208496094\n",
            "External data sample 214/300\n",
            "Influence for current training sample: 8.5407075881958\n",
            "External data sample 215/300\n",
            "Influence for current training sample: -175.5507049560547\n",
            "External data sample 216/300\n",
            "Influence for current training sample: -148.225341796875\n",
            "External data sample 217/300\n",
            "Influence for current training sample: -222.030029296875\n",
            "External data sample 218/300\n",
            "Influence for current training sample: -380.5660095214844\n",
            "External data sample 219/300\n",
            "Influence for current training sample: -97.50503540039062\n",
            "External data sample 220/300\n",
            "Influence for current training sample: -155.24607849121094\n",
            "External data sample 221/300\n",
            "Influence for current training sample: -283.8033752441406\n",
            "External data sample 222/300\n",
            "Influence for current training sample: 30.20294189453125\n",
            "External data sample 223/300\n",
            "Influence for current training sample: -375.8536071777344\n",
            "External data sample 224/300\n",
            "Influence for current training sample: 163.35568237304688\n",
            "External data sample 225/300\n",
            "Influence for current training sample: -11.55908489227295\n",
            "External data sample 226/300\n",
            "Influence for current training sample: 35.09221649169922\n",
            "External data sample 227/300\n",
            "Influence for current training sample: 57.49187469482422\n",
            "External data sample 228/300\n",
            "Influence for current training sample: 181.86004638671875\n",
            "External data sample 229/300\n",
            "Influence for current training sample: -129.045654296875\n",
            "External data sample 230/300\n",
            "Influence for current training sample: 250.7405242919922\n",
            "External data sample 231/300\n",
            "Influence for current training sample: -135.99851989746094\n",
            "External data sample 232/300\n",
            "Influence for current training sample: -38.39202117919922\n",
            "External data sample 233/300\n",
            "Influence for current training sample: -18.356937408447266\n",
            "External data sample 234/300\n",
            "Influence for current training sample: 24.126007080078125\n",
            "External data sample 235/300\n",
            "Influence for current training sample: -51.72693634033203\n",
            "External data sample 236/300\n",
            "Influence for current training sample: 133.96849060058594\n",
            "External data sample 237/300\n",
            "Influence for current training sample: 4.773000717163086\n",
            "External data sample 238/300\n",
            "Influence for current training sample: 46.923553466796875\n",
            "External data sample 239/300\n",
            "Influence for current training sample: -207.2100830078125\n",
            "External data sample 240/300\n",
            "Influence for current training sample: 63.862449645996094\n",
            "External data sample 241/300\n",
            "Influence for current training sample: 316.0079040527344\n",
            "External data sample 242/300\n",
            "Influence for current training sample: 308.39776611328125\n",
            "External data sample 243/300\n",
            "Influence for current training sample: 114.34256744384766\n",
            "External data sample 244/300\n",
            "Influence for current training sample: 265.35626220703125\n",
            "External data sample 245/300\n",
            "Influence for current training sample: -18.828147888183594\n",
            "External data sample 246/300\n",
            "Influence for current training sample: -9.58420181274414\n",
            "External data sample 247/300\n",
            "Influence for current training sample: 17.353912353515625\n",
            "External data sample 248/300\n",
            "Influence for current training sample: 276.8016662597656\n",
            "External data sample 249/300\n",
            "Influence for current training sample: -0.9928045272827148\n",
            "External data sample 250/300\n",
            "Influence for current training sample: 124.4546127319336\n",
            "External data sample 251/300\n",
            "Influence for current training sample: 423.2685852050781\n",
            "External data sample 252/300\n",
            "Influence for current training sample: -241.97647094726562\n",
            "External data sample 253/300\n",
            "Influence for current training sample: -66.35317993164062\n",
            "External data sample 254/300\n",
            "Influence for current training sample: -122.3511962890625\n",
            "External data sample 255/300\n",
            "Influence for current training sample: -49.293766021728516\n",
            "External data sample 256/300\n",
            "Influence for current training sample: 94.12199401855469\n",
            "External data sample 257/300\n",
            "Influence for current training sample: 53.30448913574219\n",
            "External data sample 258/300\n",
            "Influence for current training sample: 72.46002197265625\n",
            "External data sample 259/300\n",
            "Influence for current training sample: 130.24313354492188\n",
            "External data sample 260/300\n",
            "Influence for current training sample: -1.7485193014144897\n",
            "External data sample 261/300\n",
            "Influence for current training sample: 76.0120620727539\n",
            "External data sample 262/300\n",
            "Influence for current training sample: 13.335939407348633\n",
            "External data sample 263/300\n",
            "Influence for current training sample: 71.17597198486328\n",
            "External data sample 264/300\n",
            "Influence for current training sample: 289.57391357421875\n",
            "External data sample 265/300\n",
            "Influence for current training sample: -51.1965446472168\n",
            "External data sample 266/300\n",
            "Influence for current training sample: 98.89314270019531\n",
            "External data sample 267/300\n",
            "Influence for current training sample: -24.8988094329834\n",
            "External data sample 268/300\n",
            "Influence for current training sample: -126.53756713867188\n",
            "External data sample 269/300\n",
            "Influence for current training sample: -26.88798713684082\n",
            "External data sample 270/300\n",
            "Influence for current training sample: 30.777008056640625\n",
            "External data sample 271/300\n",
            "Influence for current training sample: -19.129653930664062\n",
            "External data sample 272/300\n",
            "Influence for current training sample: -43.736976623535156\n",
            "External data sample 273/300\n",
            "Influence for current training sample: -35.22415542602539\n",
            "External data sample 274/300\n",
            "Influence for current training sample: 0.6881742477416992\n",
            "External data sample 275/300\n",
            "Influence for current training sample: 51.16342544555664\n",
            "External data sample 276/300\n",
            "Influence for current training sample: -62.560577392578125\n",
            "External data sample 277/300\n",
            "Influence for current training sample: 2.674574375152588\n",
            "External data sample 278/300\n",
            "Influence for current training sample: 51.274925231933594\n",
            "External data sample 279/300\n",
            "Influence for current training sample: 189.44093322753906\n",
            "External data sample 280/300\n",
            "Influence for current training sample: 32.50138854980469\n",
            "External data sample 281/300\n",
            "Influence for current training sample: 10.012393951416016\n",
            "External data sample 282/300\n",
            "Influence for current training sample: 21.29410171508789\n",
            "External data sample 283/300\n",
            "Influence for current training sample: 18.86911964416504\n",
            "External data sample 284/300\n",
            "Influence for current training sample: -0.6301665306091309\n",
            "External data sample 285/300\n",
            "Influence for current training sample: 4.430468559265137\n",
            "External data sample 286/300\n",
            "Influence for current training sample: 32.62775802612305\n",
            "External data sample 287/300\n",
            "Influence for current training sample: -0.1284097284078598\n",
            "External data sample 288/300\n",
            "Influence for current training sample: -25.285125732421875\n",
            "External data sample 289/300\n",
            "Influence for current training sample: -60.262691497802734\n",
            "External data sample 290/300\n",
            "Influence for current training sample: 0.01220703125\n",
            "External data sample 291/300\n",
            "Influence for current training sample: -162.19801330566406\n",
            "External data sample 292/300\n",
            "Influence for current training sample: 17.387039184570312\n",
            "External data sample 293/300\n",
            "Influence for current training sample: 3.7724297046661377\n",
            "External data sample 294/300\n",
            "Influence for current training sample: -8.807989120483398\n",
            "External data sample 295/300\n",
            "Influence for current training sample: 10.225724220275879\n",
            "External data sample 296/300\n",
            "Influence for current training sample: -17.484697341918945\n",
            "External data sample 297/300\n",
            "Influence for current training sample: 64.12066650390625\n",
            "External data sample 298/300\n",
            "Influence for current training sample: -23.586387634277344\n",
            "External data sample 299/300\n",
            "Influence for current training sample: 17.66486358642578\n",
            "External data sample 300/300\n",
            "Influence for current training sample: -1.0930207967758179\n",
            "Most influential training points: [(104, 693.0750732421875), (3, 648.889892578125), (90, 628.1036376953125), (88, 556.17626953125), (11, 520.5252075195312), (28, 472.4814453125), (250, 423.2685852050781), (50, 399.8251647949219), (111, 388.7033996582031), (89, 367.0245361328125), (134, 354.4434509277344), (97, 322.9530029296875), (240, 316.0079040527344), (241, 308.39776611328125), (263, 289.57391357421875), (36, 279.8090515136719), (247, 276.8016662597656), (243, 265.35626220703125), (56, 254.85226440429688), (229, 250.7405242919922), (66, 243.5226593017578), (149, 218.2434539794922), (74, 216.46368408203125), (57, 205.56210327148438), (22, 200.32980346679688), (278, 189.44093322753906), (67, 189.01763916015625), (172, 188.3133087158203), (24, 182.62985229492188), (227, 181.86004638671875), (108, 178.11276245117188), (114, 173.9536590576172), (223, 163.35568237304688), (30, 162.97471618652344), (163, 159.51321411132812), (119, 154.33294677734375), (126, 149.80398559570312), (187, 147.6434326171875), (84, 137.22132873535156), (69, 135.01455688476562), (235, 133.96849060058594), (59, 133.91714477539062), (124, 130.47982788085938), (258, 130.24313354492188), (26, 129.8501739501953), (102, 124.80982971191406), (249, 124.4546127319336), (242, 114.34256744384766), (161, 105.22944641113281), (82, 101.21566772460938), (265, 98.89314270019531), (139, 97.4774169921875), (96, 96.65048217773438), (1, 95.83807373046875), (255, 94.12199401855469), (91, 93.54623413085938), (154, 91.45616912841797), (110, 87.33763885498047), (42, 87.13249206542969), (107, 86.81546783447266), (148, 86.13690185546875), (112, 84.00386047363281), (153, 78.7949447631836), (156, 76.73143005371094), (260, 76.0120620727539), (186, 74.9536361694336), (31, 73.64009094238281), (257, 72.46002197265625), (262, 71.17597198486328), (64, 68.6878662109375), (189, 68.29035949707031), (44, 67.35066223144531), (201, 65.18962860107422), (296, 64.12066650390625), (239, 63.862449645996094), (103, 63.63408660888672), (157, 59.15813064575195), (77, 58.73402404785156), (61, 57.54473876953125), (226, 57.49187469482422), (202, 57.148685455322266), (81, 56.94601821899414), (184, 56.4591178894043), (65, 56.169429779052734), (40, 54.12518310546875), (256, 53.30448913574219), (142, 52.47957992553711), (277, 51.274925231933594), (274, 51.16342544555664), (25, 50.669151306152344), (73, 50.15657043457031), (190, 47.97561264038086), (85, 47.45850372314453), (136, 47.316131591796875), (237, 46.923553466796875), (46, 46.275760650634766), (195, 46.23274612426758), (51, 46.18017578125), (191, 42.381736755371094), (141, 38.43949508666992), (8, 37.25246047973633), (21, 36.78423309326172), (174, 35.55614471435547), (225, 35.09221649169922), (86, 34.70182418823242), (72, 32.907997131347656), (285, 32.62775802612305), (279, 32.50138854980469), (158, 32.45988464355469), (155, 31.3763370513916), (269, 30.777008056640625), (221, 30.20294189453125), (18, 27.691017150878906), (175, 27.58711814880371), (71, 27.089763641357422), (200, 27.033905029296875), (27, 25.833568572998047), (98, 24.859149932861328), (233, 24.126007080078125), (76, 23.1452579498291), (54, 22.37122917175293), (101, 21.688064575195312), (281, 21.29410171508789), (121, 21.186532974243164), (140, 20.436267852783203), (282, 18.86911964416504), (92, 18.616741180419922), (80, 18.385623931884766), (120, 17.850854873657227), (75, 17.7576847076416), (171, 17.715229034423828), (298, 17.66486358642578), (291, 17.387039184570312), (246, 17.353912353515625), (196, 13.907093048095703), (261, 13.335939407348633), (183, 12.891317367553711), (135, 11.803017616271973), (32, 11.155182838439941), (294, 10.225724220275879), (280, 10.012393951416016), (106, 9.745346069335938), (39, 8.626972198486328), (213, 8.5407075881958), (176, 8.069419860839844), (188, 6.30320405960083), (105, 5.302321910858154), (206, 4.974015712738037), (236, 4.773000717163086), (147, 4.713265419006348), (284, 4.430468559265137), (173, 4.078575134277344), (292, 3.7724297046661377), (276, 2.674574375152588), (63, 1.4420409202575684), (138, 1.0140241384506226), (146, 0.9477443695068359), (273, 0.6881742477416992), (165, 0.5850897431373596), (68, 0.381960928440094), (289, 0.01220703125), (286, -0.1284097284078598), (164, -0.30746424198150635), (49, -0.4061005711555481), (167, -0.48284852504730225), (283, -0.6301665306091309), (248, -0.9928045272827148), (299, -1.0930207967758179), (199, -1.1407006978988647), (60, -1.4095838069915771), (259, -1.7485193014144897), (62, -2.739863395690918), (127, -3.59098482131958), (35, -3.7520856857299805), (160, -3.994511127471924), (208, -4.08292818069458), (143, -6.277654647827148), (131, -6.778732776641846), (123, -6.812227725982666), (100, -8.365758895874023), (293, -8.807989120483398), (33, -8.961633682250977), (181, -9.114181518554688), (38, -9.450958251953125), (37, -9.50151252746582), (245, -9.58420181274414), (224, -11.55908489227295), (113, -12.604130744934082), (150, -12.804771423339844), (145, -13.733287811279297), (193, -14.613431930541992), (45, -17.297489166259766), (295, -17.484697341918945), (232, -18.356937408447266), (129, -18.791282653808594), (244, -18.828147888183594), (270, -19.129653930664062), (144, -19.23260498046875), (179, -20.58566665649414), (93, -22.37355613708496), (297, -23.586387634277344), (266, -24.8988094329834), (287, -25.285125732421875), (109, -26.721965789794922), (268, -26.88798713684082), (185, -27.107633590698242), (166, -32.64027404785156), (192, -32.702049255371094), (272, -35.22415542602539), (130, -36.21219253540039), (125, -36.7988395690918), (118, -36.80668640136719), (231, -38.39202117919922), (15, -39.91143798828125), (204, -41.79303741455078), (137, -42.46892547607422), (271, -43.736976623535156), (162, -46.9572639465332), (254, -49.293766021728516), (264, -51.1965446472168), (234, -51.72693634033203), (168, -52.09834671020508), (170, -52.241519927978516), (205, -55.71286392211914), (177, -55.90617370605469), (116, -58.78936004638672), (151, -59.16553497314453), (288, -60.262691497802734), (275, -62.560577392578125), (34, -63.38135528564453), (182, -64.43890380859375), (252, -66.35317993164062), (198, -69.6760482788086), (178, -76.06481170654297), (48, -76.98944091796875), (152, -78.19522094726562), (53, -78.65729522705078), (128, -80.30960083007812), (20, -84.03826141357422), (41, -89.04771423339844), (218, -97.50503540039062), (115, -103.8309097290039), (10, -105.2376708984375), (17, -110.88407135009766), (117, -112.03282165527344), (94, -116.48665618896484), (83, -116.97663879394531), (169, -119.82117462158203), (197, -120.8275146484375), (253, -122.3511962890625), (267, -126.53756713867188), (194, -127.02286529541016), (6, -128.4178009033203), (228, -129.045654296875), (7, -132.17430114746094), (122, -135.0305938720703), (230, -135.99851989746094), (70, -136.05300903320312), (78, -138.7368621826172), (14, -141.1981964111328), (58, -144.33920288085938), (95, -146.1603240966797), (215, -148.225341796875), (219, -155.24607849121094), (4, -157.52743530273438), (207, -158.73834228515625), (290, -162.19801330566406), (132, -168.2659912109375), (212, -168.54051208496094), (19, -168.62701416015625), (214, -175.5507049560547), (0, -180.46450805664062), (180, -189.33984375), (12, -193.526611328125), (43, -204.76998901367188), (238, -207.2100830078125), (133, -207.34349060058594), (216, -222.030029296875), (47, -224.31912231445312), (203, -224.48809814453125), (99, -235.45877075195312), (55, -238.28030395507812), (211, -240.48983764648438), (251, -241.97647094726562), (23, -256.1189270019531), (79, -258.67822265625), (16, -266.0405578613281), (5, -267.3226623535156), (159, -280.550537109375), (220, -283.8033752441406), (210, -286.06036376953125), (9, -290.90106201171875), (87, -296.3984069824219), (2, -339.0596618652344), (52, -359.9624328613281), (222, -375.8536071777344), (29, -376.5777282714844), (217, -380.5660095214844), (209, -387.056396484375), (13, -410.25860595703125)]\n",
            "/content/nnti-project-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning Model with Influencial Points"
      ],
      "metadata": {
        "id": "9N5CB4lErhPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the influence score\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "influence_scores = pd.read_csv(\"ranked_indices_full_set.csv\")\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())\n",
        "\n",
        "positive_count = influence_scores[influence_scores['Influence Score'] > 0].shape[0]\n",
        "print(positive_count)\n",
        "print(influence_scores.iloc[100])"
      ],
      "metadata": {
        "id": "a-z92duzrgyq",
        "outputId": "e3ba313c-b021-4e30-c48a-203a8dc315e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nnti-project-25\n",
            "161\n",
            "Index               8.00000\n",
            "Influence Score    37.25246\n",
            "Name: 100, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting new train data with top 100 influential ext_data points\n",
        "ext_data = pd.read_csv(\"./tasks/External-Dataset_for_Task2.csv\")\n",
        "ext_data = ext_data.iloc[influence_scores.iloc[:100]['Index']] # selecting top 100 points\n",
        "ext_data = ext_data.rename(columns={\"Label\": \"label\"}) # making column names consistent\n",
        "ext_dataset = HF_Dataset.from_pandas(ext_data)\n",
        "ext_dataset = ext_dataset.remove_columns([\"__index__\"]) if \"__index__\" in ext_dataset.column_names else ext_dataset\n",
        "\n",
        "# train-test-val split\n",
        "split_dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42) # 80:20\n",
        "train_valid_dataset = split_dataset[\"train\"]\n",
        "test_dataset = split_dataset[\"test\"]\n",
        "split_train_valid = train_valid_dataset.train_test_split(test_size=0.1, seed=42) # 90:10\n",
        "train_dataset = split_train_valid[\"train\"]\n",
        "valid_dataset = split_train_valid[\"test\"]\n",
        "combined_train = concatenate_datasets([train_dataset, ext_dataset])\n",
        "\n",
        "# create dataset and dataloader\n",
        "combined_train = SMILESDataset(combined_train, tokenizer, max_length=128)\n",
        "valid_dataset = SMILESDataset(valid_dataset, tokenizer, max_length=128)\n",
        "test_dataset  = SMILESDataset(test_dataset, tokenizer, max_length=128)\n",
        "combined_train_dataloader = DataLoader(combined_train, batch_size=16, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
        "test_dataloader  = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "Xp4rEF6IrzIn"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS_reg = 200\n",
        "LEARNING_RATE_reg = 1e-7\n",
        "patience = 5\n",
        "epochs_no_improve = 0\n",
        "best_valid_loss = float(\"inf\")\n",
        "optimizer_reg = torch.optim.Adam(mlm_regression_model.parameters(), lr=LEARNING_RATE_reg)\n",
        "loss_fn = nn.MSELoss()\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "\n",
        "for epoch in range(EPOCHS_reg):\n",
        "    mlm_regression_model.train()\n",
        "    total_train_loss = 0.0\n",
        "\n",
        "    # training with combined set\n",
        "    for batch in combined_train_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        mask = batch['attention_mask'].to(device)\n",
        "        targets = batch['target'].to(device)\n",
        "\n",
        "        optimizer_reg.zero_grad()\n",
        "        outputs = mlm_regression_model(input_ids, mask)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer_reg.step()\n",
        "\n",
        "        total_train_loss += loss.item() * input_ids.size(0)\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataset)\n",
        "    print(f\"Epoch {epoch+1} - Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # validation\n",
        "    mlm_regression_model.eval()\n",
        "    total_valid_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in valid_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            mask = batch['attention_mask'].to(device)\n",
        "            targets = batch['target'].to(device)\n",
        "            outputs = mlm_regression_model(input_ids, mask)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            total_valid_loss += loss.item() * input_ids.size(0)\n",
        "\n",
        "    avg_valid_loss = total_valid_loss / len(valid_dataset)\n",
        "    print(f\"Epoch {epoch+1} - Validation Loss: {avg_valid_loss:.4f}\")\n",
        "\n",
        "    # early stop check\n",
        "    if avg_valid_loss < best_valid_loss:\n",
        "        best_valid_loss = avg_valid_loss\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(mlm_regression_model.state_dict(), \"best_mlm_regression_model_task2.pth\")\n",
        "        print(\"Validation loss improved, model saved.\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"No improvement for {epochs_no_improve} consecutive epochs.\")\n",
        "    if epochs_no_improve >= patience:\n",
        "        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "        break\n",
        "\n",
        "# reset the path to git repo\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "aydqwQGp2Qfz",
        "outputId": "86be353b-2bcd-428b-f27d-a4a6a38c4718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Train Loss: 6.5601\n",
            "Epoch 1 - Validation Loss: 6.0653\n",
            "Validation loss improved, model saved.\n",
            "Epoch 2 - Train Loss: 5.5992\n",
            "Epoch 2 - Validation Loss: 5.1098\n",
            "Validation loss improved, model saved.\n",
            "Epoch 3 - Train Loss: 4.7369\n",
            "Epoch 3 - Validation Loss: 4.2993\n",
            "Validation loss improved, model saved.\n",
            "Epoch 4 - Train Loss: 3.9592\n",
            "Epoch 4 - Validation Loss: 3.5940\n",
            "Validation loss improved, model saved.\n",
            "Epoch 5 - Train Loss: 3.3479\n",
            "Epoch 5 - Validation Loss: 2.9269\n",
            "Validation loss improved, model saved.\n",
            "Epoch 6 - Train Loss: 2.8080\n",
            "Epoch 6 - Validation Loss: 2.4272\n",
            "Validation loss improved, model saved.\n",
            "Epoch 7 - Train Loss: 2.3320\n",
            "Epoch 7 - Validation Loss: 2.0372\n",
            "Validation loss improved, model saved.\n",
            "Epoch 8 - Train Loss: 2.0253\n",
            "Epoch 8 - Validation Loss: 1.7211\n",
            "Validation loss improved, model saved.\n",
            "Epoch 9 - Train Loss: 1.7779\n",
            "Epoch 9 - Validation Loss: 1.5551\n",
            "Validation loss improved, model saved.\n",
            "Epoch 10 - Train Loss: 1.6379\n",
            "Epoch 10 - Validation Loss: 1.4419\n",
            "Validation loss improved, model saved.\n",
            "Epoch 11 - Train Loss: 1.5389\n",
            "Epoch 11 - Validation Loss: 1.3832\n",
            "Validation loss improved, model saved.\n",
            "Epoch 12 - Train Loss: 1.5096\n",
            "Epoch 12 - Validation Loss: 1.3646\n",
            "Validation loss improved, model saved.\n",
            "Epoch 13 - Train Loss: 1.4686\n",
            "Epoch 13 - Validation Loss: 1.3394\n",
            "Validation loss improved, model saved.\n",
            "Epoch 14 - Train Loss: 1.4684\n",
            "Epoch 14 - Validation Loss: 1.3127\n",
            "Validation loss improved, model saved.\n",
            "Epoch 15 - Train Loss: 1.4461\n",
            "Epoch 15 - Validation Loss: 1.3100\n",
            "Validation loss improved, model saved.\n",
            "Epoch 16 - Train Loss: 1.4392\n",
            "Epoch 16 - Validation Loss: 1.2720\n",
            "Validation loss improved, model saved.\n",
            "Epoch 17 - Train Loss: 1.4031\n",
            "Epoch 17 - Validation Loss: 1.2698\n",
            "Validation loss improved, model saved.\n",
            "Epoch 18 - Train Loss: 1.3996\n",
            "Epoch 18 - Validation Loss: 1.2744\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 19 - Train Loss: 1.4022\n",
            "Epoch 19 - Validation Loss: 1.2612\n",
            "Validation loss improved, model saved.\n",
            "Epoch 20 - Train Loss: 1.3793\n",
            "Epoch 20 - Validation Loss: 1.2265\n",
            "Validation loss improved, model saved.\n",
            "Epoch 21 - Train Loss: 1.3458\n",
            "Epoch 21 - Validation Loss: 1.1955\n",
            "Validation loss improved, model saved.\n",
            "Epoch 22 - Train Loss: 1.3683\n",
            "Epoch 22 - Validation Loss: 1.2195\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 23 - Train Loss: 1.3434\n",
            "Epoch 23 - Validation Loss: 1.1776\n",
            "Validation loss improved, model saved.\n",
            "Epoch 24 - Train Loss: 1.3227\n",
            "Epoch 24 - Validation Loss: 1.1936\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 25 - Train Loss: 1.3424\n",
            "Epoch 25 - Validation Loss: 1.1782\n",
            "No improvement for 2 consecutive epochs.\n",
            "Epoch 26 - Train Loss: 1.3184\n",
            "Epoch 26 - Validation Loss: 1.1785\n",
            "No improvement for 3 consecutive epochs.\n",
            "Epoch 27 - Train Loss: 1.2997\n",
            "Epoch 27 - Validation Loss: 1.1514\n",
            "Validation loss improved, model saved.\n",
            "Epoch 28 - Train Loss: 1.3037\n",
            "Epoch 28 - Validation Loss: 1.1435\n",
            "Validation loss improved, model saved.\n",
            "Epoch 29 - Train Loss: 1.2873\n",
            "Epoch 29 - Validation Loss: 1.1640\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 30 - Train Loss: 1.2856\n",
            "Epoch 30 - Validation Loss: 1.1366\n",
            "Validation loss improved, model saved.\n",
            "Epoch 31 - Train Loss: 1.2726\n",
            "Epoch 31 - Validation Loss: 1.1270\n",
            "Validation loss improved, model saved.\n",
            "Epoch 32 - Train Loss: 1.2758\n",
            "Epoch 32 - Validation Loss: 1.1033\n",
            "Validation loss improved, model saved.\n",
            "Epoch 33 - Train Loss: 1.2451\n",
            "Epoch 33 - Validation Loss: 1.0970\n",
            "Validation loss improved, model saved.\n",
            "Epoch 34 - Train Loss: 1.2418\n",
            "Epoch 34 - Validation Loss: 1.1056\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 35 - Train Loss: 1.2305\n",
            "Epoch 35 - Validation Loss: 1.1314\n",
            "No improvement for 2 consecutive epochs.\n",
            "Epoch 36 - Train Loss: 1.2363\n",
            "Epoch 36 - Validation Loss: 1.0954\n",
            "Validation loss improved, model saved.\n",
            "Epoch 37 - Train Loss: 1.2205\n",
            "Epoch 37 - Validation Loss: 1.0741\n",
            "Validation loss improved, model saved.\n",
            "Epoch 38 - Train Loss: 1.2159\n",
            "Epoch 38 - Validation Loss: 1.0773\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 39 - Train Loss: 1.2144\n",
            "Epoch 39 - Validation Loss: 1.0976\n",
            "No improvement for 2 consecutive epochs.\n",
            "Epoch 40 - Train Loss: 1.2150\n",
            "Epoch 40 - Validation Loss: 1.0508\n",
            "Validation loss improved, model saved.\n",
            "Epoch 41 - Train Loss: 1.1963\n",
            "Epoch 41 - Validation Loss: 1.0715\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 42 - Train Loss: 1.1885\n",
            "Epoch 42 - Validation Loss: 1.0442\n",
            "Validation loss improved, model saved.\n",
            "Epoch 43 - Train Loss: 1.2090\n",
            "Epoch 43 - Validation Loss: 1.0431\n",
            "Validation loss improved, model saved.\n",
            "Epoch 44 - Train Loss: 1.1776\n",
            "Epoch 44 - Validation Loss: 1.0499\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 45 - Train Loss: 1.1528\n",
            "Epoch 45 - Validation Loss: 1.0357\n",
            "Validation loss improved, model saved.\n",
            "Epoch 46 - Train Loss: 1.1655\n",
            "Epoch 46 - Validation Loss: 1.0482\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 47 - Train Loss: 1.1583\n",
            "Epoch 47 - Validation Loss: 1.0639\n",
            "No improvement for 2 consecutive epochs.\n",
            "Epoch 48 - Train Loss: 1.1497\n",
            "Epoch 48 - Validation Loss: 1.0211\n",
            "Validation loss improved, model saved.\n",
            "Epoch 49 - Train Loss: 1.1569\n",
            "Epoch 49 - Validation Loss: 1.0262\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 50 - Train Loss: 1.1334\n",
            "Epoch 50 - Validation Loss: 1.0266\n",
            "No improvement for 2 consecutive epochs.\n",
            "Epoch 51 - Train Loss: 1.1336\n",
            "Epoch 51 - Validation Loss: 1.0354\n",
            "No improvement for 3 consecutive epochs.\n",
            "Epoch 52 - Train Loss: 1.1282\n",
            "Epoch 52 - Validation Loss: 1.0216\n",
            "No improvement for 4 consecutive epochs.\n",
            "Epoch 53 - Train Loss: 1.1078\n",
            "Epoch 53 - Validation Loss: 1.0072\n",
            "Validation loss improved, model saved.\n",
            "Epoch 54 - Train Loss: 1.1207\n",
            "Epoch 54 - Validation Loss: 1.0289\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 55 - Train Loss: 1.1117\n",
            "Epoch 55 - Validation Loss: 0.9792\n",
            "Validation loss improved, model saved.\n",
            "Epoch 56 - Train Loss: 1.1048\n",
            "Epoch 56 - Validation Loss: 0.9735\n",
            "Validation loss improved, model saved.\n",
            "Epoch 57 - Train Loss: 1.1051\n",
            "Epoch 57 - Validation Loss: 0.9756\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 58 - Train Loss: 1.0947\n",
            "Epoch 58 - Validation Loss: 0.9806\n",
            "No improvement for 2 consecutive epochs.\n",
            "Epoch 59 - Train Loss: 1.0913\n",
            "Epoch 59 - Validation Loss: 0.9829\n",
            "No improvement for 3 consecutive epochs.\n",
            "Epoch 60 - Train Loss: 1.0818\n",
            "Epoch 60 - Validation Loss: 0.9629\n",
            "Validation loss improved, model saved.\n",
            "Epoch 61 - Train Loss: 1.0833\n",
            "Epoch 61 - Validation Loss: 0.9736\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 62 - Train Loss: 1.0668\n",
            "Epoch 62 - Validation Loss: 0.9647\n",
            "No improvement for 2 consecutive epochs.\n",
            "Epoch 63 - Train Loss: 1.0653\n",
            "Epoch 63 - Validation Loss: 0.9397\n",
            "Validation loss improved, model saved.\n",
            "Epoch 64 - Train Loss: 1.0642\n",
            "Epoch 64 - Validation Loss: 0.9755\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 65 - Train Loss: 1.0794\n",
            "Epoch 65 - Validation Loss: 0.9499\n",
            "No improvement for 2 consecutive epochs.\n",
            "Epoch 66 - Train Loss: 1.0540\n",
            "Epoch 66 - Validation Loss: 1.0098\n",
            "No improvement for 3 consecutive epochs.\n",
            "Epoch 67 - Train Loss: 1.0523\n",
            "Epoch 67 - Validation Loss: 0.9180\n",
            "Validation loss improved, model saved.\n",
            "Epoch 68 - Train Loss: 1.0569\n",
            "Epoch 68 - Validation Loss: 0.9578\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 69 - Train Loss: 1.0377\n",
            "Epoch 69 - Validation Loss: 0.9141\n",
            "Validation loss improved, model saved.\n",
            "Epoch 70 - Train Loss: 1.0316\n",
            "Epoch 70 - Validation Loss: 0.9125\n",
            "Validation loss improved, model saved.\n",
            "Epoch 71 - Train Loss: 1.0272\n",
            "Epoch 71 - Validation Loss: 0.9305\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 72 - Train Loss: 1.0276\n",
            "Epoch 72 - Validation Loss: 0.9192\n",
            "No improvement for 2 consecutive epochs.\n",
            "Epoch 73 - Train Loss: 1.0210\n",
            "Epoch 73 - Validation Loss: 0.9125\n",
            "Validation loss improved, model saved.\n",
            "Epoch 74 - Train Loss: 1.0166\n",
            "Epoch 74 - Validation Loss: 0.9151\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 75 - Train Loss: 1.0128\n",
            "Epoch 75 - Validation Loss: 0.8875\n",
            "Validation loss improved, model saved.\n",
            "Epoch 76 - Train Loss: 0.9987\n",
            "Epoch 76 - Validation Loss: 0.9244\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 77 - Train Loss: 0.9932\n",
            "Epoch 77 - Validation Loss: 0.9070\n",
            "No improvement for 2 consecutive epochs.\n",
            "Epoch 78 - Train Loss: 1.0033\n",
            "Epoch 78 - Validation Loss: 0.8914\n",
            "No improvement for 3 consecutive epochs.\n",
            "Epoch 79 - Train Loss: 0.9843\n",
            "Epoch 79 - Validation Loss: 0.8951\n",
            "No improvement for 4 consecutive epochs.\n",
            "Epoch 80 - Train Loss: 0.9761\n",
            "Epoch 80 - Validation Loss: 0.8937\n",
            "No improvement for 5 consecutive epochs.\n",
            "Early stopping triggered after 80 epochs.\n",
            "/content/nnti-project-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test evaluation\n",
        "influences = []\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# loading pre-trained mlm regression model\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "mlm_regression_model = MoLFormerWithRegressionHead(mlm_finetuned_model).to(device)\n",
        "mlm_regression_model.load_state_dict(torch.load(\"best_mlm_regression_model_task2.pth\"))\n",
        "# reset the path to git repo\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())\n",
        "# regression_model = mlm_regression_model.eval()\n",
        "\n",
        "mlm_regression_model.eval()\n",
        "total_test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        mask = batch['attention_mask'].to(device)\n",
        "        targets = batch['target'].to(device)\n",
        "        outputs = mlm_regression_model(input_ids, mask)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        total_test_loss += loss.item() * input_ids.size(0)\n",
        "\n",
        "avg_test_loss = total_test_loss / len(test_dataset)\n",
        "print()\n",
        "print(f\"Fine Tuned Model with Influential Ext Sample Test Loss: {avg_test_loss:.4f}\")"
      ],
      "metadata": {
        "id": "tMxGZLJuEtNR",
        "outputId": "e1df45ec-40af-4a1c-b1a3-e3ef51dba97e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-79-89bebbb64ac3>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  mlm_regression_model.load_state_dict(torch.load(\"best_mlm_regression_model_task2.pth\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nnti-project-25\n",
            "\n",
            "Fine Tuned Model with Influential Ext Sample Test Loss: 0.9426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Garbage Cleaning"
      ],
      "metadata": {
        "id": "KwlEt-ylDOuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del regression_model\n",
        "del train_dataset\n",
        "del test_dataset\n",
        "del train_dataloader\n",
        "del test_dataloader\n",
        "del ext_dataset\n",
        "del ext_dataloader\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "aqszc-zLCuSq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}