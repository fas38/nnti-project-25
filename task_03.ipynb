{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyOIH0YQE24XtJmcgLT+My/Q"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize"
      ],
      "metadata": {
        "id": "3lzYptk8YhQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the repo\n",
        "!git clone https://fas38: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@github.com/fas38/nnti-project-25.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6Vz1ixnTucc",
        "outputId": "89aa84f1-ca0f-4efe-a0e3-965d162b03a6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nnti-project-25'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 64 (delta 28), reused 18 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (64/64), 1.85 MiB | 7.59 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "# for mouting drive in google colab\n",
        "drive.mount('/content/drive')\n",
        "# set path\n",
        "%cd /content/nnti-project-25/\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "wmaTcnvQEA8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b288126-c865-421d-8afa-255cadafa877"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/nnti-project-25\n",
            "/content/nnti-project-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install required packages\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZcvcu2FELD0",
        "outputId": "8416cbdf-ced1-44aa-ffac-a8fff9f58325",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (7.7.1)\n",
            "Collecting jupyter (from -r requirements.txt (line 2))\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.5.1+cu124)\n",
            "Collecting datasets (from -r requirements.txt (line 7))\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.48.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.6.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.19.7)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r requirements.txt (line 1)) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r requirements.txt (line 1)) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r requirements.txt (line 1)) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r requirements.txt (line 1)) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r requirements.txt (line 1)) (3.0.13)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter->-r requirements.txt (line 2)) (6.5.5)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter->-r requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter->-r requirements.txt (line 2)) (7.16.6)\n",
            "Collecting jupyterlab (from jupyter->-r requirements.txt (line 2))\n",
            "  Downloading jupyterlab-4.3.5-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 4)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 4)) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 7)) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 7))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 7)) (4.67.1)\n",
            "Collecting xxhash (from datasets->-r requirements.txt (line 7))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->-r requirements.txt (line 7))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 7)) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 7)) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 7)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 8)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 8)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 8)) (0.5.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (3.5.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (2.10.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 10)) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 10)) (4.0.12)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 1)) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 1)) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 1)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 1)) (1.6.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 1)) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 1)) (6.4.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (4.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 10)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 7)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 7)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 7)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 7)) (2025.1.31)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (5.10.4)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 2)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (1.5.1)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->-r requirements.txt (line 2)) (0.28.1)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->-r requirements.txt (line 2)) (0.2.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 2)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 10)) (5.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 2)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 2)) (0.14.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (0.8.4)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 1))\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter->-r requirements.txt (line 2)) (21.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 1)) (0.4)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 2)) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 2)) (4.23.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook->jupyter->-r requirements.txt (line 2)) (2.21.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 1)) (0.2.13)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 2)) (2.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 2)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 2)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 2)) (0.23.1)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 2)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 2)) (2.22)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2)) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2)) (24.11.1)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 2))\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.3.5-py3-none-any.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
            "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: xxhash, uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, json5, jedi, fqdn, dill, async-lru, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jupyter-server-terminals, jupyter-client, arrow, nvidia-cusolver-cu12, isoduration, datasets, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "Successfully installed arrow-1.3.0 async-lru-2.0.4 datasets-3.3.2 dill-0.3.8 fqdn-1.5.1 isoduration-20.11.0 jedi-0.19.2 json5-0.10.0 jupyter-1.1.1 jupyter-client-7.4.9 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.3.5 jupyterlab-server-2.27.3 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 overrides-7.7.0 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from datasets import Dataset as HF_Dataset\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from itertools import islice\n",
        "import random\n",
        "from joblib import Parallel, delayed"
      ],
      "metadata": {
        "id": "ts0KumnWFv68"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "vIPexXD5A1we"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class and Methods"
      ],
      "metadata": {
        "id": "5kzNKy2482eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model class with regression head\n",
        "class MoLFormerWithRegressionHead(nn.Module):\n",
        "    # TODO: your code goes here\n",
        "  def __init__(self,model):\n",
        "    super(MoLFormerWithRegressionHead, self).__init__()\n",
        "    self.pretrained = model\n",
        "    hidden_size = self.pretrained.config.hidden_size\n",
        "\n",
        "    self.regression = nn.Linear(hidden_size, 1)\n",
        "\n",
        "\n",
        "  def forward(self, ids, mask):\n",
        "    # pass input to the pre-trained model\n",
        "    output = self.pretrained(ids, attention_mask=mask)\n",
        "    # extracts the last hidden state\n",
        "    hidden_states = output.last_hidden_state\n",
        "    # selects the cls token, represents the summary of the entire sequence\n",
        "    cls_representation = hidden_states[:, 0, :]\n",
        "\n",
        "    output = self.regression(cls_representation)\n",
        "    return output.squeeze(-1) # to remove the last dimension\n",
        "\n",
        "# dataset class\n",
        "class SMILESDataset(Dataset):\n",
        "\n",
        "  def __init__(self, data, tokenizer, max_length):\n",
        "      self.data = data\n",
        "      self.tokenizer = tokenizer\n",
        "      self.max_len = max_length\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      row = self.data[idx]\n",
        "      SMILES = row['SMILES']\n",
        "      label = row['label']\n",
        "\n",
        "      inputs = self.tokenizer.encode_plus(\n",
        "      SMILES,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      padding='max_length',\n",
        "      return_token_type_ids=False,\n",
        "      truncation=True\n",
        "  )\n",
        "\n",
        "      return {\n",
        "    'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
        "    'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
        "    'target': torch.tensor(label, dtype=torch.float)  # Directly convert the target to float\n",
        "}"
      ],
      "metadata": {
        "id": "zi9ZNUTB9A43"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methods for TS-DS"
      ],
      "metadata": {
        "id": "FuHUedFOIL7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class TS_DShapley:\n",
        "#   def __init__(self, target_model, train_dataloader, val_dataloader, num_chains=10, num_subsets=10):\n",
        "#       \"\"\"\n",
        "#       Initialize the TS-DShapley algorithm.\n",
        "\n",
        "#       Args:\n",
        "#           target_model: Pre-trained model\n",
        "#           train_dataloader: Dataloader for the training dataset\n",
        "#           val_dataloader: Dataloader for the validation dataset\n",
        "#           num_chains: Number of independent Monte Carlo sampling chains (J)\n",
        "#           num_subsets: Number of subsets sampled per chain (T)\n",
        "#       \"\"\"\n",
        "#       self.target_model = target_model\n",
        "#       self.train_dataloader = train_dataloader\n",
        "#       self.num_chains = num_chains\n",
        "#       self.num_subsets = num_subsets\n",
        "#       self.val_dataloader = val_dataloader\n",
        "#       self.random_seed = 42\n",
        "\n",
        "#       self.representations = None # extracted output from penultimate layer (output of MLM pretrained model)\n",
        "#       self.targets = None\n",
        "#       self.sampled_subsets = None\n",
        "#       self.sampling_chains = None\n",
        "#       self.shapley_values = None\n",
        "#       self.marginal_contributions = None\n",
        "#       self.val_X, self.val_y = [], []\n",
        "\n",
        "#       # self.src_classifier = MLPRegressor(hidden_layer_sizes=(64, 32), activation=\"relu\", solver=\"adam\", alpha=0.001, max_iter=500, random_state=self.random_seed)\n",
        "#       self.src_classifier = HistGradientBoostingRegressor(random_state=self.random_seed)\n",
        "\n",
        "#       random.seed(self.random_seed)\n",
        "\n",
        "#   def extract_representations(self):\n",
        "#     \"\"\"\n",
        "#     Extracts CLS token representations from the last hidden state of the target model.\n",
        "#     \"\"\"\n",
        "#     self.target_model.eval()\n",
        "#     device = next(self.target_model.parameters()).device\n",
        "\n",
        "#     # extracting representation of the tarin samples\n",
        "#     all_representations = []\n",
        "#     all_targets = []\n",
        "#     with torch.no_grad():\n",
        "#         for batch in self.train_dataloader:\n",
        "#             inputs, targets = batch[\"input_ids\"].to(device), batch[\"target\"].to(device)\n",
        "#             attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "#             # Forward pass through the pretrained model\n",
        "#             outputs = self.target_model.pretrained(inputs, attention_mask=attention_mask)\n",
        "#             hidden_states = outputs.last_hidden_state\n",
        "\n",
        "#             # Extract CLS token representation (first token)\n",
        "#             cls_representations = hidden_states[:, 0, :].cpu().numpy()\n",
        "#             all_representations.append(cls_representations)\n",
        "#             all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "#     # extracted representations of penultimate layer for all the train samples\n",
        "#     self.representations = np.concatenate(all_representations, axis=0)\n",
        "#     self.targets = np.concatenate(all_targets, axis=0)\n",
        "\n",
        "#     # extracting representation of the validation samples\n",
        "#     self.val_X, self.val_y = [], []\n",
        "#     with torch.no_grad():\n",
        "#         for batch in self.val_dataloader:\n",
        "#             inputs, targets = batch[\"input_ids\"].to(device), batch[\"target\"].to(device)\n",
        "#             attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "#             # Forward pass through the pretrained model\n",
        "#             outputs = self.target_model.pretrained(inputs, attention_mask=attention_mask)\n",
        "#             hidden_states = outputs.last_hidden_state\n",
        "\n",
        "#             # Extract CLS token representations\n",
        "#             cls_representations = hidden_states[:, 0, :].cpu().numpy()\n",
        "#             self.val_X.append(cls_representations)\n",
        "#             self.val_y.append(targets.cpu().numpy())\n",
        "\n",
        "#     # extracted representations of penultimate layer for all the validation samples\n",
        "#     self.val_X = np.concatenate(self.val_X, axis=0)\n",
        "#     self.val_y = np.concatenate(self.val_y, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "#   def apply_pca(self):\n",
        "#       \"\"\"\n",
        "#       Applies PCA to reduce dimensionality of extracted representations.\n",
        "#       \"\"\"\n",
        "#       # Fit PCA and transform data\n",
        "#       # pca = PCA(svd_solver=\"full\", random_state=self.random_seed)\n",
        "#       pca = PCA(n_components=32, svd_solver=\"full\", random_state=self.random_seed)\n",
        "#       self.representations = pca.fit_transform(self.representations)\n",
        "#       self.val_X = pca.transform(self.val_X)\n",
        "\n",
        "\n",
        "#   def sample_training_subsets(self):\n",
        "#       \"\"\"\n",
        "#       Samples T subsets of size in the range [s/2, s] for Monte Carlo sampling, where s is the size of full dataset.\n",
        "#       Each subset is randomly selected from the full dataset.\n",
        "#       \"\"\"\n",
        "#       self.sampled_subsets = []\n",
        "#       for _ in range(self.num_subsets):\n",
        "#           subset_size = random.randint(len(self.representations) // 2, len(self.representations))\n",
        "#           subset_indices = random.sample(range(len(self.representations)), subset_size)\n",
        "#           self.sampled_subsets.append(subset_indices)\n",
        "\n",
        "#   def generate_sampling_chains(self):\n",
        "#       \"\"\"\n",
        "#       Generates J independent Monte Carlo sampling chains.\n",
        "#       \"\"\"\n",
        "#       self.sampling_chains = []\n",
        "#       for _ in range(self.num_chains):\n",
        "#           self.sample_training_subsets()  # Generate T subsets\n",
        "#           self.sampling_chains.append(self.sampled_subsets.copy())\n",
        "\n",
        "#   def compute_marginal_contributions(self):\n",
        "#     \"\"\"\n",
        "#     Computes marginal contributions using Monte Carlo sampling.\n",
        "#     \"\"\"\n",
        "#     self.marginal_contributions = {i: {c: [] for c in range(self.num_chains)} for i in range(len(self.representations))}\n",
        "\n",
        "#     for chain_idx, chain in enumerate(self.sampling_chains):  # Iterate over J chains\n",
        "#         print(f\"chain no: {chain_idx}\")\n",
        "#         count = 1\n",
        "#         for subset_indices in chain:  # Iterate over T subsets in chain\n",
        "#             print(f\"subset no: {count}\")\n",
        "#             count += 1\n",
        "#             subset_X = self.representations[subset_indices]\n",
        "#             subset_y = self.targets[subset_indices]\n",
        "\n",
        "#             # Train A_src on subset S_t and get validation performance\n",
        "#             self.train_src_model(subset_X, subset_y)\n",
        "#             prev_score = self.evaluate_subset(self.val_X, self.val_y)\n",
        "\n",
        "#             # compute marginal contribution for each sample in the subset by sequentially removing instances in a random order\n",
        "#             for idx in range(len(subset_indices)):\n",
        "#                 reduced_indices = subset_indices[idx + 1 :]\n",
        "#                 if not reduced_indices:\n",
        "#                     break\n",
        "\n",
        "#                 reduced_X = self.representations[reduced_indices]\n",
        "#                 reduced_y = self.targets[reduced_indices]\n",
        "\n",
        "#                 self.train_src_model(reduced_X, reduced_y)\n",
        "#                 new_score = self.evaluate_subset(self.val_X, self.val_y)\n",
        "\n",
        "#                 marginal_contribution = prev_score - new_score\n",
        "#                 self.marginal_contributions[subset_indices[idx]][chain_idx].append(marginal_contribution)\n",
        "#                 prev_score = new_score\n",
        "\n",
        "#   # def compute_chain_marginal_contributions(self, chain_idx, chain):\n",
        "#   #     \"\"\"\n",
        "#   #     Computes marginal contributions for a single Monte Carlo sampling chain.\n",
        "#   #     \"\"\"\n",
        "#   #     chain_contributions = {i: [] for i in range(len(self.representations))}\n",
        "#   #     for subset_indices in chain: #Iterate over T subsets in chain\n",
        "#   #         count += 1\n",
        "#   #         subset_X = self.representations[subset_indices]\n",
        "#   #         subset_y = self.targets[subset_indices]\n",
        "\n",
        "#   #         # Train A_src on subset S_t and get validation performance\n",
        "#   #         self.train_src_model(subset_X, subset_y)\n",
        "#   #         prev_score = self.evaluate_subset(self.val_X, self.val_y)\n",
        "\n",
        "#   #         # compute marginal contribution for each sample in the subset by sequentially removing instances in a random order\n",
        "#   #         for idx in range(len(subset_indices)):\n",
        "#   #             reduced_indices = subset_indices[idx + 1 :]\n",
        "#   #             if not reduced_indices:\n",
        "#   #                 break\n",
        "\n",
        "#   #             reduced_X = self.representations[reduced_indices]\n",
        "#   #             reduced_y = self.targets[reduced_indices]\n",
        "\n",
        "#   #             self.train_src_model(reduced_X, reduced_y)\n",
        "#   #             new_score = self.evaluate_subset(self.val_X, self.val_y)\n",
        "\n",
        "#   #             marginal_contribution = prev_score - new_score\n",
        "#   #             chain_contributions[subset_indices[idx]].append(marginal_contribution)\n",
        "#   #             prev_score = new_score\n",
        "\n",
        "#   #     return chain_idx, chain_contributions\n",
        "\n",
        "#   # def compute_marginal_contributions(self):\n",
        "#   #     \"\"\"\n",
        "#   #     Computes marginal contributions using Monte Carlo sampling in parallel across chains.\n",
        "#   #     \"\"\"\n",
        "#   #     self.marginal_contributions = {i: {c: [] for c in range(self.num_chains)} for i in range(len(self.representations))}\n",
        "#   #     results = Parallel(n_jobs=-1)(delayed(self.compute_chain_marginal_contributions)(chain_idx, chain)\n",
        "#   #                                   for chain_idx, chain in enumerate(self.sampling_chains))\n",
        "\n",
        "#   #     # Aggregate results\n",
        "#   #     for chain_idx, chain_contributions in results:\n",
        "#   #         for i, contributions in chain_contributions.items():\n",
        "#   #             self.marginal_contributions[i][chain_idx].extend(contributions)\n",
        "\n",
        "\n",
        "#   def aggregate_shapley_values(self):\n",
        "#     \"\"\"\n",
        "#     Aggregates the Shapley values by first averaging the marginal contributions within each chain (over T),\n",
        "#     then averaging across all chains (over J).\n",
        "#     \"\"\"\n",
        "#     self.shapley_values = {}\n",
        "#     for i, chain_contributions in self.marginal_contributions.items():\n",
        "#         chain_averages = []\n",
        "\n",
        "#         for chain_idx, contributions in chain_contributions.items():\n",
        "#             if contributions:\n",
        "#                 chain_averages.append(sum(contributions) / self.num_subsets)  # Average over T for this chain for the specific instance\n",
        "\n",
        "#         if chain_averages:\n",
        "#             self.shapley_values[i] = sum(chain_averages) / self.num_chains  # Average over J chains for the specific instance\n",
        "#         else:\n",
        "#             self.shapley_values[i] = 0\n",
        "\n",
        "#   def train_src_model(self, subset_X, subset_y):\n",
        "#       \"\"\"\n",
        "#       Trains the simple regression model A_src.\n",
        "\n",
        "#       Args:\n",
        "#         subset_X: Feature representations of the subset.\n",
        "#         subset_y: Corresponding target values.\n",
        "#       \"\"\"\n",
        "#       self.src_classifier.fit(subset_X, subset_y)\n",
        "\n",
        "\n",
        "#   def evaluate_subset(self, subset_X, subset_y):\n",
        "#     \"\"\"\n",
        "#     Evaluates the predictive performance of the simple regression model A_src on a given subset.\n",
        "\n",
        "#     Args:\n",
        "#         subset_X: Feature representations of the subset.\n",
        "#         subset_y: Corresponding target values.\n",
        "\n",
        "#     Returns:\n",
        "#         The Mean Squared Error (MSE) of A_src on the subset.\n",
        "#     \"\"\"\n",
        "#     predictions = self.src_classifier.predict(subset_X)\n",
        "#     mse = ((predictions - subset_y) ** 2).mean()\n",
        "#     return mse\n",
        "\n",
        "#   def identify_low_value_data(self, patience=3):\n",
        "#     \"\"\"\n",
        "#     Identifies the optimal number of low-value data points to remove based on validation performance.\n",
        "\n",
        "#     Args:\n",
        "#         patience: Number of consecutive removal steps without improvement before stopping.\n",
        "\n",
        "#     Returns:\n",
        "#         Indices of instances to be removed.\n",
        "#     \"\"\"\n",
        "#     sorted_indices = sorted(self.shapley_values, key=self.shapley_values.__getitem__) # Sort in ascending order\n",
        "#     best_validation_score = float(\"inf\")\n",
        "#     best_num_to_remove = 0 # indicates the number of samples to remove\n",
        "#     no_improvement_steps = 0\n",
        "\n",
        "#     for num_to_remove in range(1, len(sorted_indices)):\n",
        "#         remaining_indices = sorted_indices[num_to_remove:]\n",
        "\n",
        "#         reduced_X = self.representations[remaining_indices]\n",
        "#         reduced_y = self.targets[remaining_indices]\n",
        "\n",
        "#         self.train_src_model(reduced_X, reduced_y)\n",
        "#         validation_score = self.evaluate_subset(self.val_X, self.val_y)\n",
        "\n",
        "#         if validation_score < best_validation_score:\n",
        "#             best_validation_score = validation_score\n",
        "#             best_num_to_remove = num_to_remove\n",
        "#             no_improvement_steps = 0\n",
        "#         else:\n",
        "#             no_improvement_steps += 1\n",
        "\n",
        "#         # break if no improvement for set threshold\n",
        "#         if no_improvement_steps >= patience:\n",
        "#             break\n",
        "\n",
        "#     return sorted_indices[:best_num_to_remove]  # Return indices of lowest-value instances to remove\n",
        "\n"
      ],
      "metadata": {
        "id": "AXIYOxMGIWvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methods for TS-DS - Parallelized"
      ],
      "metadata": {
        "id": "SZg89s_iMJVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TS_DShapley:\n",
        "  def __init__(self, target_model, train_dataloader, val_dataloader, num_chains=10, num_subsets=10):\n",
        "      \"\"\"\n",
        "      Initialize the TS-DShapley algorithm.\n",
        "\n",
        "      Args:\n",
        "          target_model: Pre-trained model\n",
        "          train_dataloader: Dataloader for the training dataset\n",
        "          val_dataloader: Dataloader for the validation dataset\n",
        "          num_chains: Number of independent Monte Carlo sampling chains (J)\n",
        "          num_subsets: Number of subsets sampled per chain (T)\n",
        "      \"\"\"\n",
        "      self.target_model = target_model\n",
        "      self.train_dataloader = train_dataloader\n",
        "      self.num_chains = num_chains\n",
        "      self.num_subsets = num_subsets\n",
        "      self.val_dataloader = val_dataloader\n",
        "      self.random_seed = 42\n",
        "\n",
        "      self.representations = None # extracted output from penultimate layer (output of MLM pretrained model)\n",
        "      self.targets = None\n",
        "      self.sampled_subsets = None\n",
        "      self.sampling_chains = None\n",
        "      self.shapley_values = None\n",
        "      self.marginal_contributions = None\n",
        "      self.val_X, self.val_y = [], []\n",
        "\n",
        "      random.seed(self.random_seed)\n",
        "\n",
        "  def extract_representations(self):\n",
        "    \"\"\"\n",
        "    Extracts CLS token representations from the last hidden state of the target model.\n",
        "    \"\"\"\n",
        "    self.target_model.eval()\n",
        "    device = next(self.target_model.parameters()).device\n",
        "\n",
        "    # extracting representation of the tarin samples\n",
        "    all_representations = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for batch in self.train_dataloader:\n",
        "            inputs, targets = batch[\"input_ids\"].to(device), batch[\"target\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            # Forward pass through the pretrained model\n",
        "            outputs = self.target_model.pretrained(inputs, attention_mask=attention_mask)\n",
        "            hidden_states = outputs.last_hidden_state\n",
        "\n",
        "            # Extract CLS token representation (first token)\n",
        "            cls_representations = hidden_states[:, 0, :].cpu().numpy()\n",
        "            all_representations.append(cls_representations)\n",
        "            all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    # extracted representations of penultimate layer for all the train samples\n",
        "    self.representations = np.concatenate(all_representations, axis=0)\n",
        "    self.targets = np.concatenate(all_targets, axis=0)\n",
        "\n",
        "    # extracting representation of the validation samples\n",
        "    self.val_X, self.val_y = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in self.val_dataloader:\n",
        "            inputs, targets = batch[\"input_ids\"].to(device), batch[\"target\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            # Forward pass through the pretrained model\n",
        "            outputs = self.target_model.pretrained(inputs, attention_mask=attention_mask)\n",
        "            hidden_states = outputs.last_hidden_state\n",
        "\n",
        "            # Extract CLS token representations\n",
        "            cls_representations = hidden_states[:, 0, :].cpu().numpy()\n",
        "            self.val_X.append(cls_representations)\n",
        "            self.val_y.append(targets.cpu().numpy())\n",
        "\n",
        "    # extracted representations of penultimate layer for all the validation samples\n",
        "    self.val_X = np.concatenate(self.val_X, axis=0)\n",
        "    self.val_y = np.concatenate(self.val_y, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "  def apply_pca(self):\n",
        "      \"\"\"\n",
        "      Applies PCA to reduce dimensionality of extracted representations.\n",
        "      \"\"\"\n",
        "      # Fit PCA and transform data\n",
        "      # pca = PCA(svd_solver=\"full\", random_state=self.random_seed)\n",
        "      pca = PCA(n_components=100, svd_solver=\"full\", random_state=self.random_seed)\n",
        "      self.representations = pca.fit_transform(self.representations)\n",
        "      self.val_X = pca.transform(self.val_X)\n",
        "\n",
        "\n",
        "  def sample_training_subsets(self):\n",
        "      \"\"\"\n",
        "      Samples T subsets of size in the range [s/2, s] for Monte Carlo sampling, where s is the size of full dataset.\n",
        "      Each subset is randomly selected from the full dataset.\n",
        "      \"\"\"\n",
        "      self.sampled_subsets = []\n",
        "      for _ in range(self.num_subsets):\n",
        "          # subset_size = random.randint(len(self.representations) // 2, len(self.representations)) # selecting half to full set as subset\n",
        "          subset_size = random.randint((len(self.representations)*0.5) // 2, (len(self.representations)*0.5)) # selecting half to 0.5 * full set as subset\n",
        "          # subset_size = int(len(self.representations) * 0.3) # selecting fraction of the dataset as subset\n",
        "          subset_indices = random.sample(range(len(self.representations)), subset_size)\n",
        "          self.sampled_subsets.append(subset_indices)\n",
        "\n",
        "  def generate_sampling_chains(self):\n",
        "      \"\"\"\n",
        "      Generates J independent Monte Carlo sampling chains.\n",
        "      \"\"\"\n",
        "      self.sampling_chains = []\n",
        "      for _ in range(self.num_chains):\n",
        "          self.sample_training_subsets()  # Generate T subsets\n",
        "          self.sampling_chains.append(self.sampled_subsets.copy())\n",
        "\n",
        "  def compute_chain_marginal_contributions(self, chain_idx, chain, representations, targets, val_X, val_y):\n",
        "      \"\"\"\n",
        "      Computes marginal contributions for a single Monte Carlo sampling chain.\n",
        "      \"\"\"\n",
        "      chain_contributions = {i: [] for i in range(len(representations))}\n",
        "\n",
        "      for subset_indices in chain:\n",
        "          subset_X = representations[subset_indices]\n",
        "          subset_y = targets[subset_indices]\n",
        "\n",
        "          # Train A_src on subset S_t and get validation performance\n",
        "          model = self.train_src_model(subset_X, subset_y)\n",
        "          prev_score = self.evaluate_subset(model, val_X, val_y)\n",
        "\n",
        "          # compute marginal contribution for each sample in the subset by sequentially removing instances in a random order\n",
        "          count = 1\n",
        "          for idx in range(len(subset_indices)):\n",
        "              print(f\"working on {count} subset index in chain {chain_idx}\")\n",
        "              count+=1\n",
        "              reduced_indices = subset_indices[idx + 1 :]\n",
        "              if not reduced_indices:\n",
        "                  break\n",
        "\n",
        "              reduced_X = representations[reduced_indices]\n",
        "              reduced_y = targets[reduced_indices]\n",
        "\n",
        "              model = self.train_src_model(reduced_X, reduced_y)\n",
        "              new_score = self.evaluate_subset(model, val_X, val_y)\n",
        "\n",
        "              marginal_contribution = prev_score - new_score\n",
        "              chain_contributions[subset_indices[idx]].append(marginal_contribution)\n",
        "              prev_score = new_score\n",
        "\n",
        "      return chain_idx, chain_contributions\n",
        "\n",
        "  def compute_marginal_contributions(self):\n",
        "      \"\"\"\n",
        "      Computes marginal contributions using Monte Carlo sampling in parallel across chains.\n",
        "      \"\"\"\n",
        "      self.marginal_contributions = {i: {c: [] for c in range(self.num_chains)} for i in range(len(self.representations))}\n",
        "\n",
        "      results = Parallel(n_jobs=-1)(\n",
        "          delayed(self.compute_chain_marginal_contributions)(\n",
        "              chain_idx, chain, self.representations, self.targets, self.val_X, self.val_y\n",
        "          ) for chain_idx, chain in enumerate(self.sampling_chains)\n",
        "      )\n",
        "\n",
        "      # Aggregate results\n",
        "      for chain_idx, chain_contributions in results:\n",
        "          for i, contributions in chain_contributions.items():\n",
        "              self.marginal_contributions[i][chain_idx].extend(contributions)\n",
        "\n",
        "  def aggregate_shapley_values(self):\n",
        "    \"\"\"\n",
        "    Aggregates the Shapley values by first averaging the marginal contributions within each chain (over T),\n",
        "    then averaging across all chains (over J).\n",
        "    \"\"\"\n",
        "    self.shapley_values = {}\n",
        "    for i, chain_contributions in self.marginal_contributions.items():\n",
        "        chain_averages = []\n",
        "\n",
        "        for chain_idx, contributions in chain_contributions.items():\n",
        "            if contributions:\n",
        "                chain_averages.append(sum(contributions) / self.num_subsets)  # Average over T for this chain for the specific instance\n",
        "\n",
        "        if chain_averages:\n",
        "            self.shapley_values[i] = sum(chain_averages) / self.num_chains  # Average over J chains for the specific instance\n",
        "        else:\n",
        "            self.shapley_values[i] = 0\n",
        "\n",
        "  def train_src_model(self, subset_X, subset_y):\n",
        "      \"\"\"\n",
        "      Trains the simple regression model A_src.\n",
        "\n",
        "      Args:\n",
        "        subset_X: Feature representations of the subset.\n",
        "        subset_y: Corresponding target values.\n",
        "      \"\"\"\n",
        "      src_classifier = HistGradientBoostingRegressor(random_state=self.random_seed)\n",
        "      src_classifier.fit(subset_X, subset_y)\n",
        "      return src_classifier\n",
        "\n",
        "\n",
        "  def evaluate_subset(self, model, subset_X, subset_y):\n",
        "    \"\"\"\n",
        "    Evaluates the predictive performance of the simple regression model A_src on a given subset.\n",
        "\n",
        "    Args:\n",
        "        subset_X: Feature representations of the subset.\n",
        "        subset_y: Corresponding target values.\n",
        "\n",
        "    Returns:\n",
        "        The Mean Squared Error (MSE) of A_src on the subset.\n",
        "    \"\"\"\n",
        "    predictions = model.predict(subset_X)\n",
        "    mse = ((predictions - subset_y) ** 2).mean()\n",
        "    return mse\n",
        "\n",
        "  def identify_low_value_data(self, ext_indices=None):\n",
        "    \"\"\"\n",
        "    Identifies the optimal number of low-value data points to remove based on validation performance.\n",
        "\n",
        "    Args:\n",
        "        patience: Number of consecutive removal steps without improvement before stopping.\n",
        "        ext_indices: Indices of external datapoints\n",
        "\n",
        "    Returns:\n",
        "        Indices of instances to be removed.\n",
        "    \"\"\"\n",
        "    sorted_indices = sorted(self.shapley_values, key=self.shapley_values.__getitem__, reverse=True) # Sort in descending order\n",
        "    # sorted_indices = [i for i in sorted(self.shapley_values, key=self.shapley_values.__getitem__) if i in ext_indices] # # Sort in ascending order and only consider external datapoints\n",
        "    validation_scores = []\n",
        "\n",
        "    for num_to_remove in range(1, len(sorted_indices)):\n",
        "        remaining_indices = sorted_indices[num_to_remove:]\n",
        "\n",
        "        reduced_X = self.representations[remaining_indices]\n",
        "        reduced_y = self.targets[remaining_indices]\n",
        "\n",
        "        model = self.train_src_model(reduced_X, reduced_y)\n",
        "        validation_score = self.evaluate_subset(model, self.val_X, self.val_y)\n",
        "        validation_scores.append(validation_score)\n",
        "\n",
        "    best_num_to_remove = np.argmin(validation_scores)\n",
        "\n",
        "    return sorted_indices[:best_num_to_remove], self.shapley_values, validation_scores  # Return indices of lowest-value instances to remove\n",
        "\n"
      ],
      "metadata": {
        "id": "AMQj6HkJJ0T5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up Model and Data"
      ],
      "metadata": {
        "id": "LIyuEsZ4-JoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"ibm/MoLFormer-XL-both-10pct\"  #MoLFormer model\n",
        "DATASET_PATH = \"scikit-fingerprints/MoleculeNet_Lipophilicity\"\n",
        "\n",
        "# load pre-trained model from HuggingFace\n",
        "model = AutoModel.from_pretrained(MODEL_NAME, deterministic_eval=True, trust_remote_code=True)\n",
        "\n",
        "# load the fine-tuned masked model from task-1\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "mlm_finetuned_model = AutoModel.from_pretrained(\"./mlm_finetuned_model\", local_files_only=True, trust_remote_code=True).to(device) # fine tuned model\n",
        "mlm_regression_model = MoLFormerWithRegressionHead(mlm_finetuned_model).to(device) # initialize with regression head\n",
        "# reset the path to git repo\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())\n",
        "\n",
        "# load dataset\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "dataset = load_dataset(DATASET_PATH)\n",
        "\n",
        "# loading external dataset\n",
        "ext_data = pd.read_csv(\"./tasks/External-Dataset_for_Task2.csv\")\n",
        "# ext_data = ext_data.iloc[:50]\n",
        "ext_data = ext_data.rename(columns={\"Label\": \"label\"}) # making column names consistent\n",
        "ext_dataset = HF_Dataset.from_pandas(ext_data)\n",
        "ext_dataset = ext_dataset.remove_columns([\"__index__\"]) if \"__index__\" in ext_dataset.column_names else ext_dataset\n",
        "\n",
        "# train-test-val split\n",
        "split_dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42) # 80:20\n",
        "train_valid_dataset = split_dataset[\"train\"]\n",
        "test_dataset = split_dataset[\"test\"]\n",
        "split_train_valid = train_valid_dataset.train_test_split(test_size=0.1, seed=42) # 90:10\n",
        "train_dataset = split_train_valid[\"train\"]\n",
        "valid_dataset = split_train_valid[\"test\"]\n",
        "combined_train = concatenate_datasets([train_dataset, ext_dataset])\n",
        "\n",
        "# create dataset and dataloader\n",
        "train_dataset = SMILESDataset(train_dataset, tokenizer, max_length=128)\n",
        "valid_dataset = SMILESDataset(valid_dataset, tokenizer, max_length=128)\n",
        "test_dataset  = SMILESDataset(test_dataset, tokenizer, max_length=128)\n",
        "ext_dataset = SMILESDataset(ext_dataset, tokenizer, max_length=128)\n",
        "combined_train = SMILESDataset(combined_train, tokenizer, max_length=128)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
        "test_dataloader  = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "test_single_dataloader  = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "combined_train_dataloader = DataLoader(combined_train, batch_size=16, shuffle=True)\n",
        "ext_train_dataloader = DataLoader(ext_dataset, batch_size=16, shuffle=False) # for training the model - batch size 16\n",
        "ext_influence_dataloader = DataLoader(ext_dataset, batch_size=1, shuffle=False) # for determing influence of each train points - batch size 1\n",
        "\n",
        "# index range of external dataset in combined loader\n",
        "ext_start_idx = len(train_dataset)\n",
        "ext_indices = list(range(ext_start_idx, ext_start_idx + len(ext_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4op_LO4_-Isx",
        "outputId": "fc7fd6ca-e475-4cce-85b6-5ace7b55530e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nnti-project-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Selection using TS-DShapley"
      ],
      "metadata": {
        "id": "3-nMKB3CovOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_dshapley = TS_DShapley(mlm_regression_model, ext_train_dataloader, valid_dataloader, num_chains=5, num_subsets=5)\n",
        "ts_dshapley.extract_representations()\n",
        "ts_dshapley.apply_pca()\n",
        "ts_dshapley.generate_sampling_chains()\n",
        "ts_dshapley.compute_marginal_contributions()\n",
        "ts_dshapley.aggregate_shapley_values()\n",
        "low_value_indices, shapley_values, validation_scores = ts_dshapley.identify_low_value_data(ext_indices=ext_indices)\n",
        "\n",
        "# Print results\n",
        "print(f\"Identified {len(low_value_indices)} low-value data points for removal.\")\n",
        "\n",
        "# store the important data points\n",
        "temp = ext_data.copy()\n",
        "temp.drop(low_value_indices, inplace=True)\n",
        "temp.reset_index(inplace=True)\n",
        "temp.drop(columns=['index'], inplace=True)\n",
        "print(ext_data.shape, temp.shape)\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "temp.to_csv(\"selected_samples_ts_dshapley.csv\", index=False)\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feoKj2Wqo3z3",
        "outputId": "81221a91-e518-4877-8385-be27ee6ba0c6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300, 2) (281, 2)\n",
            "/content/nnti-project-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_indices = sorted(shapley_values, key=shapley_values.__getitem__, reverse=True)\n",
        "print(sorted_indices)\n",
        "print(shapley_values[86])"
      ],
      "metadata": {
        "id": "objEgoX9Ggy7",
        "outputId": "966ae76d-fdfb-48bb-8427-1f027cf2945d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[159, 180, 19, 39, 207, 244, 214, 79, 15, 204, 7, 117, 14, 52, 171, 222, 43, 212, 211, 38, 238, 83, 137, 78, 202, 122, 209, 2, 98, 29, 155, 297, 12, 285, 217, 203, 208, 284, 87, 9, 31, 257, 224, 267, 23, 103, 4, 158, 93, 298, 70, 218, 131, 240, 264, 112, 210, 45, 109, 252, 17, 176, 20, 255, 246, 49, 47, 220, 205, 16, 99, 248, 216, 230, 236, 186, 32, 166, 73, 89, 152, 197, 54, 142, 239, 62, 164, 183, 283, 24, 113, 30, 170, 125, 219, 138, 33, 71, 72, 278, 48, 153, 55, 288, 245, 199, 277, 274, 234, 6, 233, 280, 127, 229, 77, 118, 232, 228, 150, 291, 293, 94, 146, 92, 108, 173, 132, 139, 106, 227, 95, 295, 162, 130, 160, 184, 287, 237, 254, 27, 161, 143, 148, 241, 5, 26, 61, 169, 121, 111, 294, 213, 177, 124, 91, 63, 296, 154, 225, 262, 36, 81, 215, 251, 273, 0, 195, 231, 249, 279, 100, 196, 21, 123, 167, 58, 128, 8, 10, 50, 265, 82, 110, 68, 260, 266, 187, 149, 147, 88, 181, 51, 190, 104, 65, 292, 116, 135, 129, 76, 182, 136, 263, 206, 13, 272, 64, 67, 276, 114, 174, 90, 126, 282, 201, 189, 256, 107, 53, 42, 157, 105, 156, 74, 289, 144, 80, 221, 198, 40, 35, 66, 59, 28, 235, 271, 261, 22, 253, 115, 270, 41, 140, 101, 37, 168, 133, 185, 119, 194, 259, 192, 163, 281, 84, 165, 69, 56, 44, 25, 75, 145, 172, 1, 18, 299, 247, 243, 193, 3, 226, 46, 11, 250, 134, 175, 141, 242, 85, 151, 179, 120, 290, 200, 97, 268, 269, 258, 60, 191, 286, 223, 57, 275, 188, 96, 102, 178, 34, 86]\n",
            "-0.0988768969068993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_scores[:21]\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(len(validation_scores)), validation_scores, marker='o', linestyle='-')"
      ],
      "metadata": {
        "id": "4t0xA_aUCQ1R",
        "outputId": "bd8de94c-e2d9-4b9d-c1b9-068b1766591b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1130910490>]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning Model with TS-DShapley Selected Data"
      ],
      "metadata": {
        "id": "9N5CB4lErhPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlm_regression_model = MoLFormerWithRegressionHead(mlm_finetuned_model).to(device) # initialize regression model\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# load selected datapoints\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "ext_data = pd.read_csv(\"selected_samples_ts_dshapley.csv\")\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())\n",
        "\n",
        "# reset the path to git repo\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "a-z92duzrgyq",
        "outputId": "bc9f0ec9-0cdc-4e9f-865b-fac323760fbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nnti-project-25\n",
            "/content/nnti-project-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting new train data with top 100 influential ext_data points\n",
        "ext_data = ext_data.rename(columns={\"Label\": \"label\"}) # making column names consistent\n",
        "ext_dataset = HF_Dataset.from_pandas(ext_data)\n",
        "ext_dataset = ext_dataset.remove_columns([\"__index__\"]) if \"__index__\" in ext_dataset.column_names else ext_dataset\n",
        "\n",
        "# train-test-val split\n",
        "split_dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42) # 80:20\n",
        "train_valid_dataset = split_dataset[\"train\"]\n",
        "test_dataset = split_dataset[\"test\"]\n",
        "split_train_valid = train_valid_dataset.train_test_split(test_size=0.1, seed=42) # 90:10\n",
        "train_dataset = split_train_valid[\"train\"]\n",
        "valid_dataset = split_train_valid[\"test\"]\n",
        "combined_train = concatenate_datasets([train_dataset, ext_dataset])\n",
        "\n",
        "# create dataset and dataloader\n",
        "combined_train = SMILESDataset(combined_train, tokenizer, max_length=128)\n",
        "valid_dataset = SMILESDataset(valid_dataset, tokenizer, max_length=128)\n",
        "test_dataset  = SMILESDataset(test_dataset, tokenizer, max_length=128)\n",
        "combined_train_dataloader = DataLoader(combined_train, batch_size=16, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
        "test_dataloader  = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "Xp4rEF6IrzIn"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS_reg = 20\n",
        "LEARNING_RATE_reg = 1e-7\n",
        "patience = 5\n",
        "epochs_no_improve = 0\n",
        "best_valid_loss = float(\"inf\")\n",
        "optimizer_reg = torch.optim.Adam(mlm_regression_model.parameters(), lr=LEARNING_RATE_reg)\n",
        "loss_fn = nn.MSELoss()\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "\n",
        "for epoch in range(EPOCHS_reg):\n",
        "    mlm_regression_model.train()\n",
        "    total_train_loss = 0.0\n",
        "\n",
        "    # training with combined set\n",
        "    for batch in combined_train_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        mask = batch['attention_mask'].to(device)\n",
        "        targets = batch['target'].to(device)\n",
        "\n",
        "        optimizer_reg.zero_grad()\n",
        "        outputs = mlm_regression_model(input_ids, mask)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer_reg.step()\n",
        "\n",
        "        total_train_loss += loss.item() * input_ids.size(0)\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataset)\n",
        "    print(f\"Epoch {epoch+1} - Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # validation\n",
        "    mlm_regression_model.eval()\n",
        "    total_valid_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in valid_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            mask = batch['attention_mask'].to(device)\n",
        "            targets = batch['target'].to(device)\n",
        "            outputs = mlm_regression_model(input_ids, mask)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            total_valid_loss += loss.item() * input_ids.size(0)\n",
        "\n",
        "    avg_valid_loss = total_valid_loss / len(valid_dataset)\n",
        "    print(f\"Epoch {epoch+1} - Validation Loss: {avg_valid_loss:.4f}\")\n",
        "\n",
        "    # early stop check\n",
        "    if avg_valid_loss < best_valid_loss:\n",
        "        best_valid_loss = avg_valid_loss\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(mlm_regression_model.state_dict(), \"best_mlm_regression_model_task3_set_name.pth\")\n",
        "        print(\"Validation loss improved, model saved.\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"No improvement for {epochs_no_improve} consecutive epochs.\")\n",
        "    if epochs_no_improve >= patience:\n",
        "        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "        break\n",
        "\n",
        "# reset the path to git repo\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "aydqwQGp2Qfz",
        "outputId": "b2aeb436-8551-44b8-b6c9-01e45a09f80e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Train Loss: 7.1513\n",
            "Epoch 1 - Validation Loss: 6.5552\n",
            "Validation loss improved, model saved.\n",
            "Epoch 2 - Train Loss: 6.0438\n",
            "Epoch 2 - Validation Loss: 5.4749\n",
            "Validation loss improved, model saved.\n",
            "Epoch 3 - Train Loss: 5.0585\n",
            "Epoch 3 - Validation Loss: 4.5445\n",
            "Validation loss improved, model saved.\n",
            "Epoch 4 - Train Loss: 4.2526\n",
            "Epoch 4 - Validation Loss: 3.8041\n",
            "Validation loss improved, model saved.\n",
            "Epoch 5 - Train Loss: 3.5574\n",
            "Epoch 5 - Validation Loss: 3.1811\n",
            "Validation loss improved, model saved.\n",
            "Epoch 6 - Train Loss: 2.9949\n",
            "Epoch 6 - Validation Loss: 2.5760\n",
            "Validation loss improved, model saved.\n",
            "Epoch 7 - Train Loss: 2.5459\n",
            "Epoch 7 - Validation Loss: 2.2116\n",
            "Validation loss improved, model saved.\n",
            "Epoch 8 - Train Loss: 2.2106\n",
            "Epoch 8 - Validation Loss: 1.9237\n",
            "Validation loss improved, model saved.\n",
            "Epoch 9 - Train Loss: 1.9397\n",
            "Epoch 9 - Validation Loss: 1.6946\n",
            "Validation loss improved, model saved.\n",
            "Epoch 10 - Train Loss: 1.7743\n",
            "Epoch 10 - Validation Loss: 1.5668\n",
            "Validation loss improved, model saved.\n",
            "Epoch 11 - Train Loss: 1.6759\n",
            "Epoch 11 - Validation Loss: 1.4862\n",
            "Validation loss improved, model saved.\n",
            "Epoch 12 - Train Loss: 1.6235\n",
            "Epoch 12 - Validation Loss: 1.4317\n",
            "Validation loss improved, model saved.\n",
            "Epoch 13 - Train Loss: 1.5792\n",
            "Epoch 13 - Validation Loss: 1.3800\n",
            "Validation loss improved, model saved.\n",
            "Epoch 14 - Train Loss: 1.5645\n",
            "Epoch 14 - Validation Loss: 1.3267\n",
            "Validation loss improved, model saved.\n",
            "Epoch 15 - Train Loss: 1.5330\n",
            "Epoch 15 - Validation Loss: 1.3343\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 16 - Train Loss: 1.5006\n",
            "Epoch 16 - Validation Loss: 1.3330\n",
            "No improvement for 2 consecutive epochs.\n",
            "Epoch 17 - Train Loss: 1.5038\n",
            "Epoch 17 - Validation Loss: 1.3090\n",
            "Validation loss improved, model saved.\n",
            "Epoch 18 - Train Loss: 1.4759\n",
            "Epoch 18 - Validation Loss: 1.3380\n",
            "No improvement for 1 consecutive epochs.\n",
            "Epoch 19 - Train Loss: 1.4724\n",
            "Epoch 19 - Validation Loss: 1.3085\n",
            "Validation loss improved, model saved.\n",
            "Epoch 20 - Train Loss: 1.4622\n",
            "Epoch 20 - Validation Loss: 1.2724\n",
            "Validation loss improved, model saved.\n",
            "/content/nnti-project-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test evaluation\n",
        "influences = []\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# loading pre-trained mlm regression model\n",
        "path = '/content/drive/My Drive/Colab Notebooks/nnti/'\n",
        "os.chdir(path)\n",
        "mlm_regression_model = MoLFormerWithRegressionHead(mlm_finetuned_model).to(device)\n",
        "mlm_regression_model.load_state_dict(torch.load(\"best_mlm_regression_model_task3_set_name.pth\"))\n",
        "# reset the path to git repo\n",
        "os.chdir(\"/content/nnti-project-25/\")\n",
        "print(os.getcwd())\n",
        "\n",
        "mlm_regression_model.eval()\n",
        "total_test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        mask = batch['attention_mask'].to(device)\n",
        "        targets = batch['target'].to(device)\n",
        "        outputs = mlm_regression_model(input_ids, mask)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        total_test_loss += loss.item() * input_ids.size(0)\n",
        "\n",
        "avg_test_loss = total_test_loss / len(test_dataset)\n",
        "print()\n",
        "print(f\"Basic Fine Tuned Model with TS-DShapley Ext Sample Test Loss: {avg_test_loss:.4f}\")"
      ],
      "metadata": {
        "id": "tMxGZLJuEtNR",
        "outputId": "87baceab-ce0b-4082-fbe4-e9f01a5655fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-365091c24573>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  mlm_regression_model.load_state_dict(torch.load(\"best_mlm_regression_model_task3_set_name.pth\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nnti-project-25\n",
            "\n",
            "Basic Fine Tuned Model with TS-DShapley Ext Sample Test Loss: 1.2583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Garbage Cleaning"
      ],
      "metadata": {
        "id": "KwlEt-ylDOuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del regression_model\n",
        "del train_dataset\n",
        "del test_dataset\n",
        "del train_dataloader\n",
        "del test_dataloader\n",
        "del ext_dataset\n",
        "del ext_dataloader\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "aqszc-zLCuSq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}